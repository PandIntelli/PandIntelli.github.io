<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>关于知识蒸馏温度T的一个简单解释(最优化函数拟合角度)</title>
    <link href="/2022/04/17/Interpreability-of-KD/"/>
    <url>/2022/04/17/Interpreability-of-KD/</url>
    
    <content type="html"><![CDATA[<p>本篇文章用最优化近似的角度解释Softmax，并进一步对知识蒸馏的温度T做出解释。要解释知识蒸馏，首先要对它进行介绍。</p><h1 id="知识蒸馏"><a href="#知识蒸馏" class="headerlink" title="知识蒸馏"></a>知识蒸馏</h1><p>知识蒸馏是Hinton于2015年提出的概念，借助一个大的、泛用性强的模型去训练一个小的、专有性(用于执行某一特定功能)强的模型。</p><img src="./KD_model.jpeg"/><p>具体做法是，同样的输入分别通过大模型(Teacher模型)和小模型(Student模型)，产生预测值。Teacher模型的预测值为$v_i$，Student模型的预测值为$z_i$。让Student模型的输出$z_i$同时和$v_i$、GT做近似。</p><p>可以看出来，和平常的神经网络训练相比，知识蒸馏的训练方法引入了Teacher模型的输出作为一个近似的Label。因为如果是做图像分类任务的话，它通常是一个经过Softmax处理后的概率分布，所以我们也叫它soft label。至于GT，因为它是one-hot形式的，所以也叫它hard label。</p><p>综上，整体Loss分为两部分：$L_{soft}$和$L_{hard}$，其中<br>$$<br>\begin{aligned}<br>    &amp;L_{soft}&#x3D;-\sum\limits_{i}^Np_i\log q_i\<br>    &amp;p_i&#x3D;\frac{\exp(v_i&#x2F;T)}{\sum \exp(v_j&#x2F;T)}\<br>    &amp;q_i&#x3D;\frac{\exp(z_i&#x2F;T)}{\sum\exp(z_j&#x2F;T)}<br>\end{aligned}<br>$$</p><p>$$<br>\begin{aligned}<br>    &amp;L_{hard}&#x3D;-\sum\limits_i^Nc_i\log(q_i)\<br>    &amp;q_i&#x3D;\frac{\exp(z_i)}{\sum\exp(z_j)}<br>\end{aligned}<br>$$</p><p>至于为什么soft loss的部分输出要除以T后再做Softmax，有一个直观上的解释：</p><p>富有经验的Teacher模型通常会输出一个置信度非常高的结果，也就是说，输入是某一类的概率非常大，整体的概率分布非常尖锐(信息熵小)。而我们训练Student模型则想让他去学习整体的分布情况(信息熵大)，除以T后，整体的概率分布趋于平滑，分布的熵越大，Teacher模型输出所含的信息也会增多，Student模型会学习这样的概率分布。</p><p>所以，整体的Loss由这两个部分loss加和组成，至于为什么起名叫知识蒸馏：</p><p>因为用高温T蒸馏出大模型所含的”知识”，让小模型去学习这些知识。</p><h1 id="最优化角度推导Softmax"><a href="#最优化角度推导Softmax" class="headerlink" title="最优化角度推导Softmax"></a>最优化角度推导Softmax</h1><p>介绍完知识蒸馏，已经可以直观上理解温度T的作用了，但是要从数值上解释它之前，还要引入一些东西。先从最优化角度推导Softmax开始。</p><p>对于一个分类问题来说，假设一共有$C$个类别，那么对于一个样本，我们希望它的真值标签(ground-truth label)比别的类别对应的输出概率要大。</p><p>也就是对应优化目标：</p><blockquote><p>输出C个概率&#x2F;score，使目标分数最大。</p></blockquote><p>换成数学语言，也就是 $z_y&#x3D;\max{z_i}$</p><p>那么，对应的损失函数就是：<br>$$<br>L&#x3D;\max(\max\limits_{i\neq y}{z_i}-z_y,0)<br>$$<br>外面套了一个ReLU函数，我们希望在$z_y$已经是最大值的时候，也就是$\max\limits_{i\neq y}{z_i}-z_y$为负的时候，Loss为0。因为此时已经达到优化目标了，不需要再优化。</p><p>接下来就要用光滑函数来替代这个函数了，毕竟max函数不可导。</p><p>介绍两个重要的近似函数(详细的推导放在这一节的最后)</p><p>1、$\max{z_i}$函数的近似<br>$$<br>\max{x_i}&#x3D;\log\sum e^{x_i}<br>$$<br>2、ReLU函数 $\max(x,0)$的近似<br>$$<br>\max(x,0)&#x3D;\log(1+e^x)<br>$$<br>由这两个函数，我们可以替换原来的loss。<br>$$<br>\begin{aligned}<br>    L&amp;&#x3D;\max(\log\sum e^{z_i}-z_y,0)\<br>     &amp;&#x3D;\log(1+\exp(\log\sum e^{z_i}-z_y))\<br>     &amp;&#x3D;\log(1+\frac{\exp(\log\sum e^{z_i})}{e^{z_y}})\<br>     &amp;&#x3D;\log(\frac{\sum’e^{z_i}}{e^{z_y}})\<br>     &amp;&#x3D;-\log{\frac{e^{z_y}}{\sum’e^{z_i}}}<br>\end{aligned}<br>$$<br>这就是我们熟知的softmax交叉熵损失函数了(默认和平均分布计算交叉熵, 也就是前面乘的概率是$\frac{1}{p}$)</p><h2 id="max-z-i-函数的光滑近似"><a href="#max-z-i-函数的光滑近似" class="headerlink" title="$\max{z_i}$函数的光滑近似"></a>$\max{z_i}$函数的光滑近似</h2><p>参考 <a href="https://kexue.fm/archives/3290">科学空间：寻求一个光滑的最大值函数</a></p><p>在数学分析中，有一个关于最大值函数的公式，即当$x\ge 0, y\ge 0$，有<br>$$<br>\max(x,y)&#x3D;\frac{1}{2}(|x+y|+|x-y|)<br>$$<br>那么，为了寻找一个最大值的函数，首先可以考虑寻找一个能够近似表示绝对值$|x|$的函数。</p><p>为了逐步推进问题，我们对$f(x)&#x3D;|x|$求导，除了$x&#x3D;0$这一点外，其他的导数为：<br>$$<br>f’(x)&#x3D;<br>\begin{cases}<br>    1, &amp;x&gt;0\<br>    -1,&amp;x&lt;0<br>\end{cases}<br>$$<br>这是一个简单的分段函数，跟他最接近的，应该是单位阶跃函数$\theta(x)$：<br>$$<br>\theta(x)&#x3D;<br>\begin{cases}<br>1, &amp;x&gt;0\<br>0, &amp;x&lt;0<br>\end{cases}<br>$$<br>那么，<br>$$<br>f’(x)&#x3D;2\theta(x)-1<br>$$<br>下面只要寻求$\theta(x)$的近似函数，物理学家已经提供现成的函数给我们了，一个比较简单的形式是 <a href="https://zh.wikipedia.org/wiki/%E5%8D%95%E4%BD%8D%E9%98%B6%E8%B7%83%E5%87%BD%E6%95%B0">ref: 维基百科: 单位阶跃函数</a><br>$$<br>\theta(x)&#x3D;\lim\limits_{k\rightarrow +\infty}\frac{1}{1+e^{-kx}}<br>$$<br>那么就可以取$\frac{1}{1+e^{-kx}}$作为近似函数了，代入$f’(x)$得到$\frac{2e^{kx}}{1+e^{kx}}-1$，积分得到<br>$$<br>\begin{aligned}<br>f(x)&amp;&#x3D;\frac{2}{k}\ln(1+e^{kx})-x\<br>    &amp;&#x3D;\frac{1}{k}[\ln(1+e^{kx})+\ln(1+e^{-kx})]\<br>    &amp;&#x3D;\frac{1}{k}\ln(2+e^{kx}+e^{-kx})<br>\end{aligned}<br>$$<br>不难发现，上面式子中的对数部分，在$k$足够大的时候，常数的影响很小，把它去掉之后，我们有一个比较简单的绝对值函数：<br>$$<br>|x|&#x3D;\lim\limits_{k\rightarrow +\infty}\frac{1}{k}\ln(e^{kx}+e^{-kx})<br>$$<br>结合上式和最开始的绝对值式子，我们可以得到：<br>$$<br>\max(x,y)&#x3D;\lim\limits_{k\rightarrow +\infty}\frac{1}{2k}{\ln( e^{k(x+y)}+e^{-k(x+y)})+\ln(e^{k(x-y)}+e^{-k(x-y)})}<br>$$<br>化简上面式子，我们可以得到<br>$$<br>\max(x,y)&#x3D;\lim\limits_{k\rightarrow +\infty}\frac{1}{2k}\ln(e^{2kx}+e^{-2kx}+e^{2ky}+e^{-2ky})<br>$$<br>由于最开始的绝对值式子是在$x\ge 0, y\ge 0$时成立，所以上面式子的$e^{-2kx}$和$e^{-2ky}$都不重要了，也把他们去掉，进一步得到：<br>$$<br>\max(x,y)&#x3D;\lim\limits_{k\rightarrow +\infty}\frac{1}{2k}\ln(e^{2kx}+e^{2kx})<br>$$<br>或者写成<br>$$<br>\max(x,y)&#x3D;\lim\limits_{k\rightarrow +\infty}\frac{1}{k}\ln(e^{kx}+e^{ky})<br>$$<br>上式正是希望得到的理想的最大值函数，虽然推导是基于$x\ge 0,y\ge 0$，但是不难发现，对于负数情况，上面式子仍然成立，甚至可以推广到多个变量的最大值函数：<br>$$<br>\max(x,y,z,…)&#x3D;\lim\limits_{k\rightarrow +\infty}\frac{1}{k}\ln(e^{kx}+e^{ky}+e^{kz}+…)<br>$$<br>关于光滑max函数的更多性质，参见Matrix67的<a href="http://www.matrix67.com/blog/archives/2830">《如何构造一个平滑的最大值函数》</a></p><p>观察最终结果可以看出，实际上max函数做了一个这样的事情：</p><p>找一个在整个实数域上都单调递增的函数，而且增长速度要快于线性增长，然后求和，最后取逆函数。</p><h1 id="知识蒸馏中温度T的作用"><a href="#知识蒸馏中温度T的作用" class="headerlink" title="知识蒸馏中温度T的作用"></a>知识蒸馏中温度T的作用</h1><p>好，现在知道了Softmax函数的光滑近似，开始推导除以T的作用。</p><p>原来的推导过程如下：<br>$$<br>\begin{aligned}<br>    L&amp;&#x3D;\max(\log\sum e^{z_i}-z_y,0)\<br>     &amp;&#x3D;\log(1+\exp(\log\sum e^{z_i}-z_y))\<br>     &amp;&#x3D;\log(1+\frac{\exp(\log\sum e^{z_i})}{e^{z_y}})\<br>     &amp;&#x3D;\log(\frac{\sum’e^{z_i}}{e^{z_y}})\<br>     &amp;&#x3D;-\log{\frac{e^{z_y}}{\sum’e^{z_i}}}<br>\end{aligned}<br>$$<br>使用的两个近似函数如下：</p><p>1、$\max{z_i}$函数的近似<br>$$<br>\max{x_i}\approx\log\sum e^{x_i}<br>$$<br>2、ReLU函数 $\max(x,0)$的近似<br>$$<br>\max(x,0)\approx\log(1+e^x)<br>$$<br>原优化损失函数为：<br>$$<br>L&#x3D;\max(\max\limits_{i\neq y}{z_i}-z_y,0)<br>$$<br>那么除以一个温度T，本质上是在做乘以一个系数s。</p><p>那么新的优化损失函数是：<br>$$<br>L&#x3D;\max(\max\limits_{i\neq y}{sz_i}-sz_y,0)<br>$$<br>乘以一个$s$本来对优化过程没有任何影响，但是在做近似的时候，会有影响。</p><p>也就是$\max(x,0)\approx \log(1+e^x)$和$\max(sx,0)\approx\log(1+e^{sx})$的区别。</p><p>为了方便讨论，这里设$x&gt;0$，实际上输出的也是概率，所以这个假设也是合理的。</p><p>为了衡量近似程度，把约等式相减，计算误差，可以得到：<br>$$<br>|\log(1+e^x)-x|&gt;|\log(1+e^{sx})-sx|<br>$$<br>乘以$s$后，误差变得更小，也就是和原函数近似程度更高，也就是采用了更光滑的近似。</p><p>或者从图上直观解释，画出了$\ln(1+e^{0.2x})-x$和$\ln(1+e^{0.01x})-x$的图像：</p><img src="./image-20220410162440200.png" alt="近似函数图像" style="zoom:67%;" /><p>黑色是$\ln(1+e^{0.01x})-x$, 蓝色是$\ln(1+e^{0.2x})-x$</p><p>这里的$s$分别取了0.01和0.2(换算成对应的温度是T&#x3D;100和T&#x3D;50)</p><p>可以看到，$s&#x3D;0.01$时(黑色)，在近似原函数$\max(x,0)$时，近似函数对小于$0.7$的值，将其值增大了($\ln(1+e^{0.01x})-x&gt;0$)，这个增大的趋势线性衰减。对于大于$0.7$的值，将其值减小了$\ln(1+e^{0.01x})-x&lt;0$。</p><p>而$s$的不同，关键在于线性增大&#x2F;减小的趋势不同，和增大&#x2F;减小的阈值(图中和$x$轴的交点)不同。</p><p>综上所述，$T$的作用其实是控制了对原函数的近似过程。大于某值，使它衰减，小于某值，使它增大。</p>]]></content>
    
    
    <categories>
      
      <category>Miscellaneous</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Knowledge Distillation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度分离卷积方法简介</title>
    <link href="/2022/04/10/Depth-wise-Convolution/"/>
    <url>/2022/04/10/Depth-wise-Convolution/</url>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>相比于普通卷积，Depth-wise 卷积是一种可以减少FLOPs的卷积。但根据网上的评价，这种卷积在降低计算量的同时，会减慢推理速度；实际原因可能是Depth-wise采用的做法将存储瓶颈变为了计算瓶颈：减小了模型size，但在实际计算时需要的IO读取次数是普通卷积的100倍，增加了IO时间。</p><h2 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h2><p>对于普通卷积，输入feature map为$HWC$，输出为$H_1W_1C_1$的情况。kernel size为$(k_1,k_2)$。那么FLOPs为：$k_1\times k_2\times C\times C_1$。</p><img src="./Normal convolution.png" style="zoom:80%;"/><p>如上图所示，输入大小为$12\times 12\times 3$，kernel大小$5\times 5$，输出大小为$8\times 8\times 256$，参数量为：$5\times 5\times 3\times 256$。</p><p>对于深度分离卷积，它将输入的每层channel分开计算卷积，再通过$1\times 1$卷积进行全channel的映射。</p><img src="./Depth-wise convolution.png" style="zoom:80%;"/><p>如图，每个channel先进行$5\times 5$大小的卷积操作，得到一个$8\times 8\times 3$的feature map。</p><img src="./Pointwise convolution.png" style="zoom:80%;"/><p>再对$8\times 8\times 3$做$1\times 1$的卷积，进行全通道的映射。</p><p>第一部分参数量为：$5\times 5\times 3$，第二部分参数量为：$1\times 1\times 3\times 256$。总参数量为$5\times 5\times 3+1\times 1\times 3\times 256$。</p><p>形象的方法例子说完了，下面来进行抽象分析。</p><p>对于输入大小为$HWC$的feature map，要得到输出大小为$H_1W_1C_1$的feature map，kernel size统一假定为$(k_1,k_2)$。</p><p><strong>普通卷积的情况为：</strong></p><p>FLOPs: $H_1\times W_1\times k_1\times k_2\times C\times C_1$。也就是输出map大小$\times$kernel大小$\times$输入输出通道。</p><p>参数量: $k_1\times k_2\times C\times C_1$。也就是$C_1$个计算$C$通道、大小为$(k_1,k_2)$的kernel。</p><p>读取的数据量为feature map+kernel权重，整体为$HWC+k_1k_2CC_1$。</p><p><strong>深度分离卷积的情况为：</strong></p><p>FLOPs: $H_1\times W_1\times k_1\times k_2\times C_1+H_1W_1\times1\times1\times C\times C_1$。</p><p>参数量：$k_1k_2C+1\times1\times C\times C_1$。</p><p>读取的数据量为feature map+kernel权重，整体为$HWC+k_1k_2C+CC_1$。</p><p><strong>对比：</strong></p><table><thead><tr><th>$HWC$$\rightarrow$$H_1W_1C_1$ ($k_1,k_2$)</th><th>FLOPs</th><th>参数量</th><th>读取数据量</th></tr></thead><tbody><tr><td>普通卷积</td><td>$H_1W_1k_1k_2CC_1$</td><td>$k_1k_2CC_1$</td><td>$HWC+k_1k_2CC_1$</td></tr><tr><td>深度分离卷积</td><td>$H_1W_1C_1(k_1k_2+C)$</td><td>$k_1k_2C+CC_1$</td><td>$HWC+k_1k_2C+CC_1$</td></tr><tr><td><strong>倍数</strong>(深度&#x2F;普通)</td><td>$\frac{k_1k_2+C}{k_1k_2C}$</td><td>$\frac{k_1k_2+C_1}{k_1k_2C_1}$</td><td>-</td></tr></tbody></table><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>深度分离卷积是一种降低FLOPs和参数量的方法，对于它的缺点(?)此处不做介绍，具体可以参见博客：<a href="https://zhuanlan.zhihu.com/p/122943688">FLOPs与模型推理速度</a>。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li>[1] <a href="https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728">A Basic Introduction to Separable Convolutions</a></li><li>[2] <a href="https://zhuanlan.zhihu.com/p/122943688">FLOPs与模型推理速度</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Miscellaneous</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读：MixFormer: End-to-End Tracking with Iterative Mixed Attention</title>
    <link href="/2022/03/29/MixFormer/"/>
    <url>/2022/03/29/MixFormer/</url>
    
    <content type="html"><![CDATA[<h2 id="视觉目标跟踪任务"><a href="#视觉目标跟踪任务" class="headerlink" title="视觉目标跟踪任务"></a>视觉目标跟踪任务</h2><p>视觉目标跟踪的主要目的是：通过对摄像头捕获到的图像序列进行分析，计算出运动目标在每一帧图像中的位置；然后，根据运动目标相关的特征值，将图像序列中连续帧的同一运动目标关联起来，得到每帧图像中目标的运动参数以及相邻帧间目标的对应关系，从而得到目标完整的运动轨迹。</p><h3 id="主要研究方向"><a href="#主要研究方向" class="headerlink" title="主要研究方向"></a>主要研究方向</h3><p>目标跟踪是计算机视觉领域的一个重要问题，目前广泛应用在体育赛事转播、安防监控、无人机、无人车、机器人等领域。研究任务包括：</p><ul><li>单目标跟踪：给定一个目标，追踪这个目标的位置。</li><li>多目标跟踪：追踪多个目标的位置。</li><li>Person Re-ID：行人重识别，是利用计算机视觉技术判断图像或者视频序列中是否存在特定行人的技术。广泛被认为是一个图像检索的子问题，即给定一个监控行人图像，检索跨设备下的该行人图像。旨在弥补固定的摄像头的视觉局限，并可与行人检测&#x2F;行人跟踪技术相结合。</li><li>MTMCT：多目标多摄像头跟踪 (Multi-target Multi-camera Tracking)，跟踪多个摄像头拍摄的多个人。</li><li>姿态跟踪：追踪人的姿态。</li></ul><h3 id="目标跟踪主要难点"><a href="#目标跟踪主要难点" class="headerlink" title="目标跟踪主要难点"></a>目标跟踪主要难点</h3><p>现有的算法虽然能一定程度上完成对运动目标的跟踪，但仍存在诸多问题，主要包括：</p><ul><li>目前的跟踪算法大多基于某一种特征集合对目标进行描述，不够完备。</li><li>提取的特征中，跟踪目标和背景特征存在耦合。当背景与目标相似或背景发生很大变化时，跟踪算法往往失效。</li><li>很难长时间对运动轨迹进行准确预测。当遮挡频繁发生时，跟踪算法同样会失效。</li></ul><h3 id="单目标跟踪基本流程"><a href="#单目标跟踪基本流程" class="headerlink" title="单目标跟踪基本流程"></a>单目标跟踪基本流程</h3><p>给定某视频序列初始帧的目标大小与位置，预测后续帧中该目标的大小与位置。基本任务流程：</p><p>输入初始化目标框 $\rightarrow$ 在下一帧中生成候选框 $\rightarrow$ 提取这些候选框的特征 $\rightarrow$ 对候选框评分 $\rightarrow$ 找到得分最高的候选框作为预测的目标</p><p>从以上流程，可以概括出目标跟踪包含4个主要的内容：</p><ul><li><p>窗口生成：生成候选样本，候选窗口的质量直接决定了跟踪系统的表现。</p></li><li><p>特征提取：提取窗口的特征表示。</p></li><li><p>目标信息整合：将候选窗口信息和目标信息进行整合，计算评分等等操作。</p></li><li><p>定位框估计：采用最大值抑制NMS等方法生成最终的定位框。</p></li></ul><h2 id="整体架构"><a href="#整体架构" class="headerlink" title="整体架构"></a>整体架构</h2><p>模型基本包含两个部分：由多层MAM (Mixed Attention Module) 组成的 backbone、一个提供目标定位框的定位头。和其他将特征提取和信息整合步骤解耦的模型相比，这种模型更加紧凑整齐。</p><img src=".\image-20220329104124740.png"/><h3 id="基于MAM的Backbone"><a href="#基于MAM的Backbone" class="headerlink" title="基于MAM的Backbone"></a>基于MAM的Backbone</h3><p>采用multi-stage的架构。每个stage由N个MAM和MLP层构成。</p><p>更详细地说，给定T个模版 (第一个是target，T-1个是在线模版)，大小 $T\times H_t\times W_t\times 3$ 和一个搜索区域，大小 $H_s\times W_s\times 3$。首先使用步长为4，kernel_size为7的卷积Token Embedding层，将他们映射成有**交叠(overlapped)**的patch embedding。然后把patch embedding展开并concat，得到 $(T\times \frac{H_t}{4}\times\frac{W_t}{4}+\frac{H_s}{4}\times\frac{W_s}{4})\times C$ 大小的混合token序列。再把这些token输入到MAM模块中，进行特征融合和特征信息整合。</p><h3 id="基于Corner-x2F-Query的定位头"><a href="#基于Corner-x2F-Query的定位头" class="headerlink" title="基于Corner&#x2F;Query的定位头"></a>基于Corner&#x2F;Query的定位头</h3><h4 id="基于Corner"><a href="#基于Corner" class="headerlink" title="基于Corner"></a>基于Corner</h4><p>受STARK$^{[2]}$启发，使用全卷积corner定位头直接估计追踪目标的bounding box。只使用数个 Conv-BN-ReLU层去分别预测bounding box左上角和右下角的位置。但MixFormer使用的全卷积头比起STARK中同时依赖encoder和decoder的头，结构更加简单。</p><h4 id="基于Query"><a href="#基于Query" class="headerlink" title="基于Query"></a>基于Query</h4><p>受DETR$^{[3]}$启发，使用一个简单的基于query的定位头。这个定位头能充分利用MAM backbone提供的信息，整个模型也就转变成纯基于transformer的框架。详细地说，他们在最后一个Stage给添加了一个regression token，用这个token作为anchor去整合目标和搜索区域的信息。最后，使用三层全连接网络构成的FFN去直接回归bounding box的坐标。</p><h2 id="核心-Mixed-Attention-Module模块"><a href="#核心-Mixed-Attention-Module模块" class="headerlink" title="核心-Mixed Attention Module模块"></a>核心-Mixed Attention Module模块</h2><p>Mixed Attention Module (MAM) 是MixFormer工作的核心。目的是为了提取目标和搜索区域的特征，同时将它们之间的交互信息整合在一起。</p><p>MAM的输入是来自于target template和search area的token，它在这些token上进行注意力机制操作。</p><p>用$q_t,k_t,v_t$分别表示target template中提取的patch embedding映射后得到的query, key, value，同样地，对搜索区域，用$q_s,k_s,v_s$表示，那么混合attention可以被定义为：<br>$$<br>\begin{aligned}<br>    &amp;k_m&#x3D;Concat(k_t,k_s), v_m&#x3D;Concat(v_t,v_s),\<br>    &amp;\text{Attention}_t&#x3D;\text{Softmax}(\frac{q_tk_m^T}{\sqrt{d}})v_m,\<br>    &amp;\text{Attention}_s&#x3D;\text{Softmax}(\frac{q_sk_m^T}{\sqrt{d}})v_m,<br>\end{aligned}<br>$$<br>这里$d$表示key的维度。$\text{Attention}_t$和$\text{Attention}_s$分别表示target和search的特征映射。</p><p>因为tracking的目的是从search region里搜索出目标，所以对$\text{Attention}_t$来说，完全没必要和完整的$k_m$做注意力计算，只要计算self-attention就行了。</p><p>所以最后的计算公式为：<br>$$<br>\begin{aligned}<br>    &amp;\text{Attention}_t&#x3D;\text{Softmax}(\frac{q_tk_t^T}{\sqrt{d}})v_t,\<br>    &amp;\text{Attention}_s&#x3D;\text{Softmax}(\frac{q_sk_m^T}{\sqrt{d}})v_m.<br>\end{aligned}<br>$$</p><h2 id="训练和推理"><a href="#训练和推理" class="headerlink" title="训练和推理"></a>训练和推理</h2><h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><p>首先用CVT$^{[4]}$模型去预训练MAM模块，然后再fine-tune整个框架。使用的Loss function为：<br>$$<br>L_{loc}&#x3D;\lambda_{L1}L_1(B_i,\hat{B}<em>i)+\lambda</em>{giou}L_{giou}(B_i,\hat{B}<em>i),<br>$$<br>这里$\lambda</em>{L1}&#x3D;5$, $\lambda_{giou}&#x3D;2$，是两个loss的权重。$B_i$是bounding box的GT，$\hat{B_i}$是预测的bounding box。</p><h3 id="Template-Online-Update"><a href="#Template-Online-Update" class="headerlink" title="Template Online Update"></a>Template Online Update</h3><p>基于模板匹配的Tracking算法的基础思想是：将要跟踪的目标选定并保存作为模板，然后在Tracking的每一帧中找和这个目标最相似的。因此质量差的模板会导致模型追踪性能下降。因此，MixFormer引入了一个分数预测模块 (Score Prediction Module)。</p><img src=".\image-20220329154716436.png"/><p>它由两个注意力模块和一个三层感知机(MLP)构成。</p><p>首先，将可学习的score token作为query来搜索ROI tokens。然后score token关注所有的初始化target token来隐式将挖掘到的target和最开始的target对比。最后，使用MLP层进行评分，预测分小于0.5则对应template评价为负。</p><p>在训练完backbone之后训练SPM，使用标准交叉熵作为loss：<br>$$<br>L_{score}&#x3D;y_i\log(p_i)+(1-y_i)\log(1-p_i)<br>$$<br>这里$y_i$是GT的label，$p_i$是预测的评分(confidence score)。</p><h3 id="Inference"><a href="#Inference" class="headerlink" title="Inference"></a>Inference</h3><p>推断过程中，提供包含一个静态template和$N$个动态在线template作为MixFormer的输入，来生成目标bounding box和confidence score。然后到更新间隔的时候选取分数最高的样本更新在线模板。</p><h2 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h2><p>可视化结果</p><img src=".\image-20220329155621138.png" style="zoom:67%;" /><img src=".\image-20220329155656980.png"/><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><p>[1] <a href="https://blog.csdn.net/qq_37002417/article/details/108141409">视觉单目标跟踪任务概述</a></p></li><li><p>[2] Bin Yan,  Houwen Peng,  Jianlong Fu,  Dong Wang,  and Huchuan Lu. Learning spatio-temporal transformer for vi-sual tracking. InProceedings of the IEEE&#x2F;CVF International Conference on Computer Vision (ICCV), 2021.</p></li><li><p>[3] Carion N, Massa F, Synnaeve G, et al. End-to-end object detection with transformers[C]&#x2F;&#x2F;European conference on computer vision. Springer, Cham, 2020: 213-229.</p></li><li><p>[4] Wu H, Xiao B, Codella N, et al. Cvt: Introducing convolutions to vision transformers[C]&#x2F;&#x2F;Proceedings of the IEEE&#x2F;CVF International Conference on Computer Vision. 2021: 22-31.</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Transformer</tag>
      
      <tag>Tracking</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>1x1卷积方法及其作用</title>
    <link href="/2022/03/20/1x1convolution/"/>
    <url>/2022/03/20/1x1convolution/</url>
    
    <content type="html"><![CDATA[<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>1x1 的卷积核被广泛使用在各种网络中，又称为网中网 (Network in Network [1])。</p><p>首先举一个简单的例子，CxHxW大小的输入 (其中C为channel, H为高, W为宽)，经过1x1xd卷积后，得到的输出为dxHxW。</p><p>其实1x1卷积可以看成是一种全连接 (full connection)，只不过这种全连接是对于不同通道同一位置的点来说的。</p><p>比如，一个3xHxW的feature，其中2为channels，对这个feature做1x1x2卷积 (其中2为维度)，那么第一个运算结果卷等价于：</p><p>把(1,1)位置，所有通道的特征取出，用$y_1,y_2,y_3$表示，那么输出的$z_1,z_2$为：<br>$$<br>\begin{aligned}<br>    z_1&amp;&#x3D;a_1y_1+a_2y_2+a_3y_3\<br>    z_2&amp;&#x3D;b_1y_1+b_2y_2+b_3y_3<br>\end{aligned}<br>$$<br>这个过程其实也就是在通道层面做全连接操作。</p><h2 id="Effect"><a href="#Effect" class="headerlink" title="Effect"></a>Effect</h2><h3 id="升维｜降维"><a href="#升维｜降维" class="headerlink" title="升维｜降维"></a>升维｜降维</h3><p>和前文中举例一样，1x1 并不会改变 height 和 width，只会将原本数据量进行增加或者减少，也就是只改变 height x width x channels中 channels 这一个维度的大小。所以它可以实现升维&#x2F;降维。</p><h3 id="增加非线性"><a href="#增加非线性" class="headerlink" title="增加非线性"></a>增加非线性</h3><p>1x1 卷积核，可以在保持 feature map 尺度不变的前提下大幅增加非线性特性 (利用后接的非线性激活函数)，把网络做得很deep。</p><h3 id="跨通道信息交互"><a href="#跨通道信息交互" class="headerlink" title="跨通道信息交互"></a>跨通道信息交互</h3><p>使用1x1卷积核，实现降维和升维的操作其实就是channel间信息的线性组合变化，3x3，64channels的卷积核后面添加一个1x1，28channels的卷积核，就变成了3x3，28channels的卷积核，原来的64个channels就可以理解为跨通道线性组合变成了28channels，这就是通道间的信息交互。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li>[1] Lin M, Chen Q, Yan S. Network in network[J]. arXiv preprint arXiv:1312.4400, 2013.</li></ul>]]></content>
    
    
    <categories>
      
      <category>Miscellaneous</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读：MoCo系列论文解读</title>
    <link href="/2022/03/13/MoCo-Series/"/>
    <url>/2022/03/13/MoCo-Series/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文介绍的三篇工作是何恺明关于动量Encoder对对比学习提升效果的研究，文章标题分别如下：</p><ul><li>MoCov1: <a href="#refer-anchor-1">Momentum Contrast for Unsupervised Visual Representation Learning</a> </li><li>MoCov2: <a href="#refer-anchor-2">Improved Baselines with Momentum Contrastive Learning</a></li><li>MoCov3: <a href="#refer-anchor-3">An Empirical Study of Training Self-Supervised Vision Transformers</a></li></ul><p>第一篇文章的工作主要在于引入队列作为负样本和momentum encoder，第二篇文章将MoCo做了改进后和SimCLR框架进行了对比，第三篇文章的主要工作在于使用ViT作为backbone，将ViT的效果和ResNet的效果做对比，证明ViT，也就是视觉Transformer的有效性。</p><h2 id="MoCo-v1"><a href="#MoCo-v1" class="headerlink" title="MoCo v1"></a>MoCo v1</h2><p>这篇文章发表在CVPR 2020上，主要对比普通端到端和Memory bank的方法：</p><ul><li>提出使用队列中的表示作为负样本，将样本数量和batchsize解耦，从而使用更多的负样本做对比学习；</li><li>提出动量更新Encoder，从而保证队列中表示具有一致性。</li></ul><h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><h4 id="端到端方法"><a href="#端到端方法" class="headerlink" title="端到端方法"></a>端到端方法</h4><p>普通端到端的方法如图所示。</p><img src="EndToEnd.png"/><p>它使用当前batch内的样本作为正样本和负样本。同一幅图片增广之后得到的图片分别为$x_k$和$x_q$，它们分别通过两个encoder计算出对应的表示$q$和$k$。如果两个表示来源于同一张图片，则把它们视为一对正样本，否则被视为一对负样本。</p><p>不难看出，这种方法的负样本数量和batchsize是耦合的。如：batchsize&#x3D;$N$，那么$q$和$k$的数量都为$N$，对于某一样本来说，它的负样本对个数为$2N-2$。</p><h4 id="Memory-bank方法"><a href="#Memory-bank方法" class="headerlink" title="Memory bank方法"></a>Memory bank方法</h4><p>Memory bank的方法如图所示。</p><img src="MemoryBank.png"/><p>Memory bank方法是把所有样本都储存在内存中，每次输入一个样本$x_q$时，从内存中取出之前它通过Encoder计算出的表示作为正样本，并从内存中采样其他样本作为负样本，进行对比学习。</p><p>这样的方法虽然不受限于batchsize的大小，而且能采样更多的负样本，但是，对于正样本来说，因为取出的是之前$x_q$通过Encoder计算来的表示，也就是上一个Epoch计算来的表示，所以表示间不具有一致性。同样的，采样出的负样本也有类似的问题。</p><h3 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h3><p>MoCo v1的方法如图所示。</p><img src="MoCov1.png"/><p>所以MoCo引入了队列来将负样本数量和batchsize解耦合，通过引入动量的方式更新encoder计算表示，分别克服了端到端方法和Memory bank方法的两个缺点：负样本数量耦合和一致性。</p><p>MoCo v1的正样本对来源于同一幅图片的两个增广，负样本则全部来源于队列，直接把队列里的所有表示作为负样本。每个迭代动量Encoder计算完表示后，都会把新的表示推入队列中，把最老的表示dequeue出列。</p><p>对于动量Encoder，MoCo采用动量更新的形式，左边query encoder的参数为$\theta_q$，右边key encoder的参数为$\theta_k$，那么参数更新的公式为：<br>$$<br>\theta_k\leftarrow m\theta_k+(1-m)\theta_q<br>$$<br>其中$m$为超参数。这种动量更新的方式应该是参考了Adam优化器等早期采用动量更新的方法。</p><p>最后总体的Loss function为：<br>$$<br>\mathcal{L}<em>q&#x3D;-\log\frac{\exp(q\cdot k</em>+&#x2F;\tau)}{\sum_{i&#x3D;0}^K\exp(q\cdot k_i&#x2F;\tau)}<br>$$<br>这里说一点个人理解：</p><p>两个Encoder首先是将两个表示做近似，采用动量的方式则更好地将右边的表示和左边的表示缓慢接近，表示近似的同时，动量Encoder提供的样本也更好，这里的样本会放入队列中作为下一次迭代的负样本，因此正负样本都是更好的表示。</p><p>但是有点不太理解的问题，左边encoder的样本为$q$，那么对左边encoder求导，导数为：<br>$$<br>\begin{aligned}<br>    \mathcal{L}<em>q&amp;&#x3D;-\log\frac{\exp(q\cdot k</em>+&#x2F;\tau)}{\sum_{i&#x3D;0}^K\exp(q\cdot k_i&#x2F;\tau)}\<br>    \frac{\partial \mathcal{L}<em>q}{\partial q}&amp;&#x3D;\frac{\sum\exp(q\cdot k_i)}{\exp(q\cdot k</em>+)}\cdot\frac{k_+\exp(q\cdot k_+)\sum\exp(q\cdot k_i)-\exp(q\cdot k_+)\sum k_i\exp(q\cdot k_i)}{\left[\sum\exp(q\cdot k_i)\right]^2}\<br>    &amp;&#x3D;-\frac{k_+\sum\exp(q\cdot k_i)-\sum k_i\exp(q\cdot k_i)}{\sum\exp(q\cdot k_i)}\<br>    &amp;&#x3D;\frac{\sum k_i\exp(q\cdot k_i)-\sum k_+\exp(q\cdot k_i)}{\sum\limits_i\exp(q\cdot k_i)}<br>\end{aligned}<br>$$<br>这里为了方便，把相似度函数直接用余弦表示，也就是乘积代替。如公式所示，左边的梯度由正样本与负样本期望的差决定，感觉很奇怪…</p><h3 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h3><p>实验方面，把MoCo 方法和其他两种方法做了对比，如图所示。</p><img src="MoCov1_compare.png" zoom="80%"/><p>End-to-end 方法的batchsize不能开得特别大，但是MoCo则没有这个限制，虽然在前面End-to-end方法的效果和MoCo差不多，但是后面就不能提供大量负样本了。</p><p>Memory bank的方法由于不具有一致性，所以效果比MoCo要低了几个点。</p><p>另外，实验中把超参数 $m$ 进行了消融，如图所示。</p><img src="MoCov1_ablation.png"/><p>更大的$m$可以使训练更加稳定，当$m&#x3D;0$的时候，相当于动量encoder直接拷贝另一个encoder的参数，网络更新太快，提供的负样本质量不好，所以不会收敛。</p><h2 id="MoCo-v2"><a href="#MoCo-v2" class="headerlink" title="MoCo v2"></a>MoCo v2</h2><p>这篇文章是一个两页的技术报告，主要对MoCo v1做了一些改进，然后和SimCLR进行了对比。</p><p>具体的改进如下表所示：</p><table><thead><tr><th></th><th>MoCo</th><th>MoCov2</th><th>SimCLR</th></tr></thead><tbody><tr><td>Projection head</td><td>fc</td><td>2-layer MLP(fc, ReLU)</td><td>MLP(fc, ReLU, fc)</td></tr><tr><td>Learning rate scheduler</td><td>SGD with momentum 0.9 and weight decay 0.0001</td><td>Cosine learning rate schedule</td><td>Cosine learning rate schedule</td></tr><tr><td>Augmentation</td><td>RandomResizedCrop, RandomGrayscale, ColorJitter, RandomHorizontalFlip</td><td>RandomResizedCrop, RandomGrayscale, <strong>[GaussianBlur]</strong>, ColorJitter, RandomHorizontalFlip</td><td>RandomResizedCrop, RandomHorizontalFlip, ColorJitter, RandomGrayscale, <strong>GaussianBlur</strong></td></tr></tbody></table><p>改进主要在三方面，都是参考了SimCLR论文中的做法</p><ul><li>映射头：SimCLR发现线性映射头比非线性映射头效果要好</li><li>学习率规划器：余弦学习率规划器训练更加稳定，SGD是强者的方法，适合调参，但是可能会出现效果不好的问题</li><li>增广：SimCLR发现强增广对于对比学习很重要，于是MoCo添加了高斯模糊</li></ul><h3 id="Ablation"><a href="#Ablation" class="headerlink" title="Ablation"></a>Ablation</h3><img src="MoCov2_ablation.png" zoom="80%"/><p>如图所示，MoCo对于新的改进做了消融，不难发现，MLP和增广对于效果的改进还是很明显的。</p><h3 id="Experiment-1"><a href="#Experiment-1" class="headerlink" title="Experiment"></a>Experiment</h3><img src="MoCov2_experiment.png" zoom="80%"/><p>实验结果如图所示，参数量、时间、准确率都吊打<a href="#refer-anchor-4">SimCLR</a> (采用backbone都是ResNet50)</p><h2 id="MoCo-v3"><a href="#MoCo-v3" class="headerlink" title="MoCo v3"></a>MoCo v3</h2><p>这篇文章是一篇实验性的工作，试着把ViT作为MoCo的backbone，在这篇工作中，MoCo取消了队列(发现大的batchsize已经提供了足够多的负样本，使用队列的增益效果不大)，模仿<a href="#refer-anchor-5">BYOL</a>添加了额外的预测头(prediction head, 非线性映射)，采用了对称的对比损失。</p><h3 id="Method-1"><a href="#Method-1" class="headerlink" title="Method"></a>Method</h3><h4 id="预测头"><a href="#预测头" class="headerlink" title="预测头"></a>预测头</h4><img src="MoCov1.png" zoom="80%"/><p>在左边的encoder后，除了包含一个projection MLP之外，还包含一个prediction MLP，但在右边的encoder后，只包含一个projection MLP。</p><h4 id="对称对比损失"><a href="#对称对比损失" class="headerlink" title="对称对比损失"></a>对称对比损失</h4><p>公式：$ctr(q_1,k_2)+ctr(q_2,k_1)$。</p><p>其中$q_1,q_2$, $k_1,k_2$分别是两幅增广后的图片分别经过encoder和动量encoder得到的表示，然后做对称对比损失。这样做的好处在于，对比单向对比损失，减少了不同encoder提取表示带来的影响，让两个表示尽可能地接近。</p><p>总体的算法流程如下图所示。</p><img src="MoCov3_algorithm.png" zoom="67%"/><h3 id="Empirical-Observations-and-Trick"><a href="#Empirical-Observations-and-Trick" class="headerlink" title="Empirical Observations and Trick"></a>Empirical Observations and Trick</h3><p>在采用ViT作为backbone进行实验的过程各种，训练不稳定，造成模型性能下降，因此作者进行了一些探究，有了一些观察</p><h4 id="Batchsize"><a href="#Batchsize" class="headerlink" title="Batchsize"></a>Batchsize</h4><img src="MoCov3_batchsize.png" zoom="70%"/><p>作者发现，在采用大的batchsize时，准确率会发现突然下降又缓慢上升的现象。</p><h4 id="Learning-rate"><a href="#Learning-rate" class="headerlink" title="Learning rate"></a>Learning rate</h4><img src="MoCov3_lr.png"/><p>同时在使用大的学习率时也有类似现象。(但这里实验采用的对比太小，学习率之间的差距应该设成一个数量级的差距进行对比)</p><h4 id="Spike-Delay"><a href="#Spike-Delay" class="headerlink" title="Spike Delay"></a>Spike Delay</h4><img src="MoCov3_spike.png"/><p>把梯度打印出来后，发现每次最后一层(映射层)在出现梯度抖动之前数个迭代，第一层(ViT的Patch embedding)的梯度总会发生抖动。基于此，作者使用了一个Trick。</p><h4 id="Trick"><a href="#Trick" class="headerlink" title="Trick"></a>Trick</h4><p>通过随机初始化后冻结第一层的网络参数，不传播梯度传播，直接固定，可以避免出现”dip”，使训练更加稳定，如下图所示：</p><img src="MoCov3_trick.png" zoom="70%"/><p>这个trick应用在其他框架上也是有效果的，当然为什么这些框架都会出现这个训练问题就不太清楚了。。</p><img src="MoCov3_trick2.png"/><h3 id="Experiment-2"><a href="#Experiment-2" class="headerlink" title="Experiment"></a>Experiment</h3><p>实验部分，采用的backbone有下面这几种ViT：</p><img src="MoCov3_exp_model.png"/><p>效果如下：</p><img src="MoCov3_exp_res.png"/><img src="MoCov3_exp_res2.png"/><p>其中下表第三行&#x2F;7代表patch_size&#x3D;7x7，使总体序列长度更长可以让Transformer效果更好(借用了iGPT结论)。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><div id="refer-anchor-1"><div>- [1] He K, Fan H, Wu Y, et al. Momentum contrast for unsupervised visual representation learning[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2020: 9729-9738.<div id="refer-anchor-2"><div>- [2] Chen X, Fan H, Girshick R, et al. Improved baselines with momentum contrastive learning[J]. arXiv preprint arXiv:2003.04297, 2020.<div id="refer-anchor-3"><div>- [3] Chen X, Xie S, He K. An empirical study of training self-supervised vision transformers[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2021: 9640-9649.<div id="refer-anchor-4"><div>- [4] Chen T, Kornblith S, Norouzi M, et al. A simple framework for contrastive learning of visual representations[C]//International conference on machine learning. PMLR, 2020: 1597-1607.<div id="refer-anchor-5"><div>- [5] Grill J B, Strub F, Altché F, et al. Bootstrap your own latent-a new approach to self-supervised learning[J]. Advances in Neural Information Processing Systems, 2020, 33: 21271-21284.]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Contrastive Learning</tag>
      
      <tag>Momentum</tag>
      
      <tag>SimCLR</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Contrastive Loss 中超参数τ的研究</title>
    <link href="/2022/03/05/Contrastive-Loss-hyper-parameter/"/>
    <url>/2022/03/05/Contrastive-Loss-hyper-parameter/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>对比学习中许多方法都使用了InfoNCE Loss作为损失函数，但很少有文章详细讲解参数$\tau$的作用，本篇文章参考CVPR 2021文章：<a href="#refer-anchor-1">Understanding the Behaviour of Contrastive Loss</a>，对损失函数的性质进行介绍，并对其中的$\tau$做一个简单解释。</p><p>论文中的发现可以总结为两点：</p><ol><li>对比损失是一个具备<strong>困难负样本自发现</strong>性质的损失函数，这一性质对于学习高质量的自监督表示是至关重要的。关注困难样本的作用是：对于那些已经远离的负样本，不需要让其继续远离，而主要聚焦在如何使没有远离的负样本远离，从而使得表示空间更均匀（Uniformity）。</li><li>$\tau$ 的作用是调节模型困难样本的关注程度： <strong>$\tau$越小，模型越关注于将那些与本样本最相似的负样本分开</strong>。</li></ol><h2 id="对比损失更关注困难负样本（Hardness-Awareness）"><a href="#对比损失更关注困难负样本（Hardness-Awareness）" class="headerlink" title="对比损失更关注困难负样本（Hardness-Awareness）"></a>对比损失更关注困难负样本（Hardness-Awareness）</h2><p>首先给出自监督学习广泛使用的对比损失（InfoNCE Loss）的形式：<br>$$<br>\mathcal{L}(x_i)&#x3D;-\log \frac{\exp(s_{i,i}&#x2F;\tau)}{\sum_{k\neq i }\exp(s_{i,k}&#x2F;\tau)+\exp(s_{i,i}&#x2F;\tau)}<br>$$<br>直观来说，该损失函数要求第 $i$ 个样本和它另一个扩增的（正）样本之间的相似度 $s_{i,i}$ 之间尽可能大，而与其它实例（负样本）之间的相似度 $s_{i,k}$ 之间尽可能小。然而，其实还有很多损失函数可以满足这个要求，例如下面最简单的形式 $\mathcal{L}<em>{simple}$：<br>$$<br>\mathcal{L}</em>{simple}(x_i)&#x3D;-s_{i,i}+\lambda\sum\limits_{i\neq j}s_{i,j}<br>$$<br>然而实际训练时，采用$\mathcal{L}_{simple}$ 作为损失函数效果非常不好，论文给出了他们的性能对比($\tau&#x3D;0.07$)：</p><table><thead><tr><th align="center">Dataset</th><th align="center">Contrastive Loss</th><th align="center">Simple Loss</th></tr></thead><tbody><tr><td align="center">CIFAR10</td><td align="center">79.75</td><td align="center">74.83</td></tr><tr><td align="center">CIFAR100</td><td align="center">51.82</td><td align="center">39.31</td></tr><tr><td align="center">ImageNet100</td><td align="center">71.53</td><td align="center">48.09</td></tr><tr><td align="center">SVHN</td><td align="center">92.55</td><td align="center">70.83</td></tr></tbody></table><p>上面的结果显示，在所有数据集上 Contrastive Loss 都要远好于 Simple Loss。作者通过研究发现，不同于 Simple Loss，Contrastive Loss 是一个困难样本自发现的损失函数。Simple Loss 对所有的负样本给予了相同权重的惩罚 $\frac{\partial \mathcal{L}<em>{simple}}{\partial s</em>{i,k}}&#x3D;\lambda$。而 Contrastive Loss 则会自动给相似度更高的负样本比较高的惩罚，这一点可以通过对 Contrastive Loss 中不同负样本的相似度惩罚梯度观察得到：<br>$$<br>\begin{aligned}<br>对正样本的梯度: &amp;\frac{\partial\mathcal{L}(x_i)}{\partial s_{i,i}}&#x3D;-\frac{1}{\tau}\sum\limits_{k\neq i}P_{i,k}\<br>对负样本的梯度: &amp;\frac{\partial \mathcal{L}(x_i)}{\partial s_{i,j}}&#x3D;\frac{1}{\tau}P_{i,j}<br>\end{aligned}<br>$$<br>其中 $P_{i,j}&#x3D;\frac{\exp(s_{i,j}&#x2F;\tau)}{\sum\limits_{k\neq i}\exp(s_{i,k}&#x2F;\tau)+\exp(s_{i,i}&#x2F;\tau)}$。对所有的负样本来说，$P_{i,j}$的分母项都是相同的，$s_{i,j}$越大，负样本的梯度项 $\frac{\partial \mathcal{L}(x_i)}{\partial s_{i,j}}&#x3D;\frac{1}{\tau}P_{i,j}$也越大。也就是说，Contrastive Loss 给予了更相似（困难）负样本更大的远离该样本的梯度。</p><h2 id="超参数-tau-的作用"><a href="#超参数-tau-的作用" class="headerlink" title="超参数 $\tau$ 的作用"></a>超参数 $\tau$ 的作用</h2><p>为了更具体的解释超参数 $\tau$ 的作用，作者计算了两种极端情况，即 $\tau$ 趋近于 0 和无穷大。当 $\tau$ 趋近于 0 时：<br>$$<br>\begin{aligned}<br>&amp;\lim\limits_{\tau\rightarrow0^+}-\log \frac{\exp(s_{i,i}&#x2F;\tau)}{\sum_{k\neq i}\exp(s_{i,k}&#x2F;\tau)+\exp(s_{i,i}&#x2F;\tau)}\<br>&#x3D;&amp;\lim\limits_{\tau\rightarrow0^+}\log \left[1+\sum\limits_{k\neq i}\exp((s_{i,k}-s_{i,i})&#x2F;\tau)\right]<br>\end{aligned}<br>$$<br>简单点，我们仅考虑那些困难的负样本，即如果存在负样本 $x_k$，有 $s(x_i,x_k)\ge s(x_i,x_i^+)$，则称$x_k$为困难的负样本。则上式可以改写为：<br>$$<br>\lim\limits_{\tau\rightarrow0^+}\log\left[1+\sum\limits_{s_{i,k\ge s_{i,i}}}^{}\exp((s_{i,k}-s_{i,i})&#x2F;\tau)\right]<br>$$<br>因为 $\tau\rightarrow0^+$，直接忽略常数1，并且将求和改为最大的 $s_{i,k}$这一项，记做 $s_{max}$，则上式为：<br>$$<br>\lim_{\tau\rightarrow0^+}\frac{1}{\tau}\max\left[s_{max}-s_{i,i},0 \right]<br>$$<br>可以看出，此时 Contrastive Loss 退化为只关注最困难的负样本的损失函数。而当 $\tau$ 趋近于无穷大时：<br>$$<br>\begin{aligned}<br>&amp;\lim_{\tau\rightarrow+\infty}-\log\left[\frac{\exp(s_{i,i}&#x2F;\tau)}{\sum_{k\neq i} \exp(s_{i,k}&#x2F;\tau)+\exp(s_{i,i}&#x2F;\tau)}\right]\<br>&#x3D;&amp;\lim_{\tau\rightarrow+\infty}-\frac{1}{\tau}s_{i,i}+\log\sum\limits_k\exp(s_{i,k}&#x2F;\tau)\<br>&#x3D;&amp;\lim_{\tau\rightarrow+\infty}-\frac{1}{\tau}s_{i,i}+\log\left[N(1+(\frac{1}{N}\sum\limits_k\exp(s_{i,k}&#x2F;\tau)-1))\right]\<br>&#x3D;&amp;\lim_{\tau\rightarrow+\infty}-\frac{1}{\tau}s_{i,i}+\log\left[1+(\frac{1}{N}\sum\limits_k\exp(s_{i,k}&#x2F;\tau)-1)\right]+\log N\<br>&#x3D;&amp;\lim <em>{\tau \rightarrow+\infty}-\frac{1}{\tau} s</em>{i, i}+\left(\frac{1}{N} \sum_{k} \exp \left(s_{i, k} &#x2F; \tau\right)-1\right)+\log N \<br>&#x3D;&amp;\lim <em>{\tau \rightarrow+\infty}-\frac{1}{\tau} s</em>{i, i}+\frac{1}{N \tau} \sum_{k} s_{i, k}+\log N \<br>&#x3D;&amp;\lim <em>{\tau \rightarrow+\infty} \frac{1-N}{N \tau} s</em>{i, i}+\frac{1}{N \tau} \sum_{k \neq i} s_{i, k}+\log N<br>\end{aligned}<br>$$<br>上述式子利用了 $\ln(1+x)$和$e^x$的泰勒展开(等价无穷小)。</p><p>此时 Contrastive Loss 对所有负样本的权重都相同 ($\frac{1}{N_\tau}$)，即 Contrastive Loss 失去了对困难样本关注的特性。有趣的是，当 $\tau&#x3D;\frac{N-1}{N}$ 时，对比损失 $\mathcal{L}(x_i)$ 与前面提到的 $\mathcal{L}_{simple}$ 几乎一样。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><div id="refer-anchor-1"><div>- [1] Wang F, Liu H. Understanding the behaviour of contrastive loss[C]//Proceedings of the IEEE/CVF conference on computer vision and pattern recognition. 2021: 2495-2504.<ul><li>[2] <a href="https://wmathor.com/index.php/archives/1581/">Contrastive Loss 中参数τ的理解</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Contrastive Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Contrastive Loss</tag>
      
      <tag>InfoNCE</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读：Attention Is All You Need</title>
    <link href="/2022/02/24/Transformer/"/>
    <url>/2022/02/24/Transformer/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>谷歌团队提出的用于生成词向量的BERT算法在NLP的11项任务中取得了效果的大幅提升，堪称2018年深度学习领域最振奋人心的消息。而BERT算法的最重要的部分便是本文中提出的Transformer的概念。</p><p>Transformer中抛弃了传统的CNN和RNN，整个网络结构完全是由Attention机制组成。更准确地讲，Transformer由且仅由self-Attenion和Feed Forward Neural Network组成。一个基于Transformer的可训练的神经网络可以通过堆叠Transformer的形式进行搭建，作者的实验是通过搭建编码器和解码器各6层，总共12层的Encoder-Decoder，并在机器翻译中取得了BLEU值的新高。</p><p>作者采用Attention机制的原因是考虑到RNN（或者LSTM，GRU等）的计算是顺序的，也就是说RNN相关算法只能从左向右依次计算或者从右向左依次计算，这种机制带来了两个问题：</p><ol><li>时间片 $t$ 的计算依赖  $t-1$ 时刻的计算结果，这样限制了模型的并行能力；</li><li>顺序计算的过程中信息会丢失，尽管LSTM等门机制的结构一定程度上缓解了长期依赖的问题，但是对于特别长期的依赖现象, LSTM依旧无能为力。</li></ol><p>Transformer的提出解决了上面两个问题，首先它使用了Attention机制，将序列中的任意两个位置之间的距离缩小为一个常量 (相似度)；其次它不是类似RNN的顺序结构，因此具有更好的并行性，符合现有的GPU框架。论文中给出Transformer的定义是：</p><blockquote><p>Transformer is the first transduction model relying entirely on self-attention to compute representations of its input and output without using sequence aligned RNNs or convolution.</p></blockquote><h2 id="Transformer-详解"><a href="#Transformer-详解" class="headerlink" title="Transformer 详解"></a>Transformer 详解</h2><h3 id="High-level-Transformer"><a href="#High-level-Transformer" class="headerlink" title="High-level Transformer"></a>High-level Transformer</h3><p>论文中的验证 Transformer 的实验是基于机器翻译的，下面以机器翻译为例子详细剖析 Transformer 的结构，在机器翻译中，Transformer 可概括为下图：</p><img src="the_transformer_3.png" alt="Transformer Structure"/>Transformer 的本质是一个 Encoder-Decoder 的结构，那么上图也可以表示为下面的结构：<img src="The_transformer_encoders_decoders.png"/><p>如论文中所设置的，编码器由6个编码block组成，同样解码器是6个解码block组成。与所有的生成模型相同的是，编码器的输出会作为解码器的输入，如图所示：</p><img src="The_transformer_encoder_decoder_stack.png" alt="Transformer的Encoder和Decoder均由6个block堆叠而成"/><p>在 Transformer 的 Encoder 中，数据首先会经过一个叫做 <code>self-attention</code> 的模块得到一个加权之后的特征向量 $Z$，这个 $Z$ 便是下面公式中的 $Attention(Q,K,V)$：<br>$$<br>\text{Attention}(Q,K,V)&#x3D;\text{softmax}(\frac{QK^T}{\sqrt{d_k}})V<br>$$<br>得到 $Z$ 之后，他会被送进 encoder 的下一个模块，前馈神经网络中。这个全连接有两层，第一层的激活函数是 ReLU，第二层是一个线性激活函数，可以表示为：<br>$$<br>\text{FFN}(Z)&#x3D;\max (0,ZW_1+b_1)W_2+b_2<br>$$<br>Encoder 的结构如下图：</p><img src="Transformer_encoder.png" alt="Transformer由self-attention和Feed Forward neural network组成"/><p>Decoder 的结构如下图右方所示，它和 Encoder 的不同之处在于 Decoder 多了一个 Encoder-Decoder Attention，两个 Attention 分别用于计算输入和输出的权值：</p><ol><li>Self-Attention：当前翻译和已经翻译的前文之间的关系；</li><li>Encoder-Decnoder Attention：当前翻译和编码的特征向量之间的关系。</li></ol><img src="Transformer_decoder.png" alt="Transformer的解码器由self-attention，Encoder-Decoder attention以及FFNN组成"/><h3 id="输入编码"><a href="#输入编码" class="headerlink" title="输入编码"></a>输入编码</h3><p>首先通过 Word2Vec 等词嵌入方法将输入语料转化为特征向量，论文中使用的词嵌入的维度为 $d_{model}&#x3D;512$。</p><img src="embeddings.png" alt="单词的输入编码"/><p>在最底层的block中， $x$ 将直接作为Transformer的输入，而在其他层中，输入则是上一个block的输出。</p><img src="encoder_with_tensors_2.png" alt="输入编码作为一个Tensor输入到Encoder中"/><h3 id="Self-Attention"><a href="#Self-Attention" class="headerlink" title="Self-Attention"></a>Self-Attention</h3><p>Self-Attention 是 Transformer 最核心的内容。下面我们举例进行讲解，比如有一个我们想要翻译的句子：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs text">The animal didn&#x27;t cross the street because it was too tired.<br></code></pre></td></tr></table></figure><p>通过加权之后可以得到类似下图的加权情况：</p><img src="transformer_self-attention_visualization.png" alt="当我们在encoder中编码'it'时, "/><p>在 Self-attention 中，每个单词有3个不同的向量，分别是 Query 向量 (Q), Key 向量 (K) 和 Value 向量 (V)，长度均是64。它们是通过3个不同的权值矩阵由嵌入向量 $X$ 乘以三个不同的权值矩阵 $W^Q,W^K,W^V$ 得到，其中三个矩阵的尺寸也是相同的。均是 $512\times 64$。</p><img src="transformer_self_attention_vectors.png"/><p>$\text{q}_1&#x3D;X_1W^Q,\text{k}_1&#x3D;X_1W^K,\text{v}_1&#x3D;X_1W^V$</p><p>为了理解 Query, Key, Value 的具体意义，我们继续往下看。Attention 的计算方法，整个过程可以分成 7 步。</p><p>1、把输入单词转化为嵌入向量；</p><p>2、根据嵌入向量得到 $\text{q,k,v}$ 三个向量；</p><p>3、为每个向量计算一个 score: $score&#x3D;\text{q}\cdot \text{k}$；</p><p>4、为了梯度的稳定，Transformer 使用了 score 归一化，即除以 $\sqrt{d_k}$；</p><p>5、对 score 施加 softmax 激活函数；</p><p>6、softmax 点乘 Value 值 $\text{v}$，得到加权的每个输入向量的评分 $\text{v}$；</p><p>7、相加得到最终的输出结果 $z&#x3D;\sum v$。</p><p>上面的步骤可以表示为下图的形式：</p><img src="self-attention-output.png" alt="Self-Attention计算示例图"/><p>实际计算过程是分batch，采用基于矩阵的计算方式，论文中的 Q,K,V 的计算方式如图：</p><img src="self-attention-matrix-calculation.png" alt="Q,K,V 计算的矩阵表示"/><p>然后得到的矩阵再进行之前 softmax 计算 score 的步骤：</p><img src="self-attention-matrix-calculation-2.png" alt="矩阵形式的 self-attention"/><p>在self-attention需要强调的最后一点是其采用了残差网络中的short-cut结构，目的当然是解决深度学习中的退化问题，得到的最终结果如图：</p><img src="transformer_resideual_layer_norm.png" alt="残差连接"/><h3 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h3><p>Multi-Head Attention 相当于是 $h$ 个 Attention 模块的集合，这里以 $h&#x3D;8$ 为例，输入一个句子，然后把每个词进行编码，然后分别输入到8个 Attention 中，最后将得到的 $Z$ 矩阵 concat 起来乘以权重 $W^O$，如下图所示：</p><img src="transformer_multi-headed_self-attention-recap.png" alt="Multi-Head Attention"/><h3 id="Encoder-Decoder-Attention"><a href="#Encoder-Decoder-Attention" class="headerlink" title="Encoder-Decoder Attention"></a>Encoder-Decoder Attention</h3><p>在解码器中，Transformer block比编码器中多了个encoder-cecoder attention。在encoder-decoder attention中， $Q$ 来自于解码器的上一个输出， $K$ 和 $V$ 则来自于与编码器的输出。</p><p>由于在机器翻译中，解码过程是一个顺序操作的过程，也就是当解码第 $k$ 个特征向量时，我们只能看到第 $k-1$ 及其之前的解码结果，论文中把这种情况下的 multi-head attention 叫做 masked multi-head attention。</p><h3 id="Full-Transformer"><a href="#Full-Transformer" class="headerlink" title="Full Transformer"></a>Full Transformer</h3><p>一个完整的网络结构便是 Encoder 和 Decoder 的堆叠（各 $N$ 个, $N&#x3D;6$），如图所示：</p><img src="Transformer_Architecture.png"/><h2 id="位置编码"><a href="#位置编码" class="headerlink" title="位置编码"></a>位置编码</h2><p>截止目前为止，我们介绍的Transformer模型并没有捕捉顺序序列的能力，也就是说无论句子的结构怎么打乱，Transformer都会得到类似的结果。换句话说，Transformer只是一个功能更强大的词袋模型而已。</p><p>为了解决这个问题，论文中在编码词向量时引入了位置编码（Position Embedding）的特征。具体地说，位置编码会在词向量中加入了单词的位置信息，这样Transformer就能区分不同位置的单词了。</p><p>那么怎么编码这个位置信息呢？常见的模式有：a. 根据数据学习；b. 自己设计编码规则。在这里作者采用了第二种方式。通常位置编码是一个长度为 $d_{model}$ 的特征向量，这样便于和词向量进行单位加的操作。</p><img src="transformer_positional_encoding_vectors.png" alt="Position Embedding"/><p>论文给出的编码公式如下：<br>$$<br>\begin{aligned}<br>    PE(pos,2i)&amp;&#x3D;\sin (pos&#x2F;10000^{2i&#x2F;d_{model}})\<br>    PE(pos,2i+1)&amp;&#x3D;\cos(pos&#x2F;10000^{2i&#x2F;d_{model}})<br>\end{aligned}<br>$$<br>其中，$pos$ 表示单词的位置，$i$ 表示单词的维度。</p><p>作者这么设计的原因是考虑到在NLP任务中，除了单词的绝对位置，单词的相对位置也非常重要。</p><p>根据公式<br>$$<br>\sin(\alpha+\beta)&#x3D;\sin\alpha\cos\beta+\cos\alpha\sin\beta\<br>cos(\alpha+\beta)&#x3D;\cos\alpha\cos\beta-sin\alpha\sin\beta<br>$$<br>这表明位置 $k+p$ 的位置向量可以表示为位置 $k$ 的特征向量的线性变化，这为模型捕捉单词之间的相对位置关系提供了非常大的便利。（？没有特别搞懂这个，应该是 Linear Combination，而不是线性变化）</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>优点</strong>：</p><p>（1）虽然Transformer最终也没有逃脱传统学习的套路，Transformer也只是一个全连接（或者是一维卷积）加Attention的结合体。但是其设计已经足够有创新，因为其抛弃了在NLP中最根本的RNN或者CNN并且取得了非常不错的效果，算法的设计非常精彩，值得每个深度学习的相关人员仔细研究和品位。</p><p>（2）Transformer的设计最大的带来性能提升的关键是将任意两个单词的距离是1，这对解决NLP中棘手的长期依赖问题是非常有效的。</p><p>（3）Transformer不仅仅可以应用在NLP的机器翻译领域，甚至可以不局限于NLP领域，是非常有科研潜力的一个方向。</p><p>（4）算法的并行性非常好，符合目前的硬件（主要指GPU）环境。</p><p><strong>缺点</strong>：</p><p>（1）粗暴的抛弃RNN和CNN虽然非常炫技，但是它也使模型丧失了捕捉局部特征的能力，RNN + CNN + Transformer的结合可能会带来更好的效果。</p><p>（2）Transformer失去的位置信息其实在NLP中非常重要，而论文中在特征向量中加入Position Embedding也只是一个权宜之计，并没有改变Transformer结构上的固有缺陷。</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li>[1] <a href="https://zhuanlan.zhihu.com/p/48508221">详解Transformer  (知乎)</a></li><li>[2] <a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html">The Annotated Transformer (代码实现教程)</a></li><li>[3] <a href="http://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer (图解Transformer)</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Transformer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch 分布式训练</title>
    <link href="/2022/02/24/DistributedModelTraining/"/>
    <url>/2022/02/24/DistributedModelTraining/</url>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>随着神经网络的参数数量和计算需求的增长，在许多节点和许多GPU上有效并行化神经网络训练变得越来越重要，因为等待大型网络训练数月会减慢实验速度并限制进一步的发展。本文介绍 PyTorch 上进行多机多卡分布式训练的原理和操作方法，以便于训练神经网络时获得显著的性能提升。</p><p>在将神经网络的训练并行化到许多GPU上时，必须选择如何将不同的操作分配到可用的不同GPU上。 在这里，我们重点介绍一种称为数据并行随机梯度下降（SGD）的技术。 与标准SGD中一样，梯度下降是对数据子集（mini-batch）进行的，需要进行多次迭代才能遍历整个数据集。 但是，在数据并行训练中，每个GPU都具有整个神经网络模型的完整副本，并且对于每次迭代，mini-batch中仅分配了样本的子集。 对于每次迭代，每个GPU都会在其数据上进行网络的正向传播和反向传播，以计算相对于网络参数的损耗梯度。</p><p>最后，GPU彼此通信以平均不同GPU计算的梯度，将平均梯度应用于权重以获得新的权重。 所有GPU都以锁定步长(lock-step)进行迭代，一旦GPU完成迭代，它就必须等待所有其他GPU完成迭代，才能正确地更新权重。 这等效于在单个GPU上执行SGD，但是我们通过在多个GPU之间分配数据并并行进行计算来获得加速。</p><h2 id="两种架构"><a href="#两种架构" class="headerlink" title="两种架构"></a>两种架构</h2><h3 id="TreeAllReduce"><a href="#TreeAllReduce" class="headerlink" title="TreeAllReduce"></a>TreeAllReduce</h3><p>这种架构如图所示。采用这种计算模型的分布式，通常会遇到网络的问题，随着 <code>worker</code> 数量的增加，其加速比会迅速地恶化，需要借助其他辅助技术。</p><img src="master-slave-gpus.png"  alt= "Data transfer to and from a single reducer GPU"/><p>由于某一个 <code>GPU</code> 需要接收其他所有 <code>GPU</code> 的梯度，并求平均以及 <code>broadcast</code> 回去，通信成本随 <code>GPU</code> 的数量线性增加。</p><h3 id="RingAllReduce"><a href="#RingAllReduce" class="headerlink" title="RingAllReduce"></a>RingAllReduce</h3><p>这种架构的特点是：通信成本是恒定的，并且与系统中GPU的数量无关，并且仅有系统中GPU之间最慢的连接确定。</p><img src="ring-gpus.png" alt="GPUs arranged in a logical ring"/><p>如图所示，在 <code>RingAllRedce</code> 中，<code>GPU</code> 集群被组织成一个逻辑环，每个 <code>GPU</code> 只从左邻居接受数据、并发送数据给右邻居，即每次同步每个 <code>GPU</code> 只获得部分梯度更新，等一个完整的 <code>Ring</code> 完成，每个 <code>GPU</code> 都获得了完整的参数。</p><p>该算法分两个步骤进行：首先是 scatter reduce，然后是 all gather。在 scatter reduce 步骤中，<code>GPU</code> 将交换数据，以使每个 <code>GPU</code> 获得最终结果的一部分。在 all gather 步骤中，<code>GPU</code> 将交换这些块，以使所有 <code>GPU</code> 获得完整的最终结果。</p><h2 id="详细流程"><a href="#详细流程" class="headerlink" title="详细流程"></a>详细流程</h2><h3 id="The-Scatter-Reduce"><a href="#The-Scatter-Reduce" class="headerlink" title="The Scatter-Reduce"></a>The Scatter-Reduce</h3><p>为了简单起见，我们假设目标是按元素逐个汇总一个大型浮点数数组中的所有元素； 系统中有N个 <code>GPU</code>，每个 <code>GPU</code> 都有一个相同大小的数组，并且在all reduce结束，每个 <code>GPU</code> 都应具有相同大小的数组，其中包含原始数组中数字的总和。</p><p>首先，<code>GPU</code> 将阵列划分为N个较小的块（其中N是环中 <code>GPU</code> 的数量）。</p><img src="array-partition.png" alt="Partitioning of an array into N chunks"/><p>接下来，<code>GPU</code> 将执行 scatter reduce 的 N-1 次迭代； 在每次迭代中，<code>GPU</code> 都会将其块之一发送到其右邻居，并从其左邻居接收一个块，并累积到该块中。 每个GPU发送和接收的块在每次迭代中都不同。 第 N 个GPU从发送块N 和接收块 N – 1 开始，然后从那里向后进行，每次迭代都发送在上一次迭代中接收到的块。</p><p>例如，在第一次迭代中，上图中的五个 <code>GPU</code> 将发送和接收以下块：</p><img src="scatter-reduce-iteration-1.png" alt="Data transfers in the first iteration of scatter-reduce"/><p>在第一个发送和接收完成之后，每个 <code>GPU</code> 将具有一个块，该块由两个不同 <code>GPU</code> 上相同块的总和组成。 例如，第二个 <code>GPU</code> 上的第一个块将是来自第二个 <code>GPU</code> 和第一个 <code>GPU</code> 的那个块中的值之和。</p><img src="scatter-reduce-iteration-2.png" alt="Itermediate sums after the first iteration of scatter-reduce is complete"/><p>在接下来的迭代中，该过程继续进行，到最后，每个 <code>GPU</code> 将具有一个块，其中包含所有 <code>GPU</code> 中该块中所有值的总和。 下图显示了 scatter reduce 完成后的结果。</p><img src="scatter-reduce-iteration-done.png" alt="Final state after all scatter-reduce transfers"/><h3 id="The-Allgather"><a href="#The-Allgather" class="headerlink" title="The Allgather"></a>The Allgather</h3><p>ring allgather 与 scatter reduce 相同（发送和接收进行 N-1 次迭代）相同，除了它们不累积 <code>GPU</code> 接收的值，而是简单地覆盖块。 第 N 个 <code>GPU</code> 首先发送第 N + 1 个块并接收第 N 个块，然后在以后的迭代中始终发送它刚接收的块。</p><p>例如，在我们的五个 <code>GPU</code> 设置的第一个迭代中，<code>GPU</code> 将发送和接收以下块：</p><img src="allgather-iteration-1.png" alt="Data transfers in the first iteration of the allgather"/><p>在接下来的迭代中，该过程继续进行，最后，每个GPU将具有整个阵列的完全累加值。下图显示了 Allgather 完成后的结果。</p><img src="allgather-iteration-done.png" alt="Final state after all allgather transfers"/><h3 id="在深度学习上的应用"><a href="#在深度学习上的应用" class="headerlink" title="在深度学习上的应用"></a>在深度学习上的应用</h3><p>为了最小化通信开销，我们可以利用神经网络的结构。 在每次迭代中，每个GPU都运行正向传播以计算误差，然后运行反向传播以计算神经网络的每个参数的梯度。 反向传播计算从输出层开始并向输入层移动，这意味着输出层参数的梯度在较早层的梯度之前明显可用。 由于Allreduce一次可以对网络参数的一个子集进行操作，因此我们可以在输出层参数上开始Allreduce，而其他梯度仍在计算中。 这样做会使通信与反向传播步骤中的其余计算重叠，从而减少了每个GPU最终等待通信完成的总时间。</p><h2 id="PyTorch-分布式训练"><a href="#PyTorch-分布式训练" class="headerlink" title="PyTorch 分布式训练"></a>PyTorch 分布式训练</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><table><thead><tr><th align="left">概念</th><th>含义</th></tr></thead><tbody><tr><td align="left"><code>group</code></td><td>即进程组。默认情况下，只有一个组，一个 <code>job</code> 即为一个组，也即一个 <code>world</code>。</td></tr><tr><td align="left"><code>world size</code></td><td>表示全局进程个数。</td></tr><tr><td align="left"><code>rank</code></td><td>表示进程序号，用于进程间通讯，表征进程优先级。<code>rank = 0</code> 的主机为 <code>master</code> 节点。</td></tr><tr><td align="left"><code>local_rank</code></td><td>进程内，<code>GPU</code> 编号，非显式参数，由 <code>torch.distributed.launch</code> 内部指定。比方说， <code>rank = 3，local_rank = 0</code> 表示第 <code>3</code> 个进程内的第 <code>1</code> 块 <code>GPU</code>。</td></tr></tbody></table><h3 id="基本使用流程"><a href="#基本使用流程" class="headerlink" title="基本使用流程"></a>基本使用流程</h3><p><code>PyTorch</code> 中分布式的基本使用流程如下：</p><ol><li>在使用 <code>distributed</code> 包的任何其他函数之前，需要使用 <code>init_process_group</code> 初始化进程组，同时初始化 <code>distributed</code> 包。</li><li>如果需要进行小组内集体通信，用 <code>new_group</code> 创建子分组</li><li>创建分布式并行模型 <code>DDP(model, device_ids=device_ids)</code></li><li>为数据集创建 <code>Sampler</code></li></ol><h3 id="重要-API"><a href="#重要-API" class="headerlink" title="重要 API"></a>重要 API</h3><p>过时 API：DataParallel</p><p>这个wrapper能够很方便的使用多张卡，而且将进程控制在一个。唯一的问题就在于，DataParallel只能满足一台机器上gpu的通信，而一台机器一般只能装8张卡，对于一些大任务，8张卡就很吃力了。</p><p>PyTorch 最新版本多机多卡训练的 API 如下：</p><ul><li>torch.nn.parallel.DistributedDataParallel</li></ul><p>​这个包是实现多机多卡分布训练最核心东西，它可以帮助我们在不同机器的多个模型拷贝平均梯度。</p><ul><li>torch.utils.data.distributed.DistributedSampler</li></ul><p>​在多机多卡情况下分布式训练数据的读取也是一个问题，不同的卡读取到的数据应该是不同的。dataparallel的做法是直接将batch切分到不同的卡，这种方法对于多机来说不可取，因为多机之间直接进行数据传输会严重影响效率。于是有了利用sampler确保dataloader只会load到整个数据集的一个特定子集的做法。DistributedSampler就是做这件事的。它为每一个子进程划分出一部分数据集，以避免不同进程之间数据重复。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 分布式训练示例</span><br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">from</span> torch.utils.data.distributed <span class="hljs-keyword">import</span> DistributedSampler<br><span class="hljs-keyword">from</span> torch.nn.parallel <span class="hljs-keyword">import</span> DistributedDataParallel<br><br>dataset = your_dataset()<br>datasampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)<br>dataloader = DataLoader(dataset, batch_size=batch_size_per_gpu, sampler=datasampler)<br>model = your_model()<br>model = DistributedDataPrallel(model, device_ids=[local_rank], output_device=local_rank)<br></code></pre></td></tr></table></figure><p>其他部分就和正常训练代码无异了。</p><p>注意要点：</p><ol><li>和dataparallel不同，dataparallel需要将batchsize设置成n倍的单卡batchsize，而distributedsampler使用的情况下，batchsize设置与单卡设置相同。</li><li>这里有几个新的参数：world size, rank, local rank, rank。world size指进程总数，在这里就是我们使用的卡数；rank指进程序号，local_rank指本地序号，两者的区别在于前者用于进程间通讯，后者用于本地设备分配。</li></ol><h3 id="Slurm-集群训练示例"><a href="#Slurm-集群训练示例" class="headerlink" title="Slurm 集群训练示例"></a>Slurm 集群训练示例</h3><blockquote><p><a href="https://pytorch.org/docs/stable/distributed.html?highlight=nccl">多线程分布式后端</a> 有 gloo, npi, nccl 三种。gloo 基本只支持 cpu，mpi 需要在本地重新编译 PyTorch，nccl 对 GPU 支持良好还不需要重新编译，官方推荐 nccl。</p></blockquote><p>关于获取节点信息的详细代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br>os.environ[<span class="hljs-string">&#x27;SLURM_NTASKS&#x27;</span>]          <span class="hljs-comment">#可用作world size</span><br>os.environ[<span class="hljs-string">&#x27;SLURM_NODEID&#x27;</span>]          <span class="hljs-comment">#node id</span><br>os.environ[<span class="hljs-string">&#x27;SLURM_PROCID&#x27;</span>]          <span class="hljs-comment">#可用作全局rank</span><br>os.environ[<span class="hljs-string">&#x27;SLURM_LOCALID&#x27;</span>]         <span class="hljs-comment">#local_rank</span><br>os.environ[<span class="hljs-string">&#x27;SLURM_STEP_NODELIST&#x27;</span>]   <span class="hljs-comment">#从中取得一个ip作为通讯ip</span><br></code></pre></td></tr></table></figure><p>完整示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br>torch.multiprocessing.set_start_method(<span class="hljs-string">&#x27;spawn&#x27;</span>)<br><br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset, DataLoader<br><span class="hljs-keyword">from</span> torch.utils.data.distributed <span class="hljs-keyword">import</span> DistributedSampler<br><span class="hljs-keyword">from</span> torch.nn.parallel <span class="hljs-keyword">import</span> DistributedDataParallel<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dist_init</span>(<span class="hljs-params">host_addr, rank, local_rank, world_size, port=<span class="hljs-number">23456</span></span>):<br>    host_addr_full = <span class="hljs-string">&#x27;tcp://&#x27;</span> + host_addr + <span class="hljs-string">&#x27;:&#x27;</span> + <span class="hljs-built_in">str</span>(port)<br>    torch.distributed.init_process_group(<span class="hljs-string">&quot;nccl&quot;</span>, init_method=host_addr_full,<br>                                         rank=rank, world_size=world_size)<br>    num_gpus = torch.cuda.device_count()<br>    torch.cuda.set_device(local_rank)<br>    <span class="hljs-keyword">assert</span> torch.distributed.is_initialized()<br><br>rank = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&#x27;SLURM_PROCID&#x27;</span>])<br>local_rank = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&#x27;SLURM_LOCALID&#x27;</span>])<br>world_size = <span class="hljs-built_in">int</span>(os.environ[<span class="hljs-string">&#x27;SLURM_NTASKS&#x27;</span>])<br><span class="hljs-comment"># get_ip函数自己写一下 不同服务器这个字符串形式不一样</span><br><span class="hljs-comment"># 保证所有task拿到的是同一个ip就成</span><br>ip = get_ip(os.environ[<span class="hljs-string">&#x27;SLURM_STEP_NODELIST&#x27;</span>])<br><br>dist_init(ip, rank, local_rank, world_size)<br><br><br><span class="hljs-comment"># 接下来是写dataset和dataloader，这个网上有很多教程</span><br><span class="hljs-comment"># 我这给的也只是个形式，按自己需求写好就ok</span><br>dataset = your_dataset()  <span class="hljs-comment">#主要是把这写好</span><br>datasampler = DistributedSampler(dataset, num_replicas=world_size, rank=rank)<br>dataloader = DataLoader(dataset, batch_size=batch_size_per_gpu, sampler=source_sampler)<br><br>model = your_model()     <span class="hljs-comment">#也是按自己的模型写</span><br>model = DistributedDataPrallel(model, device_ids=[local_rank], output_device=local_rank)<br><br><span class="hljs-comment"># 此后训练流程与普通模型无异</span><br></code></pre></td></tr></table></figure><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><p>[1] <a href="https://andrew.gibiansky.com/blog/machine-learning/baidu-allreduce/">Bringing HPC Techniques to Deep Learning</a></p></li><li><p>[2] <a href="https://zhuanlan.zhihu.com/p/126754580">Bringing HPC Techniques to Deep Learning (翻译)</a></p></li><li><p>[3] <a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html#">Getting Started With Distributed Data Parallel (PyTorch Tutorial)</a></p></li><li><p>[4] <a href="https://zhuanlan.zhihu.com/p/68717029">Pytorch多机多卡分布式训练</a></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Coding</category>
      
      <category>PyTorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Distribute</tag>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读：Deep Residual Learning for Image Recognition</title>
    <link href="/2022/02/23/ResNet/"/>
    <url>/2022/02/23/ResNet/</url>
    
    <content type="html"><![CDATA[<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>深度神经网络以端到端的多层网络方式整合低&#x2F;中&#x2F;高级别特征。在一个深层次的卷积网络中，每一层学到的特征不尽相同且越深的部分学到的feature越细节。网络的深度对于模型表现至关重要。</p><p>但是随着网络加深，会有以下几个问题：</p><ul><li>梯度消失&#x2F;爆炸</li><li>过拟合</li><li>模型退化</li></ul><p>前两个比较好理解，对于梯度消失&#x2F;爆炸，网络更新是通过梯度的BP，也就是通过链式求导一个一个乘上去，如果里面都小于1，很多项之后就会趋于0，反之也好理解(当然这只是一种情况)。这个问题随着 normalized 初始化和 中间 normalization 层的引入，很大程度上被解决了。</p><p>对于第二个过拟合，就是网络层数增多之后，网络会变复杂，参数变多，如果数据量不能和这个匹配上就会出现过拟合，也就是说在训练集上过度学习和拟合，在测试集上缺少泛化能力。</p><p>第三个这里要着重讲一下，<strong>退化</strong> ，情况如下图所示。</p><img src="Fig1.png" style="zoom:67%;" /><p>可以看到随着层数的增加，不仅test上的loss增加，train上的也增加，这就是degradation现象，区别于过拟合。</p><p>所以，作者提出了残差结构，如下图所示：</p><img src="Fig2.png" style="zoom:67%;" /><p>最初我们要拟合的是一个潜在映射 $\mathcal{H}(\textbf{x})$，现在我们堆叠的非线性层拟合另外一个映射 $\mathcal{F}(\textbf{x})&#x3D;\mathcal{H}(\textbf{x})-\textbf{x}$，所以原来我们要拟合的映射也就是 $\mathcal{F}(\textbf{x})+\textbf{x}$。</p><p>假设这个映射比原映射更容易优化，极端地说：如果 identity map 是最佳情况的话，那么把残差块优化到一个全0映射更加简单。</p><blockquote><p>To the extreme, if an identity mapping were optimal, it would be easier to push the residual to zero than to fit an identity mapping by a stack of nonlinear layers.</p></blockquote><h2 id="Deep-Residual-Learning"><a href="#Deep-Residual-Learning" class="headerlink" title="Deep Residual Learning"></a>Deep Residual Learning</h2><h3 id="Residual-learning"><a href="#Residual-learning" class="headerlink" title="Residual learning"></a>Residual learning</h3><p>如果假设多个非线性层能够渐进一个复杂函数，那么多个非线性层也能渐进残差函数 $\mathcal{H}(\textbf{x})-\textbf{x}$。</p><p>所以残差学习部分由学习函数 $\mathcal{H}(\textbf{x})$ 转化为学习 $\mathcal{H}(\textbf{x})-\textbf{x}$，新的函数比较容易学习，原因有以下几点：</p><ul><li>如果一致性映射 (Identity Mapping) 是最优的，那么 $\mathcal{F}(\textbf{x})\approx0$，更好拟合。</li><li>改为残差学习的方式后，原本的映射会对输出的变化更加敏感。</li><li>求导可以发现，梯度是 $\mathcal{F}’(\textbf{x})+1$，这部分几乎不会一直为0，所以梯度更新更顺畅。</li></ul><h3 id="Identity-Mapping-by-Shortcuts"><a href="#Identity-Mapping-by-Shortcuts" class="headerlink" title="Identity Mapping by Shortcuts"></a>Identity Mapping by Shortcuts</h3><p>$$<br>\textbf{y}&#x3D;\mathcal{F}(\textbf{x},{W_i})+\textbf{x}<br>$$</p><p>$\mathcal{F}(\textbf{x},{W_i})$ 是学习的残差映射。</p><p>这里需要注意的就是，后面加上的shortcut前面可以也加上对应的权重，也就是下面的形式：<br>$$<br>\textbf{y}&#x3D;\mathcal{F}(\textbf{x},{W_i})+W_s\textbf{x}<br>$$<br>但是经过实验，加上权重并不能让结果变好，因此，就算加权重，也是为了dimensions上的一致性。</p><h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><img src="Fig3.png"/><h3 id="进一步优化"><a href="#进一步优化" class="headerlink" title="进一步优化"></a>进一步优化</h3><p>为了减少实际运算的时间成本，作者将原来的残差学习结构改为瓶颈结构(bottleneck)，如下图。</p><img src="Fig4.png" style="zoom:67%;" /><p>通过在首尾使用1x1 conv来巧妙地缩减或扩张feature map维度，得我们的3x3 conv的filters数目不受外界即上一层输入的影响，自然它的输出也不会影响到下一层module。</p><p>这两种结构的时间复杂度相似。此时投影法映射带来的参数成为不可忽略的部分（因为输入维度的增大），所以要使用zero padding的恒等映射。bottleneck替换原本ResNet的残差学习结构buliding block，网络深度得以增加。</p>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Residual Block</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读：Non-local Neural Networks</title>
    <link href="/2022/02/22/Non-local-Neural-Network/"/>
    <url>/2022/02/22/Non-local-Neural-Network/</url>
    
    <content type="html"><![CDATA[<h3 id="Local-amp-Non-local"><a href="#Local-amp-Non-local" class="headerlink" title="Local &amp; Non-local"></a>Local &amp; Non-local</h3><p>Local这个词主要是针对感受野(receptive field)来说的。以卷积操作为例，它的感受野大小就是卷积核大小，而我们一般都选用3*3，5*5之类的卷积核，它们只考虑局部区域，因此都是local的运算。同理，池化(Pooling)也是。相反的，non-local指的就是感受野可以很大，而不是一个局部领域。</p><p>那我们碰到过什么non-local的操作吗？有的，全连接就是non-local的，而且是global的。但是全连接带来了大量的参数，给优化带来困难。这也是深度学习(主要指卷积神经网络)近年来流行的原因，考虑局部区域，参数大大减少了，能够训得动了。</p><p>那我们为什么还需要non-local？</p><p>我们知道，卷积层的堆叠可以增大感受野，但是如果看特定层的卷积核在原图上的感受野，它毕竟是有限的。这是local运算不能避免的。然而有些任务，它们可能需要原图上更多的信息，比如attention。如果在某些层能够引入全局的信息，就能很好地解决local操作无法看清全局的情况，为后面的层带去更丰富的信息。</p><h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><p>A generic non-local operation in deep neural networks.<br>$$<br>y_i&#x3D;\frac{1}{\mathcal{C}(x)}\sum\limits_{\forall j}f(x_i,x_j)g(x_j)<br>$$<br>这里 $i$ 是输出位置的索引，$j$ 是所有可能的位置。$x$ 是输入信号，$y$ 是和 $x$ 具有相同大小的输出信号。$f(\cdot)$ 计算 $i$ 和所有 $j$ 之间的相关性。一元函数 $g(\cdot)$ 计算位置 $j$ 作为输入信号的表示。最后的输出由 $\mathcal{C}(x)$ normalize。</p><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><h4 id="Gaussian"><a href="#Gaussian" class="headerlink" title="Gaussian"></a>Gaussian</h4><p>$$<br>f(x_i,x_j)&#x3D;exp(x_i^Tx_j)<br>$$</p><p>这里 $x_i^Tx_j$ 是点乘相似度。规范化因子 $\mathcal{C}(x)&#x3D;\sum_{\forall j}f(x_i,x_j)$。<br>$$<br>y_i&#x3D;\frac{1}{\sum_{\forall j}f(x_i,x_j)}\sum\limits_{\forall j}exp(x_i^Tx_j)g(x_j)<br>$$</p><h4 id="Embedded-Gaussian"><a href="#Embedded-Gaussian" class="headerlink" title="Embedded Gaussian"></a>Embedded Gaussian</h4><p>Gaussian 公式的扩展，在嵌入空间 (embedding space) 中计算相似度。<br>$$<br>f(x_i,x_j)&#x3D;exp(\theta(x_i)^T\phi(x_j))<br>$$<br>其中 $\theta(x_i)&#x3D;W_\theta x_i$，$\phi(x_j)&#x3D;W_\phi x_j$。规范化因子 $\mathcal{C}(x)&#x3D;\sum_{\forall j}f(x_i,x_j)$。<br>$$<br>y_i&#x3D;\frac{1}{\sum_{\forall j}f(x_i,x_j)}\sum\limits_{\forall j}exp(\theta(x_i)^T\phi(x_j))g(x_j)<br>$$<br>self-attention 可以视为该公式的扩展，$\frac{1}{\mathcal{C}(x)}f(x_i,x_j)$ 变为 $j$ 维的 softmax 计算：<br>$$<br>y&#x3D;softmax(x^TW^T_\theta W_\phi x)g(x)<br>$$</p><h4 id="Dot-product"><a href="#Dot-product" class="headerlink" title="Dot product"></a>Dot product</h4><p>$$<br>f(x_i,x_j)&#x3D;\theta(x_i)^T\phi(x_j)<br>$$</p><p>规范化因子 $\mathcal{C}(x)&#x3D;N$。$N$ 是 x 的维度而不是 $f(\cdot)$ 的和。</p><p>这种计算方法简化了梯度计算。</p><blockquote><p>A normalization like this is necessary because the input can have variable size.</p></blockquote><p>因为这样，输入可以有一个可变的大小，这种规范化是必要的。<br>$$<br>y&#x3D;\frac{1}{N}\sum\limits_{\forall j}(\theta(x_i)^T\phi(x_j))g(x_j)<br>$$</p><h4 id="Concatenation"><a href="#Concatenation" class="headerlink" title="Concatenation"></a>Concatenation</h4><p>$$<br>f(x_i,x_j)&#x3D;\text{ReLU}(\textbf{w}_f^T[\theta(x_i),\phi(x_j)])<br>$$</p><p>这里 $[\cdot,\cdot]$ 表示 concatenation，$\textbf{w}<em>f$ 是把连接向量映射成标量的权重向量。规范化因子 $\mathcal{C}(x)&#x3D;N$。<br>$$<br>y&#x3D;\frac{1}{N}\sum\limits</em>{\forall j}(\text{ReLU}(\textbf{w}_f^T[\theta(x_i),\phi(x_j)]))g(x_j)<br>$$</p><ul><li>后两种选择的归一化系数$\mathcal{C}(x)$选择为$x$的点数，只是为了简化计算，同时，还能保证对任意尺寸的输入，不会产生数值上的尺度伸缩。</li><li>Embedding的实现方式，以图像为例，在文章中都采用1*1的卷积，也就是 $\theta$ 和 $\phi$ 都是卷积操作。</li></ul><p>为了能让non-local操作作为一个组件，可以直接插入任意的神经网络中，作者把non-local设计成residual block的形式，让non-local操作去学x的residual：<br>$$<br>\textbf{z}_i&#x3D;W_z \textbf{y}_i+\textbf{x}_i<br>$$<br>$W_z$ 实际上是一个卷积操作，它的输出 channel 和 $\textbf{x}$ 一致。这样一来，non-local 操作就可以作为一个组件，组装到任意卷积神经网络中。</p><h3 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h3><p>$f(\cdot)$ 的计算其实是相似性计算，可以转化成矩阵运算。整个 non-local 运算可以化为矩阵乘法运算 + 卷积运算，如图所示，其中 oc 为 output_channels。</p><img src="network.png"/><p>原文考虑的是T帧的视频为例，这里以一个batch的图像、$f(\cdot)$选为embedded Gaussian为例，对于其他形式的相似性度量，可以类似地化为矩阵操作。N 是 batchsize，H,W 是高和宽，C 是 channel。</p><p>左边 softmax 之前的部分都是为了计算相似度，右边卷积计算之后直接和相似度进行相乘。</p><h3 id="Relations"><a href="#Relations" class="headerlink" title="Relations"></a>Relations</h3><h4 id="与全连接层的联系"><a href="#与全连接层的联系" class="headerlink" title="与全连接层的联系"></a>与全连接层的联系</h4><ul><li>全连接层的权重在输入与输出之间，而 non-local 计算的是输入层之间的相互关系。</li></ul><ul><li>g是identity函数，$g(x_i)&#x3D;x_i$。</li><li>归一化系数为1。归一化系数跟输入无关，全连接层不能处理任意尺寸的输入。</li></ul><h4 id="与-Self-attention-的联系"><a href="#与-Self-attention-的联系" class="headerlink" title="与 Self-attention 的联系"></a>与 Self-attention 的联系</h4><p>Embedding 的 1*1 卷积操作可以看成矩阵乘法。<br>$$<br>\begin{aligned}<br>    \theta(x_i)&#x3D;W_\theta\cdot x_i &amp;\Longrightarrow \theta(x)&#x3D;W_\theta\cdot x\<br>    \phi(x_j)&#x3D;W_\phi\cdot x_j &amp;\Longrightarrow \phi(x)&#x3D;W_\phi\cdot x<br>\end{aligned}<br>$$<br>所以<br>$$<br>y&#x3D;softmax(x^TW^T_\theta W_\phi x)g(x)<br>$$</p>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Attention</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python装饰器和functools.wraps简单解析</title>
    <link href="/2022/02/19/Python-decorator/"/>
    <url>/2022/02/19/Python-decorator/</url>
    
    <content type="html"><![CDATA[<h3 id="装饰器实例"><a href="#装饰器实例" class="headerlink" title="装饰器实例"></a>装饰器实例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">timer</span>(<span class="hljs-params">func</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">wrapper</span>(<span class="hljs-params">*args, **kwargs</span>):<br>        start = time.time()<br>        func(*args, **kwargs) <span class="hljs-comment">#此处拿到了被装饰的函数func</span><br>        time.sleep(<span class="hljs-number">2</span>)<span class="hljs-comment">#模拟耗时操作</span><br>        long = time.time() - start<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;共耗时<span class="hljs-subst">&#123;long&#125;</span>秒。&#x27;</span>)<br>    <span class="hljs-keyword">return</span> wrapper <span class="hljs-comment">#返回内层函数的引用</span><br><br><span class="hljs-meta">@timer</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">a, b</span>):<br>    <span class="hljs-built_in">print</span>(a+b)<br><br>add(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>) <span class="hljs-comment">#正常调用add</span><br></code></pre></td></tr></table></figure><p>“@”是Python的语法糖，它的作用类似于：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">add = timer(add) <span class="hljs-comment">#此处返回的是timer.&lt;locals&gt;.wrapper函数引用</span><br>add(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br></code></pre></td></tr></table></figure><p>装饰器的加载到执行的流程：</p><p><strong>模块加载 -&gt;&gt; 遇到@，执行timer函数，传入add函数 -&gt;&gt; 生成timer.&lt;locals&gt;.wrapper函数并命名为add，其实是覆盖了原同名函数 -&gt;&gt; 调用add(1, 2) -&gt;&gt; 去执行timer.&lt;locals&gt;.wrapper(1, 2) -&gt;&gt; wrapper内部持有原add函数引用(func)，调用func(1, 2) -&gt;&gt;继续执行完wrapper函数</strong></p><h3 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h3><p>对于上述实例，可以看做是对 add() 函数添加了一个名称为 timer() 的修饰，并将 add() 作为函数参数传给 timer。timer() 内部定义了新参数并接受 add() 的参数，再执行内部 return 的 wrapper 函数。</p><h3 id="functools-wraps-解读"><a href="#functools-wraps-解读" class="headerlink" title="functools.wraps 解读"></a>functools.wraps 解读</h3><p>functools模块提供了一系列的高阶函数以及对可调用对象的操作，其中为人熟知的有reduce，partial，wraps等。</p><p>为了保证被装饰器装饰后的函数还拥有原来的属性，wraps通过partial以及update_wrapper来实现。</p><p>我们先来了解一下partial，partial用于部分应用一个函数，它基于一个函数创建一个可调用对象，把原函数的某些参数固定，调用时只需要传递未固定的参数即可。</p><p>我们先看partial如何使用：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> functools<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">a, b</span>):<br>    <span class="hljs-built_in">print</span>(a + b)<br><br><br>add = functools.partial(add, <span class="hljs-number">1</span>)<br>add(<span class="hljs-number">2</span>)<br><br>输出：<span class="hljs-number">3</span><br></code></pre></td></tr></table></figure><p>add函数原本接收两个参数a和b，经过partial包装之后，a参数的值被固定为了1，新的add对象（注意此处add已经是一个可调用对象，而非函数，下文分析源码会看到）只需要接收一个参数即可。</p><p>通俗点说：<strong>就是把原函数的部分参数固定了初始值，新的调用只需要传递其它参数。</strong></p><p>下面来分析partial的源码（Python3.7），只摘录了核心部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">partial</span>:<br>    <span class="hljs-string">&quot;&quot;&quot;New function with partial application of the given arguments</span><br><span class="hljs-string">    and keywords.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    __slots__ = <span class="hljs-string">&quot;func&quot;</span>, <span class="hljs-string">&quot;args&quot;</span>, <span class="hljs-string">&quot;keywords&quot;</span>, <span class="hljs-string">&quot;__dict__&quot;</span>, <span class="hljs-string">&quot;__weakref__&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__new__</span>(<span class="hljs-params">*args, **keywords</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> args:<br>            <span class="hljs-keyword">raise</span> TypeError(<span class="hljs-string">&quot;descriptor &#x27;__new__&#x27; of partial needs an argument&quot;</span>)<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(args) &lt; <span class="hljs-number">2</span>:<br>            <span class="hljs-keyword">raise</span> TypeError(<span class="hljs-string">&quot;type &#x27;partial&#x27; takes at least one argument&quot;</span>)<br>        cls, func, *args = args<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-built_in">callable</span>(func):<br>            <span class="hljs-keyword">raise</span> TypeError(<span class="hljs-string">&quot;the first argument must be callable&quot;</span>)<br>        args = <span class="hljs-built_in">tuple</span>(args)<br><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(func, <span class="hljs-string">&quot;func&quot;</span>):<br>            args = func.args + args<br>            tmpkw = func.keywords.copy()<br>            tmpkw.update(keywords)<br>            keywords = tmpkw<br>            <span class="hljs-keyword">del</span> tmpkw<br>            func = func.func<br><br>        self = <span class="hljs-built_in">super</span>(partial, cls).__new__(cls)<br><br>        self.func = func<br>        self.args = args<br>        self.keywords = keywords<br>        <span class="hljs-keyword">return</span> self<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">*args, **keywords</span>):<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> args:<br>            <span class="hljs-keyword">raise</span> TypeError(<span class="hljs-string">&quot;descriptor &#x27;__call__&#x27; of partial needs an argument&quot;</span>)<br>        self, *args = args<br>        newkeywords = self.keywords.copy()<br>        newkeywords.update(keywords)<br>        <span class="hljs-keyword">return</span> self.func(*self.args, *args, **newkeywords)<br></code></pre></td></tr></table></figure><p>通过重写“_<em>new</em>__”方法，自定义对象实例化过程。</p><p>1、元组拆包，获取到传入的原函数（func）和需要固定的参数（args）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">cls, func, *args = args<br></code></pre></td></tr></table></figure><p>2、主要是为了支持嵌套调用，即add&#x3D;partial(partial(add,1),2)这种情况，可先看第三步，回过头再来看</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> <span class="hljs-built_in">hasattr</span>(func, <span class="hljs-string">&quot;func&quot;</span>):<br>    args = func.args + args<br>    tmpkw = func.keywords.copy()<br>    tmpkw.update(keywords)<br>    keywords = tmpkw<br>    <span class="hljs-keyword">del</span> tmpkw<br>    func = func.func<br></code></pre></td></tr></table></figure><p>3、实例化partial对象，将传入的函数和参数设置为当前对象的属性</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">self = <span class="hljs-built_in">super</span>(partial, cls).__new__(cls)<br><br>self.func = func<br>self.args = args<br>self.keywords = keywords<br><span class="hljs-keyword">return</span> self<br></code></pre></td></tr></table></figure><p>到这里我们已经明白了partial是怎么保存原函数和固定参数的了，下面来看一下调用的时候是如何执行的。</p><p>先简单了解一下可调用对象：<strong>当一个类实现了”__<em>call</em>__“方法后，这个类的对象就能够像函数一样被调用。</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Callable</span>:<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, a, b</span>):<br>        <span class="hljs-keyword">return</span> a + b<br><br><br>func = <span class="hljs-type">Callable</span>()  <br>result = func(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>) <span class="hljs-comment"># 像函数一样调用</span><br><span class="hljs-built_in">print</span>(result)<br><br>输出：<span class="hljs-number">5</span><br></code></pre></td></tr></table></figure><p>我们看下partial的”__<em>call</em>__“是如何实现的：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">*args, **keywords</span>):<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> args:<br>        <span class="hljs-keyword">raise</span> TypeError(<span class="hljs-string">&quot;descriptor &#x27;__call__&#x27; of partial needs an argument&quot;</span>)<br>    self, *args = args<br>    newkeywords = self.keywords.copy()<br>    newkeywords.update(keywords)<br>    <span class="hljs-keyword">return</span> self.func(*self.args, *args, **newkeywords)<br></code></pre></td></tr></table></figure><p>1、元组拆包，获取到传入的非固定参数args</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">self, *args = args<br></code></pre></td></tr></table></figure><p>2、拷贝当前对象的keywords参数，并且合并传入的非固定参数字典</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">newkeywords = self.keywords.copy()<br>newkeywords.update(keywords)<br></code></pre></td></tr></table></figure><p>3、调用当前对象的func属性，func即被partial包装的原函数，同时传入暂存的固定参数self.args以及新传入的其它参数。</p><p>至此一切真相大白：<strong>partial通过实现”__new__“和”__call__“生成一个可调用对象，这个对象内部保存了被包装函数以及固定参数，这个对象可以像函数一样被调用，调用时，其实是执行了对象内部持有的被包装函数，其参数由固定参数和新传入的参数组合而来。</strong></p><p>继续探索wraps的源码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">wraps</span>(<span class="hljs-params">wrapped,</span><br><span class="hljs-params">          assigned = WRAPPER_ASSIGNMENTS,</span><br><span class="hljs-params">          updated = WRAPPER_UPDATES</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Decorator factory to apply update_wrapper() to a wrapper function</span><br><span class="hljs-string"></span><br><span class="hljs-string">       Returns a decorator that invokes update_wrapper() with the decorated</span><br><span class="hljs-string">       function as the wrapper argument and the arguments to wraps() as the</span><br><span class="hljs-string">       remaining arguments. Default arguments are as for update_wrapper().</span><br><span class="hljs-string">       This is a convenience function to simplify applying partial() to</span><br><span class="hljs-string">       update_wrapper().</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> partial(update_wrapper, wrapped=wrapped,<br>                   assigned=assigned, updated=updated)<br></code></pre></td></tr></table></figure><p>入参解读：</p><p>wrapped：指被装饰器装饰的原函数，我们的装饰器便是要拷贝它的属性。</p><p>assigned：要被重新赋值的属性列表，默认为WRAPPER_ASSIGNMENTS，可自定义传入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">WRAPPER_ASSIGNMENTS = (<span class="hljs-string">&#x27;__module__&#x27;</span>, <span class="hljs-string">&#x27;__name__&#x27;</span>, <span class="hljs-string">&#x27;__qualname__&#x27;</span>, <span class="hljs-string">&#x27;__doc__&#x27;</span>,<br>                       <span class="hljs-string">&#x27;__annotations__&#x27;</span>)<br></code></pre></td></tr></table></figure><p>updated：要被合并的属性列表，默认为WRAPPER_UPDATES，可自定义传入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">WRAPPER_UPDATES = (<span class="hljs-string">&#x27;__dict__&#x27;</span>,)<br></code></pre></td></tr></table></figure><p>返回值：</p><p>返回了一个partial对象，这个对象对update_wrapper进行了包装，固定了wrapped，assigned，updated三个参数。</p><p>wraps本省就是一个装饰器，因为它返回的是一个“函数”即partial对象，这个对象接收函数作为参数，同时以函数作为返回值。</p><p>接下来看update_wrapper：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">update_wrapper</span>(<span class="hljs-params">wrapper,</span><br><span class="hljs-params">                   wrapped,</span><br><span class="hljs-params">                   assigned = WRAPPER_ASSIGNMENTS,</span><br><span class="hljs-params">                   updated = WRAPPER_UPDATES</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Update a wrapper function to look like the wrapped function</span><br><span class="hljs-string"></span><br><span class="hljs-string">       wrapper is the function to be updated</span><br><span class="hljs-string">       wrapped is the original function</span><br><span class="hljs-string">       assigned is a tuple naming the attributes assigned directly</span><br><span class="hljs-string">       from the wrapped function to the wrapper function (defaults to</span><br><span class="hljs-string">       functools.WRAPPER_ASSIGNMENTS)</span><br><span class="hljs-string">       updated is a tuple naming the attributes of the wrapper that</span><br><span class="hljs-string">       are updated with the corresponding attribute from the wrapped</span><br><span class="hljs-string">       function (defaults to functools.WRAPPER_UPDATES)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">for</span> attr <span class="hljs-keyword">in</span> assigned:<br>        <span class="hljs-keyword">try</span>:<br>            value = <span class="hljs-built_in">getattr</span>(wrapped, attr)<br>        <span class="hljs-keyword">except</span> AttributeError:<br>            <span class="hljs-keyword">pass</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-built_in">setattr</span>(wrapper, attr, value)<br>    <span class="hljs-keyword">for</span> attr <span class="hljs-keyword">in</span> updated:<br>        <span class="hljs-built_in">getattr</span>(wrapper, attr).update(<span class="hljs-built_in">getattr</span>(wrapped, attr, &#123;&#125;))<br>    <span class="hljs-comment"># Issue #17482: set __wrapped__ last so we don&#x27;t inadvertently copy it</span><br>    <span class="hljs-comment"># from the wrapped function when updating __dict__</span><br>    wrapper.__wrapped__ = wrapped<br>    <span class="hljs-comment"># Return the wrapper so this can be used as a decorator via partial()</span><br>    <span class="hljs-keyword">return</span> wrapper<br></code></pre></td></tr></table></figure><p>这个便是解析@functools.wraps(func)时最底层执行的逻辑，代码很简洁，就是把wrapped函数的属性拷贝到wrapper函数中。</p><p><strong>wrapped是被装饰的原函数</strong></p><p><strong>wrapper是被装饰器装饰后的新函数。</strong></p><p>通过下面的例子对执行过程和参数进行对号入座</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">outer</span>(<span class="hljs-params">func</span>):<br><span class="hljs-meta">    @functools.wraps(<span class="hljs-params">func</span>)</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">inner</span>(<span class="hljs-params">*args, **kwargs</span>):<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;before...&quot;</span>)<br>        func(*args, **kwargs)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;after...&quot;</span>)<br><br>    <span class="hljs-keyword">return</span> inner<br><br><br><span class="hljs-meta">@outer</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">add</span>(<span class="hljs-params">a, b</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    求和运算</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-built_in">print</span>(a + b)<br></code></pre></td></tr></table></figure><p>1、原函数为add。</p><p>2、@outer会去执行outer装饰器，传入add函数，返回一个inner函数。</p><p>3、执行outer函数时，加载inner函数，此时会直接执行functools.wraps(func)返回一个可调用对象，即partial对象。</p><p>4、此时inner的装饰器实际上是@partial，partial会被调用，传入inner函数，执行partial内部的update_wrapper函数，将func的相应属性拷贝给inner函数，最后返回inner函数。这一步并没有生成新的函数，仅仅是改变了inner函数的属性。</p><p>5、把add指向inner函数。</p><p>6、调用add实际调用的是inner函数，inner函数内部持有原add函数的引用即func。</p><p><strong>update_wrapper函数参数对应：</strong></p><p><strong>wrapper指的是inner函数</strong></p><p><strong>wrapped指的是func即原始的add函数</strong></p><p><strong>总结：</strong></p><p><strong>1）functools.wraps 旨在消除装饰器对原函数造成的影响，即对原函数的相关属性进行拷贝，已达到装饰器不修改原函数的目的。</strong></p><p><strong>2）wraps内部通过partial对象和update_wrapper函数实现。</strong></p><p><strong>3）partial是一个类，通过实现了双下方法new，自定义实例化对象过程，使得对象内部保留原函数和固定参数，通过实现双下方法call，使得对象可以像函数一样被调用，再通过内部保留的原函数和固定参数以及传入的其它参数进行原函数调用。</strong></p>]]></content>
    
    
    <categories>
      
      <category>Coding</category>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>functools</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python format 字符串格式化函数</title>
    <link href="/2022/02/18/Python-format/"/>
    <url>/2022/02/18/Python-format/</url>
    
    <content type="html"><![CDATA[<p>基本语法是通过 **{} 和 <strong>:</strong> 来代替以前的 <strong>%</strong> 。</p><p>format 函数可以接受不限个参数，位置可以不按顺序。</p><p>冒号后跟格式条件</p><ul><li>先跟对齐方式： 左’&lt;’，右’&gt; ‘, 居中’ ^ ’<ul><li><code>&#123;:&lt;&#125;.format(&#39;test&#39;)</code></li><li><code>&#123;:&gt;&#125;.format(&#39;test&#39;)</code></li><li><code>&#123;:^&#125;.format(&#39;test&#39;)</code></li></ul></li><li>再跟补位符号：只能是一个字符，不指定则默认是用空格填充<ul><li><code>&#123;: 3&#125;.format(3.1)</code></li><li><code>&#123;:03&#125;.format(3.1)</code></li></ul></li><li>再跟宽度：数字<ul><li><code>&#123;:03&#125;.format(3.11)</code></li></ul></li><li>再跟精度或格式：<ul><li>精度：点加数字加ｆ<ul><li><code>&#123;:.2f&#125;.fotmat(3.14159)</code></li></ul></li><li>格式：各种进制转化，＃表示加格式头<ul><li>b、d、o、x 分别是二进制</li><li><code>&#123;:#d&#125;.format(11)</code></li></ul></li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;&#123;:.2f&#125;,&#123;:.3f&#125;&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-number">3.1415926</span>,<span class="hljs-number">3.1</span>))<br></code></pre></td></tr></table></figure><p>示例：</p><table><thead><tr><th align="left">数字</th><th align="left">格式</th><th align="left">输出</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">3.1415926</td><td align="left">{:.2f}</td><td align="left">3.14</td><td align="left">保留小数点后两位</td></tr><tr><td align="left">3.1415926</td><td align="left">{:+.2f}</td><td align="left">+3.14</td><td align="left">带符号保留小数点后两位</td></tr><tr><td align="left">-1</td><td align="left">{:+.2f}</td><td align="left">-1.00</td><td align="left">带符号保留小数点后两位</td></tr><tr><td align="left">2.71828</td><td align="left">{:.0f}</td><td align="left">3</td><td align="left">不带小数</td></tr><tr><td align="left">5</td><td align="left">{:0&gt;2d}</td><td align="left">05</td><td align="left">数字补零 (填充左边, 宽度为2)</td></tr><tr><td align="left">5</td><td align="left">{:x&lt;4d}</td><td align="left">5xxx</td><td align="left">数字补x (填充右边, 宽度为4)</td></tr><tr><td align="left">10</td><td align="left">{:x&lt;4d}</td><td align="left">10xx</td><td align="left">数字补x (填充右边, 宽度为4)</td></tr><tr><td align="left">1000000</td><td align="left">{:,}</td><td align="left">1,000,000</td><td align="left">以逗号分隔的数字格式</td></tr><tr><td align="left">0.25</td><td align="left">{:.2%}</td><td align="left">25.00%</td><td align="left">百分比格式</td></tr><tr><td align="left">1000000000</td><td align="left">{:.2e}</td><td align="left">1.00e+09</td><td align="left">指数记法</td></tr><tr><td align="left">13</td><td align="left">{:&gt;10d}</td><td align="left">13</td><td align="left">右对齐 (默认, 宽度为10)</td></tr><tr><td align="left">13</td><td align="left">{:&lt;10d}</td><td align="left">13</td><td align="left">左对齐 (宽度为10)</td></tr><tr><td align="left">13</td><td align="left">{:^10d}</td><td align="left">13</td><td align="left">中间对齐 (宽度为10)</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>Coding</category>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Domain Adaptation 简介</title>
    <link href="/2022/02/17/BriefIntroductionOfDomainAdaptation/"/>
    <url>/2022/02/17/BriefIntroductionOfDomainAdaptation/</url>
    
    <content type="html"><![CDATA[<p><em><strong>领域自适应</strong></em> 即 <em><strong>Domain Adaptation</strong></em>是迁移学习中很重要的一部分内容，目的是把分布不同的源域和目标域的数据，映射到一个特征空间中，使其在该空间中的距离尽可能近。于是在特征空间中对source domain训练的目标函数，就可以迁移到target domain上，提高target domain上的准确率。</p><hr><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>GAN (Generate Adversarial Network) 是基于对抗的生成网络，主要目标是生成与训练集分布一致的数据。在迁移学习领域，对抗也是一种常用的方式。如 Ganin <a href="#refer-anchor-1">[1]</a> 的论文，使用的网络由三部分组成：特征映射网络 $G_f(x;\theta_f)$，标签分类网络 $G_y(z;\theta_y)$ 和域判别网络 $G_d(z;\theta_d)$。</p><p>其中，source domain 的数据是有标签的，target domain 的数据是无标签的。$G_f$ 将 source 和 target domain 的数据都映射到一个特征空间 $Z$ 上，$G_y$ 预测标签 $y$，$G_d$ 预测数据来自于 target 还是 source domain。所以流入 $G_y$ 的是带标签的 source 数据，流入 $G_d$ 的是不带标签的 source 和 target 的数据。</p><p>$G_f$：将数据映射到 feature space，使 $G_y$ 能分辨出 source domain 数据的 label，$G_d$ 分辨不出数据来自 source domain 还是 target domain。</p><p>$G_y$：对 feature space 的 source domain 数据进行分类，尽可能分出正确的 label。</p><p>$G_d$：对 feature space 的数据进行领域分类，尽量分辨出数据来自于哪一个 domain。</p><p>最终，期望 $G_f$ 和 $G_d$ 博弈的结果是 source 和 target domain 的数据在 feature space 上分布已经很一致，$G_d$ 无法区分。于是，可以直接使用 $G_y$。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><div id="refer-anchor-1"><div>- [1] [Ganin Y, Lempitsky V. Unsupervised domain adaptation by backpropagation[C]//International conference on machine learning. PMLR, 2015: 1180-1189.](http://proceedings.mlr.press/v37/ganin15.html)]]></content>
    
    
    <categories>
      
      <category>Transfer Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Domain Adaptation</tag>
      
      <tag>Transfer Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Histogram of oriented gradient, HOG</title>
    <link href="/2022/01/20/HOG/"/>
    <url>/2022/01/20/HOG/</url>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>方向梯度直方图 (Histogram of oriented gradient, HOG) 是应用在计算机视觉和图像处理领域，用于目标检测的特征描述器。这项技术是用来计算局部图像梯度的方向信息的统计值。这种方法跟边缘方向直方图 (edge orientation histograms)、尺度不变特征变换 (scale-invariant feature transform descriptors) 以及形状上下文方法 (shape contexts) 有很多相似之处，但与它们的不同点是：HOG 描述器是在一个网格密集的大小统一的细胞单元 (dense grid of uniformly spaced cells) 上计算，而且为了提高性能，还采用了重叠的局部对比归一化 (overlapping local contrast normalization) 技术。</p><p>方法首见于 <a href="https://hal.inria.fr/file/index/docid/548512/filename/hog_cvpr2005.pdf">Histograms of Oriented Gradients for Human Detection</a>，发表在2005年 CVPR 上。</p><p>算法计算步骤概览：</p><ul><li>图像预处理。伽马矫正 (减少亮度影响) 和灰度化 (也可以在RGB图上做，只不过对三通道颜色值计算，取梯度最大的) [可选]</li><li>计算图像像素点梯度值，得到梯度图 (尺寸和原图同等大小)</li><li>图像划分多个 cell，统计 cell 内梯度直方图</li><li>将 $2\times 2$ 个 cell 联合成一个 block，对每个 block 做块内梯度归一化</li></ul><p>以下将分别介绍这几个步骤。</p><h2 id="图像预处理"><a href="#图像预处理" class="headerlink" title="图像预处理"></a>图像预处理</h2><p>作用：gamma 矫正通常用于电视和监视器系统中重现摄像机拍摄的画面．在图像处理中也可用于调节图像的对比度，减少图像的光照不均和局部阴影。</p><p><strong>原理</strong>： 通过非线性变换，让图像从曝光强度的线性响应变得更接近人眼感受的响应，也就是将漂白（相机曝光）或过暗（曝光不足）的图片，进行矫正。</p><p>gamma 矫正公式：<br>$$<br>f(x)&#x3D;x^\gamma<br>$$<br>输出是输入的幂函数，指数为$\gamma$，典型的Gamma值是0.45。</p><h2 id="计算图像像素梯度图"><a href="#计算图像像素梯度图" class="headerlink" title="计算图像像素梯度图"></a>计算图像像素梯度图</h2><p>对于一个像素点 $L(x,y)$ 来说，在水平方向和竖直方向有两个梯度 $g_x$ 和 $g_y$：<br>$$<br>g_x&#x3D;\frac{L(x+1,y)-L(x-1,y)}{2}\<br>g_y&#x3D;\frac{L(x,y+1)-L(x,y-1)}{2}<br>$$<br>总的梯度大小为：<br>$$<br>g&#x3D;\sqrt{g_x^2+g_y^2}<br>$$<br>梯度的方向为：<br>$$<br>\theta(x,y)&#x3D;\arctan {\frac{g_y}{g_x}}<br>$$<br>梯度方向取绝对值，因此得到的角度范围是 $[0°,180°]$。</p><p>上面的计算过程，可以用下面的两个 kernel 函数很简单的实现。</p><img src="sobel_kernel.jpg"/><p>我们也可以通过 OpenCV 中 size&#x3D;1 的 Sobel 算子来实现。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">gx = cv2.Sobel(img, cv2.CV_32F, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, ksize=<span class="hljs-number">1</span>)<br>gy = cv2.Sobel(img, cv2.CV_32F, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, ksize=<span class="hljs-number">1</span>)<br>mag, angle = cv2.cartToPolar(gx, gy, angleInDegrees=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h2 id="计算梯度直方图"><a href="#计算梯度直方图" class="headerlink" title="计算梯度直方图"></a>计算梯度直方图</h2><p>经过上一步计算，每个像素点会有两个值：梯度方向和梯度大小。</p><p>但是，梯度大小和梯度方向图和原图大小相同，如果实际使用这些特征，会有两个问题：</p><ul><li>计算量很大</li><li>特征稀疏，图中只有少量特征</li></ul><p>所以 HOG 特征选择联合 $8\times 8$ 大小的 cell 内部的像素，计算其梯度幅度和梯度方向的统计直方图。由此一来，需要计算的数值就大量减少了。</p><p>梯度方向取值范围为 $[0°,180°]$，以每 $20°$ 一个单元，可以划分为9组。然后把 cell 内部的值先通过角度划分到对应的 bin 内，然后再把大小赋给这个 bin，具体如下图所示。</p><img src="histogram_1.png"/><p>蓝圈角度为80°，划分到80的 bin，大小2，也赋给这个 bin。红圈角度10°，介于0和20之间，所以两个 bin 各分一半。</p><p>这里有一个细节，如果角度大于160，那么我们要考虑均匀分配，如下图。</p><img src="histogram_2.png"/><p>最终我们可以得到下面这样的直方图：</p><img src="histogram_3.png"/><p>从上图可以看到，更多的点的梯度方向是倾向于0度和160度，也就是说这些点的梯度方向是向上或者向下，表明图像这个位置存在比较明显的横向边缘。因此HOG是对边角敏感的，由于这样的统计方法，也是对部分像素值变化不敏感的，所以能够适应不同的环境。</p><p>至于为什么选取 $8\times 8$ 为一个单元格，是因为HOG特征当初设计时是用来做行人检测的。在行人图片中 $8\times 8$ 的矩阵足以捕获一些特征，比如脸部或者头部特征等。</p><h2 id="Block-归一化"><a href="#Block-归一化" class="headerlink" title="Block 归一化"></a>Block 归一化</h2><p>目的：降低光照的影响。</p><p>方法：向量的每一个值除以向量模长。</p><p>HOG 在选取 $8\times 8$ 为一个 cell 的基础上，以 $2\times 2$ 个 cell 为一组，称为 block。每个 cell 有九个向量 (直方图)，那么 $2\times 2$ 个 cell 则有 36 个向量。</p><h2 id="代码实例"><a href="#代码实例" class="headerlink" title="代码实例"></a>代码实例</h2><p>可以使用 sklearn-image 库中的 hog 函数很简单地实现求一个图片的 HOG，代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">from</span> skimage.feature <span class="hljs-keyword">import</span> hog<br><span class="hljs-keyword">from</span> skimage <span class="hljs-keyword">import</span> data, exposure<br>image = cv2.imread(<span class="hljs-string">&#x27;./00000001.png&#x27;</span>)<br><br>fd, hog_image = hog(image, orientations=<span class="hljs-number">8</span>, pixels_per_cell=(<span class="hljs-number">16</span>, <span class="hljs-number">16</span>),<br>                    cells_per_block=(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), visualize=<span class="hljs-literal">True</span>, multichannel=<span class="hljs-literal">True</span>)<br>fig, (ax1, ax2) = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, figsize=(<span class="hljs-number">8</span>, <span class="hljs-number">4</span>), sharex=<span class="hljs-literal">True</span>, sharey=<span class="hljs-literal">True</span>)<br>ax1.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>ax1.imshow(image, cmap=plt.cm.gray)<br>ax1.set_title(<span class="hljs-string">&#x27;Input image&#x27;</span>)<br><span class="hljs-comment"># Rescale histogram for better display</span><br>hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(<span class="hljs-number">0</span>, <span class="hljs-number">10</span>))<br>ax2.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)<br>ax2.set_title(<span class="hljs-string">&#x27;Histogram of Oriented Gradients&#x27;</span>)<br>plt.show()<br></code></pre></td></tr></table></figure><p>实现效果如下：</p><img src="image1.png"/><img src="image2.png"/><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>[1] <a href="https://zh.wikipedia.org/wiki/%E6%96%B9%E5%90%91%E6%A2%AF%E5%BA%A6%E7%9B%B4%E6%96%B9%E5%9B%BE">Wikipedia: 方向梯度直方图</a></li><li>[2] <a href="https://learnopencv.com/histogram-of-oriented-gradients/">Histogram of Oriented Gradients explained using OpenCV</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Others</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读：Masked Autoencoders Are Scalable Vision Learners</title>
    <link href="/2022/01/20/Masked-Autoencoders-Are-Scalable-Vision-Learners/"/>
    <url>/2022/01/20/Masked-Autoencoders-Are-Scalable-Vision-Learners/</url>
    
    <content type="html"><![CDATA[<h2 id="Motivation-x2F-Problem"><a href="#Motivation-x2F-Problem" class="headerlink" title="Motivation&#x2F;Problem"></a>Motivation&#x2F;Problem</h2><p>NLP 领域的自监督预训练方式不需要标注数据，解决了模型需要大量标签数据的问题。典型的解决方案有基于自回归语言模型的 GPT 和基于遮罩自编码 (masked autoencoding) 的BERT。它们的概念都很简单：</p><p>移除数据中的一部分然后预测被移除的内容。</p><p>遮罩自编码，也就是一种更通用的去噪自编码，这种想法很自然，也应该能应用于计算机视觉。</p><p>但是当前自编码方法在 CV 领域的应用远远落后于 NLP 领域，所以自然而然产生了一个问题：去噪自编码在 CV 和 NLP 领域的区别是什么？</p><p>作者总结了三点：</p><ul><li><p>直到最近，CV 和 NLP 的网络架构都不同。</p><p>在过去十年，卷积网络在视觉方面处于支配地位。典型卷积在标准网格上进行操作，它不能直接将 NLP 领域的 ‘indicator’ 概念比如 ‘mask tokens’ 或者 ‘positional embeddings’ 整合到卷积神经网络中。</p><p>不过这种架构差距已经被 ViT (Vision Transformers) 的引入解决，并且将不再成为障碍。</p></li><li><p>语言和视觉的信息密度不同。</p><p>语言是人造信号，具有高度语义性和信息密度。当训练模型去预测每个句子里缺失的词时，我们可以认为这个任务要求模型具有熟练的语言理解。图片则相反，它是具有高度空间冗余的自然信号。在对邻域块，物品和场景具有一点 (little) 理解的前提下，可以恢复缺失块。</p><p>为了克服这一不同并且学到更多有益的特征，我们发现了一个在 CV 领域很有用的简单策略：随机 mask 掉非常大比例的 patches。这个策略大幅度减少了冗余而且创造了一个非常有挑战性的自监督任务。这个任务要求模型要求模型掌控全局信息，而不是仅仅拥有 low-level 图像信息的理解 (例如局部缺失的物体形状，颜色等等)。</p></li><li><p>将特征表示重新映射回输入的 Autoencoder 的 decoder，对于重建文本和图像起着不同的作用。</p><p>在视觉领域中，decoder 重建的是低维语义级别的 pixels。在语言领域中，它重建的是具有丰富语义的信息。虽然在 BERT 中 decoder 没有那么重要，但是在图像领域中，decoder 对于学到的 latent representation 的语义级别具有决定性的重要作用。</p></li></ul><p>所以 encoder 的任务是：处理没 mask 掉的块，输出 latent representation，decoder 的任务是，把 mask 掉的块和 latent representation 合并的信息作为输入，输出重建图像。</p><p>在这个设计下，encoder 只需要处理一小部分没有 mask 掉的 patches，减少了总体预训练时间和内存需要。</p><h2 id="Approach"><a href="#Approach" class="headerlink" title="Approach"></a>Approach</h2><p>总架构如图所示。和传统的 autoencoder 不同，采用了不对称的设计。MAE 的 encoder 只在部分可被观测的信号上进行操作，然后轻量级 decoder 使用 latent representation 和 mask tokens 重建所有信号。</p><img src="Figure1.png"/><h3 id="Masking"><a href="#Masking" class="headerlink" title="Masking"></a>Masking</h3><p>跟随 ViT 的思想，MAE 把图片分为正常的没有重叠的 patches 然后使用均匀分布随机取样然后 mask 掉剩余的块 (不做替换)。</p><p>高 mask 比例的随机采样消除了冗余，因此任务不能简单地从邻域 patches 推断来完成。均匀采样避免了潜在的中心偏移 (比如 mask 掉更多的中心区域 patches)。高度稀疏的输入给设计一个高效的 encoder 创造了机会。</p><h3 id="MAE-encoder"><a href="#MAE-encoder" class="headerlink" title="MAE encoder"></a>MAE encoder</h3><p>MAE 的 encoder 是一个只在没有 mask 掉的 patches 上应用的 ViT。和在标准 ViT 中一样，MAE 的 encoder 通过一个添加位置嵌入的线性映射把 patches 嵌入，然后把映射结果使用 Transformer 块处理。</p><blockquote><p>Just as in a standard ViT, our encoder embeds patches by a linear projection with added positional embeddings, and then processes the resulting set via a series of Transformer blocks.</p></blockquote><h3 id="MAE-decoder"><a href="#MAE-decoder" class="headerlink" title="MAE decoder"></a>MAE decoder</h3><p>MAE decoder 的输入由 (i) 编码过的可视 patches (ii) mask tokens 组成。每个 mask token 都是一个共享的向量，指示是否存在一个待预测的缺失 patch。</p><blockquote><p>Each mask token is a shared, learned vector that indicates the presence of a missing patch to be predicted.</p></blockquote><p>除此之外，向所有 patches 添加位置嵌入信息，来指示他们在图像中的位置。Decoder 由另外一系列的 Transformer 块组成。</p><p>Decoder 只用来在预训练过程中完成图像重建任务，只有 encoder 用来输出用于识别的 image representations。所以 decoder 的架构很灵活，因为 decoder 独立于 encoder 的设计。</p><p>MAE 研究者使用相对于 encoder 来讲非常小的 decoder 做了实验，他们默认的 decoder 是 encoder 的计算量的不到 $10%$。这种非对称的设计，轻量的 decoder 大大减少了预训练的时间。</p><h3 id="Reconstruction-target"><a href="#Reconstruction-target" class="headerlink" title="Reconstruction target"></a>Reconstruction target</h3><p>重建目标是预测每个 masked patch。最后一层的 decoder 是一个输出 channel 等于一个 patch 的 pixel 个数的线性映射，最后的输出通过 reshape 形成一幅重建图像。Loss function 计算重建图像和原图像在像素空间的均方误差 (MSE)。<strong>MAE 只在 masked patches 上计算 loss</strong>。</p><p>他们还研究了一种变体，重建目标是每个 mask patches 的归一化后的像素值。具体地说，他们计算一个 patch 中所有像素的平均值和标准差，并使用他们来归一化这个 patch。在他们的实验中，使用归一化的像素值可以提高 representation 的质量。</p><h3 id="Simple-implementation"><a href="#Simple-implementation" class="headerlink" title="Simple implementation"></a>Simple implementation</h3><p>MAE 预训练可以被高效实现，它不需要任何特殊的稀疏操作。首先(使用一个附加位置嵌入的线性映射)为每个输入 patch 生成一个 taken，然后随机 shuffle tokens 的列表，把列表的最后一部分移除 (基于 mask ratio)。Encoding 后，把移除的 mask tokens 附加到 encoded patches 后，然后 unshuffle 整个列表来对齐所有的 tokens 和他们的 targets。在这个完整列表上应用 decoder (使用附加位置嵌入)。</p><h2 id="ImageNet-Experiments"><a href="#ImageNet-Experiments" class="headerlink" title="ImageNet Experiments"></a>ImageNet Experiments</h2><h3 id="Mask-ratio"><a href="#Mask-ratio" class="headerlink" title="Mask ratio"></a>Mask ratio</h3><img src="Figure5.png"/><h3 id="Decoder-design"><a href="#Decoder-design" class="headerlink" title="Decoder design"></a>Decoder design</h3><img src="Tableab.png"/><p>其中 ft (fine-tuning), lin (linear probing)。</p><h3 id="Mask-token"><a href="#Mask-token" class="headerlink" title="Mask token"></a>Mask token</h3><img src="Tablec.png"/><p>encoder w&#x2F; [M] 把 masked patches 也作为输入，encoder w&#x2F;o [M] 不把它作为输入。</p><p>可以看到丢弃 masked patches 的运算效率大大提升，不使用 fine-tuning 时的效果也更好。</p><h3 id="Reconstruction-target-1"><a href="#Reconstruction-target-1" class="headerlink" title="Reconstruction target"></a>Reconstruction target</h3><img src="Tabled.png"/><p>w&#x2F;o without, w&#x2F; with, PCA 在 patch space 上应用 PCA，使用最大的 PCA coefficients 作为 target。</p><h3 id="Data-augmentation"><a href="#Data-augmentation" class="headerlink" title="Data augmentation"></a>Data augmentation</h3><img src="Tablee.png"/><h3 id="Mask-sampling-strategy"><a href="#Mask-sampling-strategy" class="headerlink" title="Mask sampling strategy"></a>Mask sampling strategy</h3><img src="Tablef.png"/><img src="Figure6.png"/><h3 id="Training-schedule"><a href="#Training-schedule" class="headerlink" title="Training schedule"></a>Training schedule</h3><img src="Figure7.png"/>]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Transformer</tag>
      
      <tag>Autoencoder</tag>
      
      <tag>Contrastive Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch 中的 CrossEntropyLoss 及其具体应用</title>
    <link href="/2022/01/20/CrossEntropyLoss/"/>
    <url>/2022/01/20/CrossEntropyLoss/</url>
    
    <content type="html"><![CDATA[<h2 id="交叉熵"><a href="#交叉熵" class="headerlink" title="交叉熵"></a>交叉熵</h2><p>交叉熵 (Cross Entropy) 是 Shannon 信息论中的一个重要概念，主要用于度量两个概率分布间的差异性信息。</p><p>给定两个概率分布 $p$ 和 $q$，$p$ 相对于 $q$ 的交叉熵定义为：<br>$$<br>H(p,q)&#x3D;E_p[-\log q]&#x3D;H(p)+D_{KL}(p||q),<br>$$<br>其中 $H(p)$ 是 $p$ 的熵，$D_{KL}(p||q)$ 是从 $p$ 与 $q$ 的KL散度 (也被称为 $p$ 相对于 $q$ 的相对熵)。</p><p>熵的计算公式为：<br>$$<br>H(X)&#x3D;E[I(X)]&#x3D;E[-\ln P(X)]&#x3D;-\sum P(x_i)\log P(x_i)<br>$$<br>KL散度的计算公式为：<br>$$<br>D_{KL}(p||q)&#x3D;\sum P(x_i)\log \frac{P(x_i)}{Q(x_i)}<br>$$<br>对于离散分布的 $p$ 和 $q$，也就是：<br>$$<br>\begin{aligned}<br>H(p,q)&amp;&#x3D;\sum P(x_i)\log \frac{P(x_i)}{Q(x_i)}-\sum P(x_i)\log P(x_i)\<br>&amp;&#x3D;\sum P(x_i)\log \frac{1}{Q(x_i)}\<br>&amp;&#x3D;-\sum\limits_{x}p(x)\log q(x)<br>\end{aligned}<br>$$</p><h2 id="torch-nn-CrossEntropyLoss"><a href="#torch-nn-CrossEntropyLoss" class="headerlink" title="torch.nn.CrossEntropyLoss"></a>torch.nn.CrossEntropyLoss</h2><p>PyTorch 里的 CrossEntropyLoss 通过结合 <code>torch.nn.LogSoftmax</code> 和 <code>torch.nn.NLLLoss</code> 实现，这里不赘述这两个类的实现原理，仅描述 <code>toch.nn.CrossEntropyLoss</code> 的具体内容。</p><p>方法具体为：<code>torch.nn.CrossEntropyLoss(input, target)</code>。</p><p>参数：</p><ul><li>weight (Tensor, optional) 给每个 class 的权重，Shape 为 $C$。</li></ul><p>Shape：</p><ul><li>Input：$(N,C)$ 或者 $(N,C,d_1,d_2,\dots,d_K)$ ，其中 $C$ 是 class 的数量，$N$ 是样本数量。</li><li>Target：$(N)$，其中的数值范围在 $0\leq\text{targets}[i]\leq C-1$ 用来指示类，或者 $(N,d_1,d_2,\dots,d_K)$。</li><li>Output：和 Target 的 Size 相同。</li></ul><p>具体公式为：<br>$$<br>\text{loss}(x, class) &#x3D; -\log\left(\frac{\exp(x[class])}{\sum_j \exp(x[j])}\right)<br>                       &#x3D; -x[class] + \log\left(\sum_j \exp(x[j])\right)<br>$$<br>这个公式的含义为：先 <code>LogSoftmax</code> 求得样本 $x$ 是否属于它的真实类别 $class$，如果是，则值接近1，如果不是，则值接近0 (简单的 Softmax 思想)，然后所有样本的值<strong>加和</strong>或者<strong>加和求平均</strong>，求得最终的 CrossEntropyLoss。</p><h2 id="具体应用"><a href="#具体应用" class="headerlink" title="具体应用"></a>具体应用</h2><p>CrossEntropyLoss 可以被应用在很多方面，这里以 SimCLR 中的计算为例，会介绍一些代码实现的 trick。</p><p>首先 SimCLR 中的正样本对 $(i,j)$ 间的 loss 被定义为：<br>$$<br>\ell_{i,j}&#x3D;-\log\frac{\exp(sim(z_i,z_j)&#x2F;\tau)}{\sum_{k&#x3D;1}^{2N}\mathbb{1}_{[k\neq i]}\exp(sim(z_i,z_k)&#x2F;\tau)},<br>$$<br>其中 $2N$ 为样本数量，有 $N$ 个原样本，$N$ 个通过数据增广得到的新样本，对于一个样本来说，有一个它增广得到的样本，正样本数量为2，其他 $2N-2$ 个样本都是负样本。$sim(\cdot)$ 函数为相似性函数，$\tau$ 为比例参数 temperature。</p><p>总 Loss function 为：<br>$$<br>\mathcal{L}&#x3D;\frac{1}{2N}\sum_{k&#x3D;1}^N[\ell(2k-1,2k)+\ell(2k,2k-1)]<br>$$<br>下面来看一下代码中的实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># features shape:(minibatch*2, dims), (i, dims) 和 (i+minibatch, dims) 互为正样本对</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">info_nce_loss</span>(<span class="hljs-params">features, **kwargs</span>):<br><br>    labels = torch.cat([torch.arange(kwargs[<span class="hljs-string">&#x27;batch_size&#x27;</span>]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>)], dim=<span class="hljs-number">0</span>)<br>    labels = (labels.unsqueeze(<span class="hljs-number">0</span>) == labels.unsqueeze(<span class="hljs-number">1</span>)).<span class="hljs-built_in">float</span>()<br>    labels = labels.to(kwargs[<span class="hljs-string">&#x27;device&#x27;</span>])<br><span class="hljs-comment"># labels 为四个区块均为单位阵的矩阵, 以 4x4 矩阵为例, labels:</span><br>    <span class="hljs-comment">#  [[1, 0, 1, 0],</span><br>    <span class="hljs-comment">#   [0, 1, 0, 1],</span><br>    <span class="hljs-comment">#   [1, 0, 1, 0],</span><br>    <span class="hljs-comment">#   [0, 1, 0, 1]] </span><br>    <span class="hljs-comment"># 最终 labels shape: (minibatch*2, minibatch*2)</span><br>    <br>    features = F.normalize(features, dim=<span class="hljs-number">1</span>) <span class="hljs-comment"># 把 每一行 normalize</span><br><br>    similarity_matrix = torch.matmul(features, features.T) <span class="hljs-comment"># 计算相似度矩阵</span><br><br>    mask = torch.eye(labels.shape[<span class="hljs-number">0</span>], dtype=torch.<span class="hljs-built_in">bool</span>).to(kwargs[<span class="hljs-string">&#x27;device&#x27;</span>])<br>    <span class="hljs-comment"># 此处 mask 是和 labels 相同 shape 的单位阵</span><br>    labels = labels[~mask].view(labels.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>) <br>    <span class="hljs-comment"># 把 labels 对角线上的值 mask 掉, 将矩阵 reshape 成 (minibatch*2， minibatch*2-1)</span><br>    similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 对相似度矩阵同样操作, reshape 成 (minibatch*2, minibatch*2-1)</span><br><span class="hljs-comment"># 这里几步操作就完成了 l(i, j) 分母上剔除 k=i 情况的操作</span><br>    <br>    positives = similarity_matrix[labels.<span class="hljs-built_in">bool</span>()].view(labels.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 正样本的 sim</span><br>    negatives = similarity_matrix[~labels.<span class="hljs-built_in">bool</span>()].view(similarity_matrix.shape[<span class="hljs-number">0</span>], -<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 负样本的 sim</span><br>    <br>    logits = torch.cat([positives, negatives], dim=<span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># 每个样本的第一列元素即为正样本, 要使正样本的 sim 最大</span><br>    labels = torch.zeros(logits.shape[<span class="hljs-number">0</span>], dtype=torch.long).to(kwargs[<span class="hljs-string">&#x27;device&#x27;</span>])<br><br>    logits = logits / kwargs[<span class="hljs-string">&#x27;temperature&#x27;</span>]<br>    <span class="hljs-comment"># 这里除以公式里的 \tau</span><br>    <span class="hljs-keyword">return</span> logits, labels<br><span class="hljs-comment"># 返回 logits 和 labels, 直接调用 CrossEntropyLoss 即可</span><br><br>torch.nn.CrossEntropyLoss(logits, labels)<br><span class="hljs-comment"># logits shape:(minibatch*2,minibatch*2-1) 每一行是和其他样本的相似度,每行的第一列是和正样本的相似度</span><br><span class="hljs-comment"># labels 因为正样本都在第一列, 所以 labels 是全0 Tensor</span><br></code></pre></td></tr></table></figure><p>代码中注释详细叙述了流程，总体的 Trick 概括如下：</p><ul><li>通过 mask 剔除分母中 $k&#x3D;i$ 的部分</li><li>把所有正样本的 similarity reshape 到第一列</li><li>最后所有 labels 为0，直接调用 CrossEntropyLoss</li></ul>]]></content>
    
    
    <categories>
      
      <category>Coding</category>
      
      <category>PyTorch</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch 中的 softmax 函数解读</title>
    <link href="/2022/01/19/softmax-in-PyTorch/"/>
    <url>/2022/01/19/softmax-in-PyTorch/</url>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>在学习 <code>torch.nn.CrossEntropyLoss()</code> 时看到有从 <code>argmax-&gt;softmax-&gt;logsoftmax-&gt;NLLLoss-&gt;CrossEntropyLos</code> 思路解释 <code>CrossEntropyLoss</code> 的文章，顺带简要学了下 softmax ，这里做个简要总结。</p><hr><p>众所周知，<code>argmax</code> 是求极大值点的 index，此函数不可导，也无法计算梯度。为了满足 “需要使用 <code>argmax</code> 同时也需要求导计算梯度” 这一应用场景，<code>softmax</code> 被应用在了 <code>argmax</code> 上。又因为指数函数增长过快，很容易产生一个巨大的值，为了防止数值溢出，又有了 <code>logsoftmax</code>。接下来将分别介绍 <code>softmax</code>，<code>softargmax</code> 和<code>logsoftmax</code>。</p><h2 id="softmax"><a href="#softmax" class="headerlink" title="softmax"></a>softmax</h2><p><code>softmax</code> 函数的表达式如下：<br>$$<br>softmax(x)&#x3D;\frac{e^{x_i}}{\sum\limits_je^{x_j}}<br>$$<br>对 <code>softmax</code> 求导为：<br>$$<br>\begin{aligned}<br>\frac{\partial,softmax(x_i)}{\partial, x_i}&amp;&#x3D;\frac{e^{x_i}\sum\limits_je^{x_j}-e^{x_i}\cdot e^{x_i}}{(\sum\limits_je^{x_j})^2}\<br>&amp;&#x3D; \frac{e^{x_i}}{\sum\limits_je^{x_j}}\cdot\frac{\sum\limits_je^{x_j}-e^{x_i}}{\sum\limits_je^{x_j}}\<br>&amp;&#x3D; softmax(x_i)\cdot(1-softmax(x_i))<br>\end{aligned}<br>$$<br>重新观察一下 <code>softmax</code> 函数的形式，其实就是在指数形式下当前值在总和中所占的比例，如果当前值 $x$ 为最大值，那么 $softmax(x)$ 将接近 1。</p><p>那么为什么不直接求所占比例，而是求个指数？答案显而易见，为了凸显 <code>max</code> 值相对于其他值的大小，如下式：</p><p>$e^{0.5}-e^{0.4}\approx 0.15689&gt;0.5-0.4&#x3D;0.1$。</p><p>差距越大，采用指数的优势越明显，可以从 $f(x)&#x3D;x$ 和 $f(x)&#x3D;e^x$ 的图示中看出这点：</p><img src="exp_x.png" alt="一次函数和指数函数图示" style="zoom:80%;" /><h2 id="softargmax"><a href="#softargmax" class="headerlink" title="softargmax"></a>softargmax</h2><p>为了解决 <code>argmax</code> 不可导的问题，引入 <code>softmax</code> ，由于 <code>softmax</code> 的值在最大值处接近 1，那么乘上对应的 index 就可以完成 <code>argmax</code> 的功能，<code>softargmax</code> 的函数如下：<br>$$<br>softargmax&#x3D;\sum\limits_i\frac{e^{x_i}}{\sum\limits_je^{x_j}}i<br>$$<br>但是这样有个问题，极大值和其他值的差距有可能不够明显，导致求得的值和真实的 <code>argmax</code> 有一定的差距：如 $2.7669$ 和 $3$，可以引入一个常量解决这个问题，改进后的 <code>softargmax</code> 函数如下：<br>$$<br>softargmax&#x3D;\sum\limits_i\frac{e^{\beta x_i}}{\sum\limits_je^{\beta x_j}}i<br>$$<br>$\beta$ 可以取个任何值，加了常量之后，极大值的凸显效应更加明显了(可以看上图中 $f(x)&#x3D;e^{10x}$ 和 $f(x)&#x3D;e^x$ 的对比。</p><h2 id="logsoftmax"><a href="#logsoftmax" class="headerlink" title="logsoftmax"></a>logsoftmax</h2><p>但是 <code>softmax</code> 会有函数上溢的问题，也就是求指数函数之后值太大，所以解决方法就是对 <code>softmax</code> 求一个 log。</p><p><code>logsoftmax</code> 的函数表达式如下：<br>$$<br>logsoftmax(x_i)&#x3D;\log\frac{e^{x_i}}{\sum\limits_je^{x_j}}<br>$$<br>对 <code>logsoftmax</code> 求导为：<br>$$<br>\begin{aligned}<br>logsoftmax(x_i)&amp;&#x3D;\log\frac{e^{x_i}}{\sum\limits_je^{x_j}}\<br>&amp;&#x3D;\log e^{x_i}-\log \sum\limits_je^{x_j}\<br>&amp;&#x3D;x_i-\log\sum\limits_je^{x_j}\<br>\end{aligned}<br>$$</p><p>$$<br>\begin{aligned}<br>\frac{\partial,logsoftmax(x_i)}{\partial x_i}&amp;&#x3D;1-\frac{e^{x_i}}{\sum\limits_je^{x_j}}\<br>&amp;&#x3D;1-softmax(x_i)<br>\end{aligned}<br>$$</p><p><code>logsoftmax</code> 的优点：</p><p>解决函数上溢和下溢的问题，加快运算速度，提高数据稳定性。</p><p>如果还是想要 <code>softmax</code> 的结果，但是又想运行稳定怎么办？既然 <code>logsoftmax</code> 取了 log，那再取个指数就行了。</p>]]></content>
    
    
    <categories>
      
      <category>Coding</category>
      
      <category>PyTorch</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch 中 TensorBoard 可视化模块应用</title>
    <link href="/2022/01/18/tensorboard-application-in-PyTorch/"/>
    <url>/2022/01/18/tensorboard-application-in-PyTorch/</url>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Tensorboard 原本是 tensorflow 的可视化工具，pytorch 从1.2.0开始支持tensorboard。之前的版本也可以使用tensorboardX 代替。它在 PyTorch 中的模块为 <code>torch.utils.tensorboard</code>。</p><p>使用 tensorboard，我们可以在 TensorBoard UI 的框架内把 PyTorch 的模型和数据记录到文件夹内。</p><p>支持的可视化有：标量，图片，直方图，图表，嵌入，Caffe 2 nets 和 blobs。</p><blockquote><p>Scalars, images, histograms, graphs, and embedding visualizations are all supported for PyTorch models and tensors as well as Caffe2 nets and blobs.</p></blockquote><p>Tensorboard 的工作流程为：</p><ul><li>将代码运行过程中的数据写入一个文件夹中。(由代码中的 SummaryWriter 完成)</li><li>读取这个文件夹中的数据，用浏览器显示出来。(在命令行运行 tensorboard 完成)</li></ul><p>接下来将分别介绍 SummaryWriter 和命令行 tensorboard 的使用方法。</p><h2 id="SummaryWriter"><a href="#SummaryWriter" class="headerlink" title="SummaryWriter"></a>SummaryWriter</h2><p>一个简单实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>writer = SummaryWriter()<br><br><span class="hljs-keyword">for</span> n_iter <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    writer.add_scalar(<span class="hljs-string">&#x27;Loss/train&#x27;</span>, np.random.random(), n_iter)<br>    writer.add_scalar(<span class="hljs-string">&#x27;Loss/test&#x27;</span>, np.random.random(), n_iter)<br>    writer.add_scalar(<span class="hljs-string">&#x27;Accuracy/train&#x27;</span>, np.random.random(), n_iter)<br>    writer.add_scalar(<span class="hljs-string">&#x27;Accuracy/test&#x27;</span>, np.random.random(), n_iter)<br></code></pre></td></tr></table></figure><p>可以看到，首先创建 <code>SummaryWriter</code> 的实例来对写入文件夹等等进行总体控制，然后再通过实例写入。<code>SummaryWriter</code> 的初始化参数如下：</p><ul><li><code>log_dir</code> (string) - 保存目录位置。默认为 <code>runs/CURRENT_DATETIME_HOSTNAME</code>，因为每次运行的时间都会改变，所以每次都会写入新文件夹。平常使用时可以使用层级结构，如 <code>runs/exp1</code>，<code>runs/exp2</code>，方便对实验进行比较。</li><li><code>purge_step</code> (int) - 当 log 在 $T+X$ 步崩溃导致意外终止，然后在 $T$ 步重启时，可以指定 <code>purge_step</code>。大于等于 $T$ 步的数据会在 TensorBoard 里被清除然后隐藏。注意重启的实验和崩溃的实验应该指定同一 <code>log_dir</code> 文件目录。</li></ul><h2 id="命令行-tensorboard-可视化"><a href="#命令行-tensorboard-可视化" class="headerlink" title="命令行 tensorboard 可视化"></a>命令行 tensorboard 可视化</h2><p>常用的命令就两个参数 <code>--logdir</code> 和 <code>--port</code>。</p><ul><li><code>logdir</code>：需要可视化的目录位置。</li><li><code>port</code>：tensorboard 可视化显示的 localhost 端口。</li></ul><p>示例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">tensorboard --logdir=./runs --port <span class="hljs-number">4000</span><br></code></pre></td></tr></table></figure><h2 id="写数据方法"><a href="#写数据方法" class="headerlink" title="写数据方法"></a>写数据方法</h2><p>就像在 <code>SummaryWriter</code> 中展示的，tensorboard 通过 <code>SummaryWriter</code> 的各种方法来向目录文件中写入数据，除了 <code>add_scalar</code> 方法外，还有许多方法，本节将一一进行介绍。</p><h3 id="add-scalar"><a href="#add-scalar" class="headerlink" title="add_scalar"></a>add_scalar</h3><p>将标量数据添加到 summary。</p><blockquote><p>add_scalar(tag, scalar_value, global_step&#x3D;None)</p></blockquote><ul><li>tag：数据 ID。</li><li>scalar_value：需要存储的值。</li><li>global_step：全局的步骤数。</li></ul><p>实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br>writer = SummaryWriter()<br>x = <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> x:<br>    writer.add_scalar(<span class="hljs-string">&#x27;y=2x&#x27;</span>, i * <span class="hljs-number">2</span>, i)<br>writer.close()<br></code></pre></td></tr></table></figure><h3 id="add-scalars"><a href="#add-scalars" class="headerlink" title="add_scalars"></a>add_scalars</h3><p>批量添加标量数据到 summary。</p><blockquote><p>add_scalars(main_tag, tag_scalar_dict, global_step&#x3D;None)</p></blockquote><ul><li>main_tag：所有 tag 的主标签。</li><li>tag_scalar_dict：存储的标签和值的键值对。</li><li>global_step：全局的步骤数。</li></ul><p>实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>writer = SummaryWriter()<br>r = <span class="hljs-number">5</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    writer.add_scalars(<span class="hljs-string">&#x27;run_14h&#x27;</span>, &#123;<span class="hljs-string">&#x27;xsinx&#x27;</span>:i*np.sin(i/r),<br>                                    <span class="hljs-string">&#x27;xcosx&#x27;</span>:i*np.cos(i/r),<br>                                    <span class="hljs-string">&#x27;tanx&#x27;</span>: np.tan(i/r)&#125;, i)<br>writer.close()<br></code></pre></td></tr></table></figure><p>注意，该方法存储时不是将 xsinx, xcosx, tanx 存储在 run_14h 这个 section 下，而是在主文件夹下将三个值存入 run_14h_xsinx, run_14h_xcosx, run_14h_tanx 文件夹。</p><p>如果想存储在一个 section 下，还是使用 add_scalar 方法，如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">writer.add_scalar(<span class="hljs-string">&#x27;Loss/loss1&#x27;</span>, loss1, step)<br>writer.add_scalar(<span class="hljs-string">&#x27;Loss/loss2&#x27;</span>, loss2, step)<br></code></pre></td></tr></table></figure><h3 id="add-histogram"><a href="#add-histogram" class="headerlink" title="add_histogram"></a>add_histogram</h3><p>将直方图添加到 summary。</p><blockquote><p>add_histogram(tag, values, global_step)</p></blockquote><ul><li>tag：数据 ID。</li><li>values：建立直方图的值。(type 为 <code>torch.Tensor</code> 或者 <code>numpy.array</code>)</li><li>global_step：全局的步骤数。</li></ul><p>实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>writer = SummaryWriter()<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):<br>    x = np.random.random(<span class="hljs-number">1000</span>)<br>    writer.add_histogram(<span class="hljs-string">&#x27;distribution centers&#x27;</span>, x + i, i)<br>writer.close()<br></code></pre></td></tr></table></figure><h3 id="add-image"><a href="#add-image" class="headerlink" title="add_image"></a>add_image</h3><p>将图片信息添加到 summary。注意需要安装 <code>pillow</code> 包。</p><blockquote><p>add_image(tag, img_tensor, global_step&#x3D;None, dataformats&#x3D;’CHW’)</p></blockquote><ul><li><p>tag：数据 ID。</p></li><li><p>img_tensor：图片数据。</p></li><li><p>global_step：全局的步骤数。</p></li><li><p>dataformats：数据格式，如 <code>CHW</code>, <code>HWC</code>, <code>HW</code>。<code>H</code> 为高, <code>W</code>为宽, <code>C</code> 为通道数。</p></li></ul><p>Shape：</p><p><code>img_tensor</code> 默认为 $(3, H,W)$。可以使用 <code>torchvision.utils.make_grid()</code> 把一个 <code>batch</code> 的 <code>tensor</code> 转换成 $3\times H\times W$ 的格式。如果 <code>img_tensor</code> 为其他格式，需要更改 <code>dataformats</code> 为对应的格式。</p><p>实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>img = np.zeros((<span class="hljs-number">3</span>, <span class="hljs-number">100</span>, <span class="hljs-number">100</span>))<br>img[<span class="hljs-number">0</span>] = np.arange(<span class="hljs-number">0</span>, <span class="hljs-number">10000</span>).reshape(<span class="hljs-number">100</span>, <span class="hljs-number">100</span>) / <span class="hljs-number">10000</span><br>img[<span class="hljs-number">1</span>] = <span class="hljs-number">1</span> - np.arange(<span class="hljs-number">0</span>, <span class="hljs-number">10000</span>).reshape(<span class="hljs-number">100</span>, <span class="hljs-number">100</span>) / <span class="hljs-number">10000</span><br><br>img_HWC = np.zeros((<span class="hljs-number">100</span>, <span class="hljs-number">100</span>, <span class="hljs-number">3</span>))<br>img_HWC[:, :, <span class="hljs-number">0</span>] = np.arange(<span class="hljs-number">0</span>, <span class="hljs-number">10000</span>).reshape(<span class="hljs-number">100</span>, <span class="hljs-number">100</span>) / <span class="hljs-number">10000</span><br>img_HWC[:, :, <span class="hljs-number">1</span>] = <span class="hljs-number">1</span> - np.arange(<span class="hljs-number">0</span>, <span class="hljs-number">10000</span>).reshape(<span class="hljs-number">100</span>, <span class="hljs-number">100</span>) / <span class="hljs-number">10000</span><br><br>writer = SummaryWriter()<br>writer.add_image(<span class="hljs-string">&#x27;my_image&#x27;</span>, img, <span class="hljs-number">0</span>)<br><br><span class="hljs-comment"># If you have non-default dimension setting, set the dataformats argument.</span><br>writer.add_image(<span class="hljs-string">&#x27;my_image_HWC&#x27;</span>, img_HWC, <span class="hljs-number">0</span>, dataformats=<span class="hljs-string">&#x27;HWC&#x27;</span>)<br>writer.close()<br></code></pre></td></tr></table></figure><h3 id="add-images"><a href="#add-images" class="headerlink" title="add_images"></a>add_images</h3><p>将一个 batch 的图片数据添加到 summary。注意需要安装 <code>pillow</code> 包。</p><blockquote><p>add_images(<em>tag</em>, <em>img_tensor</em>, <em>global_step&#x3D;None</em>, <em>dataformats&#x3D;’NCHW’</em>)</p></blockquote><ul><li><p>tag：数据 ID。</p></li><li><p>img_tensor：图片数据。</p></li><li><p>global_step：全局的步骤数。</p></li><li><p>dataformats：数据格式，如 <code>NCHW</code>, <code>NHWC</code>, <code>CHW</code>。<code>H</code> 为高, <code>W</code>为宽, <code>C</code> 为通道数。</p></li></ul><p>Shape：</p><p><code>img_tensor</code> 默认为 $(N,3, H,W)$。如果 <code>img_tensor</code> 为其他格式，需要更改 <code>dataformats</code> 为对应的格式。</p><p>实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br>img_batch = np.zeros((<span class="hljs-number">16</span>, <span class="hljs-number">3</span>, <span class="hljs-number">100</span>, <span class="hljs-number">100</span>))<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">16</span>):<br>    img_batch[i, <span class="hljs-number">0</span>] = np.arange(<span class="hljs-number">0</span>, <span class="hljs-number">10000</span>).reshape(<span class="hljs-number">100</span>, <span class="hljs-number">100</span>) / <span class="hljs-number">10000</span> / <span class="hljs-number">16</span> * i<br>    img_batch[i, <span class="hljs-number">1</span>] = (<span class="hljs-number">1</span> - np.arange(<span class="hljs-number">0</span>, <span class="hljs-number">10000</span>).reshape(<span class="hljs-number">100</span>, <span class="hljs-number">100</span>) / <span class="hljs-number">10000</span>) / <span class="hljs-number">16</span> * i<br><br>writer = SummaryWriter()<br>writer.add_images(<span class="hljs-string">&#x27;my_image_batch&#x27;</span>, img_batch, <span class="hljs-number">0</span>)<br>writer.close()<br></code></pre></td></tr></table></figure><h3 id="add-figure"><a href="#add-figure" class="headerlink" title="add_figure"></a>add_figure</h3><p>将 matplotlib figure 渲染成图片并把它添加到 summary。注意需要安装 <code>matplotlib</code> 包。</p><blockquote><p>add_figure(tag, figure, global_step&#x3D;None, close&#x3D;True)</p></blockquote><ul><li>tag：数据 ID。</li><li>figure：figure 或者 figure 列表。</li><li>global_step：全局的步骤数。</li></ul><h3 id="add-graph"><a href="#add-graph" class="headerlink" title="add_graph"></a>add_graph</h3><p>将图数据添加到 summary。</p><blockquote><p>add_graph(model, input_to_model&#x3D;None, verbose&#x3D;False)</p></blockquote><ul><li>model (torch.nn.Module)：要画的模型。</li><li>input_to_model：输入变量。(<code>torch.Tensor</code> 或者 <code>torch.Tensor</code> 的 <code>list</code>)</li><li>verbose：是否把图结构输入到控制台。(没啥用, 输出的结果看不懂)</li></ul><h3 id="add-hparms"><a href="#add-hparms" class="headerlink" title="add_hparms"></a>add_hparms</h3><p>将一组超参数数据添加到 TensorBoard。</p><blockquote><p>add_hparams(hparam_dict, metric_dict, run_name)</p></blockquote><ul><li><p>hparam_dict：字典中每个键值对，超参数和它对应的值。</p></li><li><p>metric_dcit：字典中每个 metric 和它对应的值。注意这里使用的值应该是 tensorboard 记录里唯一的值。(unique)</p></li><li><p>run_name：这次 run 的名称，会被包含在 <code>logdir</code> 文件夹下。如果 run_name 未被指定，则默认会使用当前时间戳。</p></li></ul><p>实例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter<br><span class="hljs-keyword">with</span> SummaryWriter() <span class="hljs-keyword">as</span> w:<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):<br>        w.add_hparams(&#123;<span class="hljs-string">&#x27;lr&#x27;</span>: <span class="hljs-number">0.1</span>*i, <span class="hljs-string">&#x27;bsize&#x27;</span>: i&#125;,<br>                      &#123;<span class="hljs-string">&#x27;hparam/accuracy&#x27;</span>: <span class="hljs-number">10</span>*i, <span class="hljs-string">&#x27;hparam/loss&#x27;</span>: <span class="hljs-number">10</span>*i&#125;)<br></code></pre></td></tr></table></figure><h2 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tensorboard.backend.event_processing <span class="hljs-keyword">import</span> event_accumulator<br> <br><span class="hljs-comment">#加载日志数据</span><br>ea=event_accumulator.EventAccumulator(<span class="hljs-string">&#x27;events.out.tfevents.1550994567.vvd-Inspiron-7557&#x27;</span>) <br>ea.Reload()<br><span class="hljs-built_in">print</span>(ea.scalars.Keys())<br> <br>val_psnr=ea.scalars.Items(<span class="hljs-string">&#x27;val_psnr&#x27;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(val_psnr))<br><span class="hljs-built_in">print</span>([(i.step,i.value) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> val_psnr])<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">[<span class="hljs-string">&#x27;val_loss&#x27;</span>, <span class="hljs-string">&#x27;val_psnr&#x27;</span>, <span class="hljs-string">&#x27;loss&#x27;</span>, <span class="hljs-string">&#x27;psnr&#x27;</span>, <span class="hljs-string">&#x27;lr&#x27;</span>]<br><span class="hljs-number">29</span><br>[(<span class="hljs-number">0</span>, <span class="hljs-number">33.70820617675781</span>), (<span class="hljs-number">1</span>, <span class="hljs-number">34.52505874633789</span>), (<span class="hljs-number">2</span>, <span class="hljs-number">34.26629638671875</span>), (<span class="hljs-number">3</span>, <span class="hljs-number">35.47195053100586</span>), (<span class="hljs-number">4</span>, <span class="hljs-number">35.45940017700195</span>), (<span class="hljs-number">5</span>, <span class="hljs-number">35.336708068847656</span>), (<span class="hljs-number">6</span>, <span class="hljs-number">35.467647552490234</span>), (<span class="hljs-number">7</span>, <span class="hljs-number">35.919857025146484</span>), (<span class="hljs-number">8</span>, <span class="hljs-number">35.29727554321289</span>), (<span class="hljs-number">9</span>, <span class="hljs-number">35.63655471801758</span>), (<span class="hljs-number">10</span>, <span class="hljs-number">36.219871520996094</span>), (<span class="hljs-number">11</span>, <span class="hljs-number">36.178646087646484</span>), (<span class="hljs-number">12</span>, <span class="hljs-number">35.93777847290039</span>), (<span class="hljs-number">13</span>, <span class="hljs-number">35.587406158447266</span>), (<span class="hljs-number">14</span>, <span class="hljs-number">36.198944091796875</span>), (<span class="hljs-number">15</span>, <span class="hljs-number">36.241966247558594</span>), (<span class="hljs-number">16</span>, <span class="hljs-number">36.379913330078125</span>), (<span class="hljs-number">17</span>, <span class="hljs-number">36.28306198120117</span>), (<span class="hljs-number">18</span>, <span class="hljs-number">36.03053665161133</span>), (<span class="hljs-number">19</span>, <span class="hljs-number">36.20806121826172</span>), (<span class="hljs-number">20</span>, <span class="hljs-number">36.21710968017578</span>), (<span class="hljs-number">21</span>, <span class="hljs-number">36.42262268066406</span>), (<span class="hljs-number">22</span>, <span class="hljs-number">36.00306701660156</span>), (<span class="hljs-number">23</span>, <span class="hljs-number">36.4374885559082</span>), (<span class="hljs-number">24</span>, <span class="hljs-number">36.163787841796875</span>), (<span class="hljs-number">25</span>, <span class="hljs-number">36.53673553466797</span>), (<span class="hljs-number">26</span>, <span class="hljs-number">35.99557113647461</span>), (<span class="hljs-number">27</span>, <span class="hljs-number">36.96220016479492</span>), (<span class="hljs-number">28</span>, <span class="hljs-number">36.63676452636719</span>)]<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Coding</category>
      
      <category>PyTorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python 中 logging 模块的基础使用</title>
    <link href="/2022/01/18/Python-logging/"/>
    <url>/2022/01/18/Python-logging/</url>
    
    <content type="html"><![CDATA[<h2 id="logging-模块简介"><a href="#logging-模块简介" class="headerlink" title="logging 模块简介"></a>logging 模块简介</h2><p>logging 模块定义的函数和类为应用程序和库的开发实现了一个灵活的事件日志系统。logging 模块是 Python 的一个标准库模块，由标准库模块提供日志记录 API 的关键好处是所有 Python 模块都可以使用这个日志记录功能。</p><h3 id="logging-模块的日志级别"><a href="#logging-模块的日志级别" class="headerlink" title="logging 模块的日志级别"></a>logging 模块的日志级别</h3><p>日志功能应以所追踪事件级别或严重性而定。各级别适用性如下 (以严重性递增) ：</p><table><thead><tr><th>级别</th><th>描述</th></tr></thead><tbody><tr><td><code>DEBUG</code></td><td>细节信息，仅当诊断问题时适用。</td></tr><tr><td><code>INFO</code></td><td>确认程序按预期运行。</td></tr><tr><td><code>WARNING</code></td><td>表明有已经或即将发生的意外（例如：磁盘空间不足）。程序仍按预期进行。</td></tr><tr><td><code>ERROR</code></td><td>由于严重的问题，程序的某些功能已经不能正常执行。</td></tr><tr><td><code>CRITICAL</code></td><td>严重的错误，表明程序已不能继续执行。</td></tr></tbody></table><p>默认的级别是 <code>WARNING</code>，意味着只会追踪该级别及以上的事件，除非更改日志配置。</p><h3 id="logging-模块的使用方式介绍"><a href="#logging-模块的使用方式介绍" class="headerlink" title="logging 模块的使用方式介绍"></a>logging 模块的使用方式介绍</h3><p>logging模块提供了两种记录日志的方式：</p><ul><li>第一种方式是使用logging提供的模块级别的函数</li><li>第二种方式是使用Logging日志系统的四大组件</li></ul><p>其实，logging所提供的模块级别的日志记录函数也是对logging日志系统相关类的封装而已。</p><h4 id="logging模块定义的模块级别的常用函数"><a href="#logging模块定义的模块级别的常用函数" class="headerlink" title="logging模块定义的模块级别的常用函数"></a>logging模块定义的模块级别的常用函数</h4><table><thead><tr><th>函数</th><th>说明</th></tr></thead><tbody><tr><td><code>logging.debug(msg, *args, **kwargs)</code></td><td>创建一条严重级别为DEBUG的日志记录</td></tr><tr><td><code>logging.info(msg, *args, **kwargs)</code></td><td>创建一条严重级别为INFO的日志记录</td></tr><tr><td><code>logging.warning(msg, *args, **kwargs)</code></td><td>创建一条严重级别为WARNING的日志记录</td></tr><tr><td><code>logging.error(msg, *args, **kwargs)</code></td><td>创建一条严重级别为ERROR的日志记录</td></tr><tr><td><code>logging.critical(msg, *args, **kwargs)</code></td><td>创建一条严重级别为CRITICAL的日志记录</td></tr><tr><td><code>logging.log(level, *args, **kwargs)</code></td><td>创建一条严重级别为level的日志记录</td></tr><tr><td><code>logging.basicConfig(**kwargs)</code></td><td>对root logger进行一次性配置</td></tr></tbody></table><p>其中 <code>logging.basicConfig(**kwargs)</code> 函数用于指定“要记录的日志级别”、“日志格式”、“日志输出位置”、“日志文件的打开模式”等信息，其他几个都是用于记录各个级别日志的函数。</p><h4 id="logging模块的四大组件"><a href="#logging模块的四大组件" class="headerlink" title="logging模块的四大组件"></a>logging模块的四大组件</h4><table><thead><tr><th>组件</th><th>说明</th></tr></thead><tbody><tr><td>loggers</td><td>提供应用程序代码直接使用的接口</td></tr><tr><td>handlers</td><td>用于将日志记录发送到指定的目的位置</td></tr><tr><td>filters</td><td>提供更细粒度的日志过滤功能，用于决定哪些日志记录将会被输出（其它的日志记录将会被忽略）</td></tr><tr><td>formatters</td><td>用于控制日志信息的最终输出格式</td></tr></tbody></table><h2 id="使用-logging-提供的模块级别函数记录日志"><a href="#使用-logging-提供的模块级别函数记录日志" class="headerlink" title="使用 logging 提供的模块级别函数记录日志"></a>使用 logging 提供的模块级别函数记录日志</h2><p>只有级别大于或等于日志记录器指定级别的日志记录才会被输出，小于该级别的日志记录将会被丢弃。</p><p>首先配置 <code>logging.basicConfig()</code>。</p><h3 id="logging-basicConfig-函数说明"><a href="#logging-basicConfig-函数说明" class="headerlink" title="logging.basicConfig() 函数说明"></a>logging.basicConfig() 函数说明</h3><p>该方法用于为logging日志系统做一些基本配置，方法定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">logging.basicConfig(**kwargs)<br></code></pre></td></tr></table></figure><p>该函数可接收的关键字参数如下：</p><table><thead><tr><th>参数名称</th><th>描述</th></tr></thead><tbody><tr><td>filename</td><td>指定日志输出目标文件的文件名，指定该设置项后日志信心就不会被输出到控制台了</td></tr><tr><td>filemode</td><td>指定日志文件的打开模式，默认为’a’。需要注意的是，该选项要在filename指定时才有效</td></tr><tr><td>format</td><td>指定日志格式字符串，即指定日志输出时所包含的字段信息以及它们的顺序。logging模块定义的格式字段下面会列出。</td></tr><tr><td>datefmt</td><td>指定日期&#x2F;时间格式。需要注意的是，该选项要在format中包含时间字段%(asctime)s时才有效</td></tr><tr><td>level</td><td>指定日志器的日志级别</td></tr></tbody></table><h3 id="logging模块定义的格式字符串字段"><a href="#logging模块定义的格式字符串字段" class="headerlink" title="logging模块定义的格式字符串字段"></a>logging模块定义的格式字符串字段</h3><p>logging模块中定义好的可以用于format格式字符串中字段有：</p><table><thead><tr><th>字段&#x2F;属性名称</th><th>使用格式</th><th>描述</th></tr></thead><tbody><tr><td>asctime</td><td>%(asctime)s</td><td>日志事件发生的时间–人类可读时间，如：2003-07-08 16:49:45,896</td></tr><tr><td>created</td><td>%(created)f</td><td>日志事件发生的时间–时间戳，就是当时调用time.time()函数返回的值</td></tr><tr><td>levelname</td><td>%(levelname)s</td><td>该日志记录的文字形式的日志级别（’DEBUG’, ‘INFO’, ‘WARNING’, ‘ERROR’, ‘CRITICAL’）</td></tr><tr><td>name</td><td>%(name)s</td><td>所使用的日志器名称，默认是’root’，因为默认使用的是 rootLogger</td></tr><tr><td>message</td><td>%(message)s</td><td>日志记录的文本内容，通过 <code>msg % args</code>计算得到的</td></tr></tbody></table><h3 id="经过配置的日志输出"><a href="#经过配置的日志输出" class="headerlink" title="经过配置的日志输出"></a>经过配置的日志输出</h3><p>在配置日志器日志级别的基础上，在配置下日志输出目标文件和日志格式：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">LOG_FORMAT = <span class="hljs-string">&quot;%(asctime)s - %(levelname)s - %(message)s&quot;</span><br>DATE_FORMAT = <span class="hljs-string">&quot;%m/%d/%Y %H:%M:%S %p&quot;</span><br><br>logging.basicConfig(filename=<span class="hljs-string">&#x27;my.log&#x27;</span>, level=logging.DEBUG, <span class="hljs-built_in">format</span>=LOG_FORMAT, datefmt=DATE_FORMAT)<br><br>logging.debug(<span class="hljs-string">&quot;This is a debug log.&quot;</span>)<br>logging.info(<span class="hljs-string">&quot;This is a info log.&quot;</span>)<br>logging.warning(<span class="hljs-string">&quot;This is a warning log.&quot;</span>)<br>logging.error(<span class="hljs-string">&quot;This is a error log.&quot;</span>)<br>logging.critical(<span class="hljs-string">&quot;This is a critical log.&quot;</span>)<br></code></pre></td></tr></table></figure><p>输出内容为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">05/08/<span class="hljs-number">2017</span> <span class="hljs-number">14</span>:<span class="hljs-number">29</span>:04 PM - DEBUG - This <span class="hljs-keyword">is</span> a debug log.<br>05/08/<span class="hljs-number">2017</span> <span class="hljs-number">14</span>:<span class="hljs-number">29</span>:04 PM - INFO - This <span class="hljs-keyword">is</span> a info log.<br>05/08/<span class="hljs-number">2017</span> <span class="hljs-number">14</span>:<span class="hljs-number">29</span>:04 PM - WARNING - This <span class="hljs-keyword">is</span> a warning log.<br>05/08/<span class="hljs-number">2017</span> <span class="hljs-number">14</span>:<span class="hljs-number">29</span>:04 PM - ERROR - This <span class="hljs-keyword">is</span> a error log.<br>05/08/<span class="hljs-number">2017</span> <span class="hljs-number">14</span>:<span class="hljs-number">29</span>:04 PM - CRITICAL - This <span class="hljs-keyword">is</span> a critical log.<br></code></pre></td></tr></table></figure><p>如果要输出变量，则使用 Python 的格式占位：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">logging.debug(<span class="hljs-string">f&quot;Epoch: <span class="hljs-subst">&#123;epoch_iter&#125;</span>\tLoss: <span class="hljs-subst">&#123;loss&#125;</span>\tTop1 Acc: <span class="hljs-subst">&#123;top1[<span class="hljs-number">0</span>]&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure><h4 id="覆盖写入-log"><a href="#覆盖写入-log" class="headerlink" title="覆盖写入 log"></a>覆盖写入 log</h4><p>这样配置时每次会在 log 文件后面续写，如果需要覆盖，在 basicConfig 参数中指定 <code>filemode=&#39;w&#39;</code>。</p>]]></content>
    
    
    <categories>
      
      <category>Coding</category>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python 中 Yaml 配置文件模块的使用</title>
    <link href="/2022/01/17/The-application-of-yaml-in-python/"/>
    <url>/2022/01/17/The-application-of-yaml-in-python/</url>
    
    <content type="html"><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>YAML 是 “YAML Ain’t a Markup Language” 的缩写。在开发这种语言时，YAML 的意思是 “Yet Another Markup Language”，但为了强调这种语言以数据做为中心，而不是以标记语言为重点，而用反向缩略语重命名。</p><p>相较于 XML，YAML 可以基于流来处理，表达性强，扩展性好。</p><p>简要的语法规则可以概括为：</p><p>结构通过空格缩进来展示，列表里的项用”- “(dash then space) 来代表，字典中的键值对用”: “(colon then space)分隔。</p><p>更多的语法规则可以参见：</p><p>YAML 官方 Github 仓库：<a href="https://github.com/yaml/pyyaml">https://github.com/yaml/pyyaml</a>，</p><p>YAML 教程：<a href="https://pyyaml.org/wiki/PyYAMLDocumentation">https://pyyaml.org/wiki/PyYAMLDocumentation</a>。</p><h3 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h3><p>单个文件不需要显式分隔，直接写文件内容即可，如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-bullet">-</span> <span class="hljs-string">Multimedia</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">Internet</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">Education</span><br></code></pre></td></tr></table></figure><p>文件以 <code>---</code> 开头，以 <code>...</code> 结束，如：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">Afterstep</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">CTWM</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">Oroborus</span><br><span class="hljs-string">...</span><br></code></pre></td></tr></table></figure><p>多个文件的例子：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">Ada</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">APL</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">ASP</span><br><br><span class="hljs-bullet">-</span> <span class="hljs-string">Assembly</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">Awk</span><br><span class="hljs-meta">---</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">Basic</span><br><span class="hljs-meta">---</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">C</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">C#</span>    <span class="hljs-comment"># Note that comments are denoted with &#x27; #&#x27; (space then #).</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">C++</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">Cold</span> <span class="hljs-string">Fusion</span><br></code></pre></td></tr></table></figure><h3 id="序列块"><a href="#序列块" class="headerlink" title="序列块"></a>序列块</h3><p>字典用 “: “ 来表示，读入 Python 中是个 dict</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">name: rosmantis<br>age: <span class="hljs-number">2</span><br>job: tester<br></code></pre></td></tr></table></figure><p>列表用 “- “来表示，读入 Python 中是个 list</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-bullet">-</span> <span class="hljs-string">rosmantis</span><br><span class="hljs-bullet">-</span> <span class="hljs-number">2</span><br><span class="hljs-bullet">-</span> <span class="hljs-string">tester</span><br></code></pre></td></tr></table></figure><p>复合结构：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">name:</span> <span class="hljs-string">simclr</span><br><span class="hljs-attr">channels:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">pytorch</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">anaconda</span><br><span class="hljs-attr">dependencies:</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">cudatoolkit=10.1</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">numpy=1.18.1</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">opencv=3.4.2</span><br>  <span class="hljs-bullet">-</span> <span class="hljs-string">pillow=7.0</span><br></code></pre></td></tr></table></figure><h3 id="读写文件"><a href="#读写文件" class="headerlink" title="读写文件"></a>读写文件</h3><p>读取 yml 文件：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> yaml<br>f = <span class="hljs-built_in">open</span>(<span class="hljs-string">r&#x27;config.yaml&#x27;</span>)<br>y = yaml.load(f)<br><br><span class="hljs-comment"># default load 会有 userwarning, 所以可以用以下格式代替</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;config.yaml&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    config = yaml.load(f, Loader=yaml.FullLoader)<br></code></pre></td></tr></table></figure><p>写入 yml 文件：</p><p>yaml.dump 将一个 Python 对象生成为 yaml 文档</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> yaml<br>file = &#123;<br>    <span class="hljs-string">&#x27;name&#x27;</span>: <span class="hljs-string">&#x27;rosmantis&#x27;</span>,<br>    <span class="hljs-string">&#x27;age&#x27;</span>: <span class="hljs-string">&#x27;2&#x27;</span>,<br>    <span class="hljs-string">&#x27;hobbies&#x27;</span>: [<span class="hljs-string">&#x27;computer game&#x27;</span>, <span class="hljs-string">&#x27;badminton&#x27;</span>]<br>&#125;<br>yaml.dump(file, f)<br><span class="hljs-comment"># f 处需要是打开的文本文件, 如</span><br>f = <span class="hljs-built_in">open</span>(<span class="hljs-string">r&#x27;config.yml&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>)<br><br><span class="hljs-comment"># 另一种格式</span><br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&#x27;config.yml&#x27;</span>, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    yaml.dump(file, f)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Coding</category>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Yaml</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Python *args **kwargs 函数传参</title>
    <link href="/2022/01/17/Python-Variable-Length-Parameters/"/>
    <url>/2022/01/17/Python-Variable-Length-Parameters/</url>
    
    <content type="html"><![CDATA[<p>我们写程序时，不确定要往函数中传入多少个参数，即可使用可变参数（不定长参数），用 <code>*args</code>，<code>**kwargs</code> 表示。</p><p><code>*args</code> 被称为 Non-keyword Variable Arguments，无关键字参数。</p><p><code>**kwargs</code> 被称为 Keyword Variable Arguments，有关键字参数。</p><p><code>*args</code> 以列表或者元组形式传参，<code>**kwargs</code> 以字典形式传参。</p><p><code>*args</code> 实例：</p><p>当位置参数和不定长参数一起使用时，先把参数分配给位置参数，再将多余的参数以元组形式分配给 <code>args</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>(<span class="hljs-params">a, b, *args</span>):<br>    c = args<br>    <span class="hljs-built_in">print</span>(a, b, c)<br><br><span class="hljs-comment"># 给的参数多于位置参数时的输出结果:</span><br>test(<span class="hljs-string">&quot;this is&quot;</span>, <span class="hljs-string">&quot;a&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>, <span class="hljs-string">&quot;for&quot;</span>, <span class="hljs-string">&quot;args&quot;</span>)<br>this <span class="hljs-keyword">is</span> a (<span class="hljs-string">&#x27;test&#x27;</span>, <span class="hljs-string">&#x27;for&#x27;</span>, <span class="hljs-string">&#x27;args&#x27;</span>)<br><br><span class="hljs-comment"># 给的参数等于位置参数时的输出结果:</span><br>test(<span class="hljs-string">&quot;this is a&quot;</span>, <span class="hljs-string">&quot;test&quot;</span>)<br>this <span class="hljs-keyword">is</span> a test ()<br><span class="hljs-comment"># args 为空列表</span><br></code></pre></td></tr></table></figure><p><code>**kwargs</code> 实例：</p><p>当传入参数为字典时，使用 <code>**kwargs</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">test_kwargs</span>(<span class="hljs-params">a, *args, **kwargs</span>):<br>    <span class="hljs-built_in">print</span>(a)<br>    <span class="hljs-built_in">print</span>(args)<br>    <span class="hljs-built_in">print</span>(kwargs)<br>    <br><span class="hljs-comment"># 传入 key 和 value</span><br><span class="hljs-comment"># input</span><br>test_kwargs(<span class="hljs-number">1</span>, f=<span class="hljs-number">1</span>, s=<span class="hljs-number">2</span>)<br><br><span class="hljs-comment"># output</span><br><span class="hljs-number">1</span><br>()<br>&#123;<span class="hljs-string">&#x27;f&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;s&#x27;</span>: <span class="hljs-number">2</span>&#125;<br>    <br><span class="hljs-comment"># 传入整个字典    </span><br><span class="hljs-comment"># input</span><br>a, b, c = <span class="hljs-number">1</span>, [<span class="hljs-string">&#x27;1&#x27;</span>, <span class="hljs-string">&#x27;2&#x27;</span>, <span class="hljs-string">&#x27;3&#x27;</span>], &#123;<span class="hljs-string">&#x27;f&#x27;</span>:<span class="hljs-number">1</span>, <span class="hljs-string">&#x27;s&#x27;</span>:<span class="hljs-number">2</span>, <span class="hljs-string">&#x27;t&#x27;</span>:<span class="hljs-number">3</span>&#125;<br>test_kwargs(a, b, **c) <span class="hljs-comment"># 注意字典参数前要加 `**`</span><br><br><span class="hljs-comment"># output</span><br><span class="hljs-number">1</span><br>([<span class="hljs-string">&#x27;1&#x27;</span>, <span class="hljs-string">&#x27;2&#x27;</span>, <span class="hljs-string">&#x27;3&#x27;</span>],)<br>&#123;<span class="hljs-string">&#x27;f&#x27;</span>: <span class="hljs-number">1</span>, <span class="hljs-string">&#x27;s&#x27;</span>: <span class="hljs-number">2</span>, <span class="hljs-string">&#x27;t&#x27;</span>: <span class="hljs-number">3</span>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Coding</category>
      
      <category>Python</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LaTeX 符号</title>
    <link href="/2022/01/15/LaTeX-notations/"/>
    <url>/2022/01/15/LaTeX-notations/</url>
    
    <content type="html"><![CDATA[<h2 id="字体样式"><a href="#字体样式" class="headerlink" title="字体样式"></a>字体样式</h2><h3 id="美术字-calligraphy"><a href="#美术字-calligraphy" class="headerlink" title="美术字 (calligraphy)"></a>美术字 (calligraphy)</h3><blockquote><p>\mathcal{A}：$\mathcal{A}$ </p></blockquote><p>字体样式如下：</p><p>$\mathcal{A}, \mathcal{B},\mathcal{C},\mathcal{D},\mathcal{E},\mathcal{F},\mathcal{G},\mathcal{H},\mathcal{I},\mathcal{K},\mathcal{L},\mathcal{M},\mathcal{N},\mathcal{O},\mathcal{P},\mathcal{Q},\mathcal{R},\mathcal{S},\mathcal{T},\mathcal{U},\mathcal{V},\mathcal{W},\mathcal{X},\mathcal{Y},\mathcal{Z}$</p><h3 id="黑板粗体-blackboard-bold"><a href="#黑板粗体-blackboard-bold" class="headerlink" title="黑板粗体 (blackboard bold)"></a>黑板粗体 (blackboard bold)</h3><blockquote><p>\mathbb{A}：$\mathbb{A}$</p></blockquote><p>字体样式如下：</p><p>$\mathbb{A}, \mathbb{B},\mathbb{C},\mathbb{D},\mathbb{E},\mathbb{F},\mathbb{G},\mathbb{H},\mathbb{I},\mathbb{K},\mathbb{L},\mathbb{M},\mathbb{N},\mathbb{O},\mathbb{P},\mathbb{Q},\mathbb{R},\mathbb{S},\mathbb{T},\mathbb{U},\mathbb{V},\mathbb{W},\mathbb{X},\mathbb{Y},\mathbb{Z}$</p><h3 id="尖角体-fraktur"><a href="#尖角体-fraktur" class="headerlink" title="尖角体 (fraktur)"></a>尖角体 (fraktur)</h3><blockquote><p>\mathfrak{A}：$\mathfrak{A}$</p></blockquote><p>字体样式如下：</p><p>$\mathfrak{A}, \mathfrak{B},\mathfrak{C},\mathfrak{D},\mathfrak{E},\mathfrak{F},\mathfrak{G},\mathfrak{H},\mathfrak{I},\mathfrak{K},\mathfrak{L},\mathfrak{M},\mathfrak{N},\mathfrak{O},\mathfrak{P},\mathfrak{Q},\mathfrak{R},\mathfrak{S},\mathfrak{T},\mathfrak{U},\mathfrak{V},\mathfrak{W},\mathfrak{X},\mathfrak{Y},\mathfrak{Z}$</p><h3 id="影魔体-shadow-fiend"><a href="#影魔体-shadow-fiend" class="headerlink" title="影魔体 (shadow fiend)"></a>影魔体 (shadow fiend)</h3><blockquote><p>\mathsf{A}：$\mathsf{A}$</p></blockquote><p>字体样式如下：</p><p>$\mathsf{A}, \mathsf{B},\mathsf{C},\mathsf{D},\mathsf{E},\mathsf{F},\mathsf{G},\mathsf{H},\mathsf{I},\mathsf{K},\mathsf{L},\mathsf{M},\mathsf{N},\mathsf{O},\mathsf{P},\mathsf{Q},\mathsf{R},\mathsf{S},\mathsf{T},\mathsf{U},\mathsf{V},\mathsf{W},\mathsf{X},\mathsf{Y},\mathsf{Z}$</p><h3 id="矩阵体-math-boldface"><a href="#矩阵体-math-boldface" class="headerlink" title="矩阵体 (math boldface)"></a>矩阵体 (math boldface)</h3><blockquote><p>\mathbf{A}：$\mathbf{A}$</p></blockquote><p>字体样式如下：</p><p>$\mathbf{A}, \mathbf{B},\mathbf{C},\mathbf{D},\mathbf{E},\mathbf{F},\mathbf{G},\mathbf{H},\mathbf{I},\mathbf{K},\mathbf{L},\mathbf{M},\mathbf{N},\mathbf{O},\mathbf{P},\mathbf{Q},\mathbf{R},\mathbf{S},\mathbf{T},\mathbf{U},\mathbf{V},\mathbf{W},\mathbf{X},\mathbf{Y},\mathbf{Z}$</p><h3 id="打字机字体"><a href="#打字机字体" class="headerlink" title="打字机字体"></a>打字机字体</h3><blockquote><p>\mathtt{A}：$\mathtt{A}$</p></blockquote><p>$\mathtt{A}, \mathtt{B},\mathtt{C},\mathtt{D},\mathtt{E},\mathtt{F},\mathtt{G},\mathtt{H},\mathtt{I},\mathtt{K},\mathtt{L},\mathtt{M},\mathtt{N},\mathtt{O},\mathtt{P},\mathtt{Q},\mathtt{R},\mathtt{S},\mathtt{T},\mathtt{U},\mathtt{V},\mathtt{W},\mathtt{X},\mathtt{Y},\mathtt{Z}$</p><h3 id="斜体"><a href="#斜体" class="headerlink" title="斜体"></a>斜体</h3><blockquote><p>\mathit{A}：$\mathit{A}$</p></blockquote><p>$\mathit{A}, \mathit{B},\mathit{C},\mathit{D},\mathit{E},\mathit{F},\mathit{G},\mathit{H},\mathit{I},\mathit{K},\mathit{L},\mathit{M},\mathit{N},\mathit{O},\mathit{P},\mathit{Q},\mathit{R},\mathit{S},\mathit{T},\mathit{U},\mathit{V},\mathit{W},\mathit{X},\mathit{Y},\mathit{Z}$</p><h3 id="罗马字体"><a href="#罗马字体" class="headerlink" title="罗马字体"></a>罗马字体</h3><blockquote><p>\mathrm{A}：$\mathrm{A}$</p></blockquote><p>$\mathrm{A}, \mathrm{B},\mathrm{C},\mathrm{D},\mathrm{E},\mathrm{F},\mathrm{G},\mathrm{H},\mathrm{I},\mathrm{K},\mathrm{L},\mathrm{M},\mathrm{N},\mathrm{O},\mathrm{P},\mathrm{Q},\mathrm{R},\mathrm{S},\mathrm{T},\mathrm{U},\mathrm{V},\mathrm{W},\mathrm{X},\mathrm{Y},\mathrm{Z}$</p><h2 id="数学符号"><a href="#数学符号" class="headerlink" title="数学符号"></a>数学符号</h2><h3 id="数学模式重音符号"><a href="#数学模式重音符号" class="headerlink" title="数学模式重音符号"></a>数学模式重音符号</h3><img src="math_hat.png"/><h3 id="希腊字母"><a href="#希腊字母" class="headerlink" title="希腊字母"></a>希腊字母</h3><img src="greek_alphabet.png"/><h3 id="二元关系"><a href="#二元关系" class="headerlink" title="二元关系"></a>二元关系</h3><img src="binary_relation.png"/><p>否定形式为前面加上 <code>\not</code>，例如 <code>\not\in</code>：$\not\in$。</p><h3 id="二元运算符"><a href="#二元运算符" class="headerlink" title="二元运算符"></a>二元运算符</h3><img src="binary_computation.png"/><h3 id="“大”运算符"><a href="#“大”运算符" class="headerlink" title="“大”运算符"></a>“大”运算符</h3><img src="other.png"/><h3 id="箭头"><a href="#箭头" class="headerlink" title="箭头"></a>箭头</h3><img src="arrows.png"/><h3 id="其他运算符"><a href="#其他运算符" class="headerlink" title="其他运算符"></a>其他运算符</h3><img src="exception.png"/>]]></content>
    
    
    <categories>
      
      <category>Writing</category>
      
      <category>LaTeX</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LaTeX</tag>
      
      <tag>Writing</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Blog Writing</title>
    <link href="/2022/01/14/Blog-Writing/"/>
    <url>/2022/01/14/Blog-Writing/</url>
    
    <content type="html"><![CDATA[<h2 id="正常创建新文章"><a href="#正常创建新文章" class="headerlink" title="正常创建新文章"></a>正常创建新文章</h2><p>我们正常使用Hexo进行写作的时候，一般使用 <code>hexo new &lt;title&gt;</code> 来建立文章，默认是缺省了一个布局参数的，完整的命令应该 <code>hexo new [layout] &lt;title&gt;</code> 。</p><p>不指定布局(layout)时，默认布局就是 <code>post</code> ，等同于 <code>hexo new post 文章名</code>。</p><p>这种方式创建的文章 <code>md</code> 源码默认存放在 <code>source/_posts</code> 路径下，当我们执行 <code>hexo deploy</code> 部署时，自动发布出来。</p><h2 id="创建草稿文章"><a href="#创建草稿文章" class="headerlink" title="创建草稿文章"></a>创建草稿文章</h2><p>但是有些时候，我们的博客文章不是一次写完的，可能中间的写作断断续续会持续一段时间，这种情况下，将写到一半的文章发布到博客网站上显然是不太合适的。</p><p>这时候 <code>draft</code> 布局就有作用了。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">创建草稿布局文章的命令</span><br>hexo new draft &lt;title&gt;<br></code></pre></td></tr></table></figure><p><code>draft</code> 顾名思义就是草稿的意思，使用 <code>draft</code> 布局建立的文章，其博客文章 <code>md</code> 源码位于 <code>source/_drafts</code> 路径下， <code>hexo generate</code> 不会将其编译到 <code>public</code> 目录下，所以 <code>hexo deploy</code> 也不会将其部署发布到博客网站上。</p><p>当我们写完整篇博客文章时，可以将草稿发布为正式文章，<code>hexo</code> 会将发布为正式文章的草稿文章源码从 <code>source/_drafts</code> 路径下，移到 <code>source/_posts</code> 下，这样就转成了正式文章，简单明了效果好。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">将草稿发布为正式文章的命令</span><br>hexo publish &lt;filename&gt;<br></code></pre></td></tr></table></figure><h2 id="预览草稿"><a href="#预览草稿" class="headerlink" title="预览草稿"></a>预览草稿</h2><p><code>hexo generate</code> 不会编译 <code>source/_drafts</code> 目录下的文章，但是我们编写博客文章的过程中，可能需要查看预览，所以 <code>hexo</code> 也提供了预览草稿文章的方法。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">Hexo 预览草稿的命令</span><br>hexo s --draft<br></code></pre></td></tr></table></figure><p>至此，我们就可以愉快的写需要长时间编写的博客文章了。</p>]]></content>
    
    
    <categories>
      
      <category>Blog Building</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Writing</tag>
      
      <tag>Markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于腾讯云的博客服务器部署</title>
    <link href="/2022/01/13/Blog-Remote-Deploy/"/>
    <url>/2022/01/13/Blog-Remote-Deploy/</url>
    
    <content type="html"><![CDATA[<h2 id="服务器属性"><a href="#服务器属性" class="headerlink" title="服务器属性"></a>服务器属性</h2><p>因为是个人博客，访问流量不大，选择了腾讯的 30 多块的服务器，配置如下：</p><ul><li>CPU：1核</li><li>内存：2 GB</li><li>系统盘：50 GB SSD</li><li>流量：500 GB&#x2F;月</li><li>带宽：5 Mbps</li><li>操作系统：CentOS 7.8 64bit</li></ul><p>由于操作系统为 CentOS，和其他版本的 Linux 不同，所以下文安装软件使用 <code>yum</code> 而不是 <code>apt-get</code></p><h2 id="服务器用户配置"><a href="#服务器用户配置" class="headerlink" title="服务器用户配置"></a>服务器用户配置</h2><h3 id="腾讯云官方直接操作"><a href="#腾讯云官方直接操作" class="headerlink" title="腾讯云官方直接操作"></a>腾讯云官方直接操作</h3><p>发现直接使用腾讯云服务器管理的重置实例密码就能完成登录了…指定用户名然后手动设置密码，非常简单，搞了额外操作的我像个憨憨。。。我搞的额外操作写在下面。</p><h3 id="其他参考操作"><a href="#其他参考操作" class="headerlink" title="其他参考操作"></a>其他参考操作</h3><p>由于服务器使用的是镜像盘，刚开始登录时不是用的自己的用户名和密码登录，所以这里删除其他所有用户，新建自己的用户。</p><p>执行之后的操作，需要切换到 root 用户，首先重置 root 用户的密码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">sudo passwd root<br></code></pre></td></tr></table></figure><p>然后切换至 root 账号，输入密码：</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs nginx"><span class="hljs-attribute">su</span> -l root<br><span class="hljs-comment"># -l 选项完整切换工作环境</span><br></code></pre></td></tr></table></figure><p>创建自己的账户并修改密码：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">useradd rosmantis<br>passwd rosmantis<br></code></pre></td></tr></table></figure><h2 id="连接服务器"><a href="#连接服务器" class="headerlink" title="连接服务器"></a>连接服务器</h2><p><strong>如果直接使用服务器方配置SSH 连接服务器，直接跳过此大节。</strong></p><hr><p>本地为 Windows 客户端，选择 PuTTY 作为软件连接远端服务器。</p><p>以下操作需要通过腾讯云远程登录到服务器进行服务器操作。</p><h3 id="安装依赖包"><a href="#安装依赖包" class="headerlink" title="安装依赖包"></a>安装依赖包</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">yum install openssh-server xbase-clients<br></code></pre></td></tr></table></figure><h3 id="启用SSH"><a href="#启用SSH" class="headerlink" title="启用SSH"></a>启用SSH</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">service sshd start<br></code></pre></td></tr></table></figure><h3 id="安装-PuTTY"><a href="#安装-PuTTY" class="headerlink" title="安装 PuTTY"></a>安装 PuTTY</h3><p>PuTTY 可以从 <a href="https://www.chiark.greenend.org.uk/~sgtatham/putty/latest.html">官网</a> 下载，这里选择 64-bit x86 的。</p><img src="PuTTY.png" alt="PuTTY Config"/><p>IP 输入自己服务器的 IP，端口选择通用设置 22，Saved Sessions 里面填写会话名称 (自己随便定义)。</p><h4 id="无密码登录"><a href="#无密码登录" class="headerlink" title="无密码登录"></a>无密码登录</h4><p>如果想使用 SSH Key 连接，每次不输入密码，需要本地生成 SSH 私钥和公钥对，输入以下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa<br></code></pre></td></tr></table></figure><p>然后使用 <code>ssh-copy-id</code> 将公钥复制到远程服务器中，rosmantis 是此时我的用户名，用自己的用户名代替，@后面为服务器 IP：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-copy-id rosmantis@159.75.40.50<br></code></pre></td></tr></table></figure><p><strong>注意：</strong> 无密码登录在生成公钥私钥对时不要输入密码，直接 <code>Enter</code> 。</p><p>之后通过 PuTTY 客户端直接登录服务器即可，如果想不每次输入自己的用户名和密码，在 PuTTY 桌面客户端属性的目标后面添加 <code>-load &quot;会话名称&quot; -l 用户名 -ssh -pw 密码</code>。</p><h4 id="小报错"><a href="#小报错" class="headerlink" title="小报错"></a>小报错</h4><ul><li><p>no supported authentication methods available</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">vi /etc/ssh/sshd_config<br><span class="hljs-comment"># 查找 PasswordAuthentication, 将其改为 yes 并保存退出</span><br>systemctl restart sshd <span class="hljs-comment"># 重启 SSH 服务</span><br></code></pre></td></tr></table></figure></li></ul><h3 id="给用户添加-root-权限"><a href="#给用户添加-root-权限" class="headerlink" title="给用户添加 root 权限"></a>给用户添加 root 权限</h3><p>添加权限需要编辑 sudoers 文件实现，分为以下几个步骤：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 先修改 sudoers 的编辑权限</span><br><span class="hljs-built_in">chmod</span> 740 /etc/sudoers<br>vim /etc/sudoers<br></code></pre></td></tr></table></figure><p>找到以下内容：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">## Allow root to run any commands anywhere</span><br>root    ALL=(ALL)       ALL<br></code></pre></td></tr></table></figure><p>在该语句下面添加：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">rosmantis ALL=(ALL) ALL<br><span class="hljs-comment"># rosmantis 为自己的用户名</span><br></code></pre></td></tr></table></figure><p>退出并还原 sudoers 文件权限：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">chmod</span> 400 /etc/sudoers<br></code></pre></td></tr></table></figure><h2 id="服务器配置"><a href="#服务器配置" class="headerlink" title="服务器配置"></a>服务器配置</h2><h3 id="安装依赖包-1"><a href="#安装依赖包-1" class="headerlink" title="安装依赖包"></a>安装依赖包</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel<br>yum install gcc perl-ExtUtils-MakeMaker<br></code></pre></td></tr></table></figure><p>遇到选项输入 <code>y</code> 即可，等待 <code>Complete!</code> 下载安装结束 。</p><h3 id="安装-Git"><a href="#安装-Git" class="headerlink" title="安装 Git"></a>安装 Git</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">yum install git<br>git --version<br><span class="hljs-comment"># 出现版本信息安装成功</span><br></code></pre></td></tr></table></figure><h3 id="SSH-连接"><a href="#SSH-连接" class="headerlink" title="SSH 连接"></a>SSH 连接</h3><p>如果之前已经创建过 SSH 连接，则不需要此步骤。</p><h4 id="本地使用-git-bash-创建密钥"><a href="#本地使用-git-bash-创建密钥" class="headerlink" title="本地使用 git bash 创建密钥"></a>本地使用 git bash 创建密钥</h4><p><strong>如果已经有本地密钥，不需要再次生成</strong></p><hr><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa<br></code></pre></td></tr></table></figure><h4 id="远程拷贝密钥"><a href="#远程拷贝密钥" class="headerlink" title="远程拷贝密钥"></a>远程拷贝密钥</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">su rosmantis<br><span class="hljs-built_in">cd</span> ~<br><span class="hljs-built_in">mkdir</span> .ssh<br>vi .ssh/authorized_keys<br><span class="hljs-built_in">chmod</span> 600 .ssh/authorized_keys<br><span class="hljs-built_in">chmod</span> 700 .ssh<br></code></pre></td></tr></table></figure><p>这里注意权限一定要对，<code>authorized_keys</code> 是 <code>600</code>，<code>.ssh</code> 是 <code>700</code>。</p><h4 id="本地测试"><a href="#本地测试" class="headerlink" title="本地测试"></a>本地测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh -v rosmantis@159.75.40.50 <span class="hljs-comment"># 用户名@IP</span><br></code></pre></td></tr></table></figure><h4 id="小报错-1"><a href="#小报错-1" class="headerlink" title="小报错"></a>小报错</h4><p>如果之前有用 SSH 连接过远端服务器，那么本地 Host Key 中会存有历史信息，可能会有以下报错：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">Host key <span class="hljs-keyword">for</span> IP has changed and you have requested strict checking.<br>Host key verification failed.<br></code></pre></td></tr></table></figure><p>把 本地<code>.ssh/known_hosts</code> 中有自己 IP 的项都删了再重新连接就行。</p><h3 id="安装和配置-Nginx"><a href="#安装和配置-Nginx" class="headerlink" title="安装和配置 Nginx"></a>安装和配置 Nginx</h3><h4 id="安装-Nginx"><a href="#安装-Nginx" class="headerlink" title="安装 Nginx"></a>安装 Nginx</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">yum install -y nginx<br>systemctl start nginx.service<br></code></pre></td></tr></table></figure><h4 id="小报错-2"><a href="#小报错-2" class="headerlink" title="小报错"></a>小报错</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">no package nginx available<br></code></pre></td></tr></table></figure><p>手动安装 Nginx，详情参考 <a href="https://www.lilinchao.com/archives/939.html">CentOS 7安装Nginx教程</a>。</p><p>添加软链：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">ln</span> -s /usr/local/nginx/sbin/nginx /usr/sbin/<br></code></pre></td></tr></table></figure><p>将 Nginx 添加为系统服务并设置开机自启动：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> /etc/systemd/system/<br>vim nginx.service<br></code></pre></td></tr></table></figure><p>编辑内容如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">[Unit]<br>Description=nginx<br>After=syslog.target network.terget<br>[Service]<br>Type=forking<br>ExecStart=/usr/sbin/nginx -c /usr/local/nginx/conf/nginx.conf<br>ExecReload=/usr/sbin/nginx -s reload<br>ExecStop=/usr/sbin/nginx -s stop<br>User=root<br>Group=root<br>[Install]<br>WantedBy=multi-user.target<br></code></pre></td></tr></table></figure><p>刷新系统服务：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">systemctl daemon-reload<br></code></pre></td></tr></table></figure><p>其他各类操作：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 添加到开机自启动：</span><br>systemctl <span class="hljs-built_in">enable</span> nginx.service<br><span class="hljs-comment"># 服务启动、停止、重新载入命令：</span><br>systemctl start nginx.service<br>systemctl stop nginx.service<br>systemctl reload nginx.service<br></code></pre></td></tr></table></figure><h4 id="配置云服务器网站文件夹"><a href="#配置云服务器网站文件夹" class="headerlink" title="配置云服务器网站文件夹"></a>配置云服务器网站文件夹</h4><p>在云服务器中创建自己的网站目录并设置权限：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> /home/rosmantis/blog<br><span class="hljs-built_in">chown</span> rosmantis:rosmantis -R /home/rosmantis/blog <span class="hljs-comment"># rosmantis 处为自己的用户名</span><br></code></pre></td></tr></table></figure><p>配置 Nginx：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">nginx -t  // 命令查看位置，一般为 /etc/nginx/nginx.conf。<br>vim /etc/nginx/nginx.conf <span class="hljs-comment"># 修改配置文件，在server_name后添加自己的域名(要备案), root后添加网站目录路径, 此处为/home/rosmantis/blog</span><br><span class="hljs-comment"># 把最上面的 user 改为自己的名字</span><br></code></pre></td></tr></table></figure><h3 id="创建-Git-仓库"><a href="#创建-Git-仓库" class="headerlink" title="创建 Git 仓库"></a>创建 Git 仓库</h3><p>注意此处不要用 root 账号，使用自己的账号。不然有可能会出现远端无权限访问的情况。</p><p>建立 git 仓库并修改权限</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">mkdir</span> rosmantis.git<br><span class="hljs-built_in">cd</span> rosmantis.git<br>git init --bare<br></code></pre></td></tr></table></figure><p>同步网站根目录：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">vi hooks/post-receive<br><span class="hljs-comment"># 填入以下内容 注意 work-tree 为自己的博客部署文件夹, git-dir Git 版本控制的文件夹</span><br><span class="hljs-comment">#!/bin/bash</span><br>git --work-tree=/home/rosmantis/blog --git-dir=/home/rosmantis/rosmantis.git checkout -f<br></code></pre></td></tr></table></figure><p>修改权限：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">chmod</span> +x hooks/post-receive<br></code></pre></td></tr></table></figure><p>刷新一下 Nginx：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">service nginx restart<br></code></pre></td></tr></table></figure><h2 id="本地部署"><a href="#本地部署" class="headerlink" title="本地部署"></a>本地部署</h2><p>在本地 Hexo 目录下修改 <code>_config.yml</code> 文件中的 deploy 后的 repo：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">rosmantis@SERVER:/home/rosmantis/rosmantis.git<br><span class="hljs-comment"># rosmantis 为用户名, SERVER 为 IP, 后面是自己的库工具</span><br></code></pre></td></tr></table></figure><p>以上完成后，本地执行 Hexo 部署命令  <code>Hexo d -g</code> 即可完成腾讯云服务器上的部署，Over！</p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li>[1] <a href="https://blog.csdn.net/chen1234520nnn/article/details/109315903">SSH 实现远程服务器 (主机) 无密码登录</a></li><li>[2] <a href="https://cloud.tencent.com/developer/article/1620879?from=15425">Hexo 博客部署腾讯云</a></li><li>[3] <a href="https://blog.csdn.net/IMW_MG/article/details/77893220">使用shell脚本批量删除除root用户以外的其它用户</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Blog Building</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>Tencent Cloud</tag>
      
      <tag>Remote Server</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch Tutorial</title>
    <link href="/2022/01/13/Pytorch-Tutorial/"/>
    <url>/2022/01/13/Pytorch-Tutorial/</url>
    
    <content type="html"><![CDATA[<h2 id="基础元素-Tensor"><a href="#基础元素-Tensor" class="headerlink" title="基础元素 Tensor"></a>基础元素 Tensor</h2><p>Tensor 是 PyTorch 中的一个基础数据结构，和 numpy 中的 ndarray 非常相近，我们使用 tensors 去编码输入和输出，还有模型参数。</p><h3 id="生成操作"><a href="#生成操作" class="headerlink" title="生成操作"></a>生成操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">x_ones = torch.ones_like(data) <span class="hljs-comment"># 生成和 data 大小一样的全1 tensor</span><br>x_rand = torch.rand_like(data) <span class="hljs-comment"># 生成和 data 大小一样的随机 tensor (value 0~1)</span><br><br>shape = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>] <span class="hljs-comment"># 指定大小</span><br>rand_tensor = torch.rand(shape)<br>zeros_tensor = torch.zeros(shape)<br>ones_tensor = torch.ones(shape)<br></code></pre></td></tr></table></figure><h3 id="Tensor-属性"><a href="#Tensor-属性" class="headerlink" title="Tensor 属性"></a>Tensor 属性</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">tensor = torch.rand(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>)<br>tensor.shape <span class="hljs-comment"># Shape of tensor</span><br>tensor.dtype <span class="hljs-comment"># Datatype of tensor</span><br>tensor.device <span class="hljs-comment"># Device that tensor is stored on</span><br></code></pre></td></tr></table></figure><h3 id="Tensor-操作"><a href="#Tensor-操作" class="headerlink" title="Tensor 操作"></a>Tensor 操作</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 索引, 切片操作和 Numpy 一致</span><br><span class="hljs-comment"># join 操作</span><br>t1 = torch.cat([tensor, tensor, tensor], dim=<span class="hljs-number">1</span>)<br><span class="hljs-comment"># 算术操作</span><br><br><span class="hljs-comment"># tensors 之间的矩阵乘法, y1, y2, y3 会有相同的值 </span><br>y1 = tensor @ tensor.T<br>y2 = tensor.matmul(tensor.T)<br>torch.matmul(tensor, tensor.T, out=y3)<br><br><span class="hljs-comment"># tensors 之间的 element-wise product (点乘), z1, z2, z3 会有相同的只</span><br>z1 = tensor * tensor<br>z2 = tensor.mul(tensor)<br>torch.mul(tensor, tensor, out=z3)<br><br><span class="hljs-comment"># 单个元素取值操作, 当只有一个元素时, 可以将它转换成Python数值</span><br>value = value.item()<br><br><span class="hljs-comment"># In-place 操作, 会替换之前元素的存储空间, 在其他操作后加上 _ 后缀</span><br>tensor.add_(<span class="hljs-number">5</span>)<br>tensor.copy_(x)<br>tensor.t_(x)<br></code></pre></td></tr></table></figure><h3 id="和-Numpy-的关联"><a href="#和-Numpy-的关联" class="headerlink" title="和 Numpy 的关联"></a>和 Numpy 的关联</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Tensor to Numpy</span><br>np = tensor.numpy()<br><span class="hljs-comment"># Numpy to Tensor</span><br>tensor = torch.from_numpy(np)<br></code></pre></td></tr></table></figure><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><p>PyTorch 处理数据有两个前提：<code>torch.utils.data.Dataset</code> 和 <code>torch.utils.data.DataLoader</code>。<code>Dataset</code> 存储样本和它们对应的标签，<code>DataLoader</code> 对 <code>Dataset</code> 绑定迭代轮数。</p><h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p><code>torchvision.datasets</code> 模块包含许多真实世界图像数据如 CIFAR, COCO (<a href="https://pytorch.org/vision/stable/datasets.html">full list here</a>)。</p><p>所有数据集都是 <code>torch.utils.data.Dataset</code> 的子类，也就是说，它们都有 <code>__getitem__</code> 和 <code>__len__</code> 这两个API。所以，它们可以通过 <code>torch.multiprocessing</code> 给 <code>torch.utils.data.DataLoader</code> 传递多个样本实现多线程。</p><p>所有数据集都有类似的API。它们有两个共同参数 <code>transform</code> 和 <code>target_transform</code> 来分别转换 input 和 target。可以通过提供的 <a href="https://pytorch.org/vision/stable/datasets.html#base-classes-datasets">base classes</a> 创建自己的数据集。</p><h4 id="导入官方提供数据集"><a href="#导入官方提供数据集" class="headerlink" title="导入官方提供数据集"></a>导入官方提供数据集</h4><p>此处以 <code>ImageNet ILSVRC2012</code> 数据集举例，但 PyTorch 不提供 ImageNet 数据集的下载，需要自己下载数据集后放在root路径，此处放在 <code>./dataset</code> 路径下。如果 PyTorch 有提供数据集下载，<code>download=True</code> 后会将数据集下载在 <code>root</code> 路径下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> ToTensor<br><br><span class="hljs-comment"># training_data = datasets.ImageNet(root=&quot;dataset&quot;, train=True, download=True, transform=ToTensor())</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">download = True 会报错, 原因上述已经提到, PyTorch 库中代码根本没有下载, 源代码如下</span><br><span class="hljs-string">if download is True:</span><br><span class="hljs-string">msg = (&quot;The dataset is no longer publicly accessible. You need to &quot;</span><br><span class="hljs-string">   &quot;download the archives externally and place them in the root &quot;</span><br><span class="hljs-string">           &quot;directory.&quot;)</span><br><span class="hljs-string">raise RuntimeError(msg)</span><br><span class="hljs-string">elif download is False:</span><br><span class="hljs-string">    msg = (&quot;The use of the download flag is deprecated, since the dataset &quot;</span><br><span class="hljs-string">           &quot;is no longer publicly accessible.&quot;)</span><br><span class="hljs-string">    warnings.warn(msg, RuntimeWarning)</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br>training_data = datasets.ImageNet(root=<span class="hljs-string">&quot;dataset&quot;</span>, train=<span class="hljs-literal">True</span>, transform=ToTensor())<br>test_data = datasets.ImageNet(root=<span class="hljs-string">&quot;dataset&quot;</span>, train=<span class="hljs-literal">False</span>, transform=ToTensor())<br></code></pre></td></tr></table></figure><h4 id="创建自定义数据集"><a href="#创建自定义数据集" class="headerlink" title="创建自定义数据集"></a>创建自定义数据集</h4><p><code>Dataset</code> 类的部分内容如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Dataset</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;An abstract class representing a Dataset.</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    All other datasets should subclass it. All subclasses should overide ``__len__``,     that provides the size of the dataset, and ``__getitem__``, supporing integer     indexing in range from 0 to len(self) exclusive.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br>        <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">raise</span> NotImplementedError<br></code></pre></td></tr></table></figure><p>子类继承父类 <code>Dataset</code> 时，必须重写 <code>__getitem__</code> 和 <code>__len__</code> 方法，否则将会报错。</p><p>其中 <code>__getitem__</code> 实现通过索引来返回图像数据的功能，<code>__len__</code> 返回数据集的大小。</p><p>要自定义数据集，首先要继承 <code>Dataset</code> 类，然后在 <code>__init__</code> 方法中对数据进行整理，给图片打标签，划分数据集等等。</p><p>Example：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">PCIEDataset</span>(<span class="hljs-title class_ inherited__">Dataset</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, root, size, mode</span>):<br>        <span class="hljs-built_in">super</span>(PCIEDataset, self).__init__()<br>        self.root = root<br>        self.size = size<br>        <br>        self.images, self.labels = load_images(self.root) <span class="hljs-comment"># 从路径中读取文件</span><br>        <span class="hljs-comment"># 图像处理, 任意什么处理都可以, 这里只是简单 resize</span><br>        self.images = [x.reshape(self.size) <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> self.images] <span class="hljs-comment"># 将图片resize</span><br>        <br>        <span class="hljs-comment"># 对数据集进行划分</span><br>        <span class="hljs-keyword">if</span> mode == <span class="hljs-string">&#x27;train&#x27;</span>: <span class="hljs-comment"># 60%</span><br>            self.images = self.images[:<span class="hljs-built_in">int</span>(<span class="hljs-number">0.6</span>*<span class="hljs-built_in">len</span>(self.images))]<br>            self.labels = self.labels[:<span class="hljs-built_in">int</span>(<span class="hljs-number">0.6</span>*<span class="hljs-built_in">len</span>(self.labels))]<br>        <span class="hljs-keyword">elif</span> mode == <span class="hljs-string">&#x27;val&#x27;</span>: <span class="hljs-comment"># 40%</span><br>            self.images = self.images[-<span class="hljs-built_in">int</span>(<span class="hljs-number">0.4</span>*<span class="hljs-built_in">len</span>(self.images))]<br>            self.labels = self.labels[-<span class="hljs-built_in">int</span>(<span class="hljs-number">0.4</span>*<span class="hljs-built_in">len</span>(self.labels))]<br>            <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):<br>        img, label = self.images[index], self.labels[index]<br>        <span class="hljs-keyword">return</span> torch.tensor(img), torch.tensor(label)<br>    <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">len</span>(self.images)<br></code></pre></td></tr></table></figure><h3 id="DataLoader"><a href="#DataLoader" class="headerlink" title="DataLoader"></a>DataLoader</h3><p><code>Dataset</code> 每次检索提供一个样本和一个标签，在训练模型时，我们通常通过 minibatches 来取数据集，在每个 epoch 重新打乱数据来避免模型过拟合，并且使用 Python 的 <code>multiprocessing</code> 对数据检索加速。</p><p>DataLoader 类的定义如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">torch</span>.utils.data.DataLoader(<br>dataset,<span class="hljs-comment"># 加载数据的数据集</span><br>    batch_size=<span class="hljs-number">1</span>,<span class="hljs-comment"># 每个 batch 加载多少个样本</span><br>    shuffle=<span class="hljs-literal">False</span>,<span class="hljs-comment"># 在每个 epoch 重新打乱数据</span><br>    sampler=<span class="hljs-literal">None</span>,<span class="hljs-comment"># 从数据集中生成 index 的方式</span><br>    batch_sampler=<span class="hljs-literal">None</span>,<br>    num_workers=<span class="hljs-number">0</span>,<span class="hljs-comment"># 用多少个子进程加载数据, 0 默认单进程</span><br>    collate_fn=&lt;function default_collate&gt;,<span class="hljs-comment"># 将一个 batch 的数据集和标签进行合并操作</span><br>    pin_memory=<span class="hljs-literal">False</span>,<span class="hljs-comment"># True 时, 最开始生成的内存属于锁页内存, 转义到GPU的显存速度会更快一点</span><br>    drop_last=<span class="hljs-literal">False</span><br>    <span class="hljs-comment"># 如果数据集大小不能被 batchsize 整除, 则为True后可以删除最后一个不完整的 batch, 如果为False, 则最后一个 batch 将会更小 </span><br>)<br></code></pre></td></tr></table></figure><p>Example：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">train_loader = DataLoader(dataset, batch_size=<span class="hljs-number">64</span>, shuffle=<span class="hljs-literal">True</span>, pin_memory=<span class="hljs-literal">True</span>)<br><br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(epochs):<br>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">input</span>, label <span class="hljs-keyword">in</span> train_loader:<br>        <span class="hljs-comment"># 训练操作</span><br></code></pre></td></tr></table></figure><h2 id="变换-Transforms"><a href="#变换-Transforms" class="headerlink" title="变换 (Transforms)"></a>变换 (Transforms)</h2><p>由于大多数据在进行训练之前都需要进行处理，PyTorch 内置了一些函数，来方便用户对图像等数据进行处理。</p><p>以下提到的类都在 <code>torchvision.transforms</code> 下，例如 <code>torchvision.transforms.Compose</code></p><h3 id="裁剪"><a href="#裁剪" class="headerlink" title="裁剪"></a>裁剪</h3><h4 id="CenterCrop"><a href="#CenterCrop" class="headerlink" title="CenterCrop"></a>CenterCrop</h4><p>将给定的 <code>PIL.Image</code> 进行中心切割，得到给定的 size。 size 可以是一个 tuple ([height, width])，也可以是一个整数，在整数的情况下，切割出来的图片形状是正方形。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">CenterCrop([h, w])<br>CenterCrop(size)<br></code></pre></td></tr></table></figure><h4 id="RandomCrop"><a href="#RandomCrop" class="headerlink" title="RandomCrop"></a>RandomCrop</h4><p>切割中心点的位置随便选取，根据给定的 size 进行切割，具体参数如下。</p><ul><li>size：可以是 tuple 也可以是整数。</li><li>padding：设置填充多少个 pixel。当为 <code>int</code> 时，图像上下左右均填充 <code>int</code> 个，若有两个数，则第一个数为左右扩充多少，第二个数表示上下的。当有 4 个数时，则为 左、上、右、下 各填充多少个。</li><li>fill：填充的值 (仅当填充 mode 为 ‘constant’ 时有效。当为 <code>int</code> 时，各通道均填充该值，当为 [r, g, b] tuple 时，表示RGB通道分别填充的值。</li><li>padding_mode：有 4 种填充模式：<ul><li>constant 常量。</li><li>edge 按照图片边缘像素值填充。</li><li>reflect 。以边缘值为中心做镜面对称，如 [1, 2, 3, 4] 边缘扩充一个值，结果为 [2, 1, 2, 3, 4, 3]。</li><li>symmetric。以边缘为中心做镜面对称，如 [1, 2, 3, 4] 边缘扩充一个值，结果为 [1, 1, 2, 3, 4, 4]。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">RandomCrop(size, padding=<span class="hljs-literal">None</span>, pad_if_needed=<span class="hljs-literal">False</span>, fill=<span class="hljs-number">0</span>, padding_mode=<span class="hljs-string">&#x27;constant&#x27;</span>)<br></code></pre></td></tr></table></figure><h4 id="RandomResizedCrop"><a href="#RandomResizedCrop" class="headerlink" title="RandomResizedCrop"></a>RandomResizedCrop</h4><p>随机长宽比裁剪，之后再将图片 resize 到给定的 size。</p><ul><li>size：可以是 tuple 也可以是整数。<code>int</code> 不支持，要用长度为1的序列 [size, ]。</li><li>scale： float 的 tuple。指定随机 crop 的比例区间，如 0.08x~1.0x。</li><li>ratio： float的tuple。随机长宽比范围设置，如 0.75~1.33。</li><li>interpolation：插值方法。默认为双线性插值。由 <code>torchvision.transforms.InterpolationMode</code> 定义。如输入为 Tensor，只有 <code>InterpolationMode.NEAREST</code>，<code>InterpolationMode.BILINEAR</code> 和 <code>InterpolationMode.BICUBIC</code> 可用。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">RandomResizedCrop(size, scale=(<span class="hljs-number">0.08</span>, <span class="hljs-number">1.0</span>), ratio=(<span class="hljs-number">3.</span>/<span class="hljs-number">4.</span>, <span class="hljs-number">4.</span>/<span class="hljs-number">3.</span>), interpolation=InterpolationMode.BILINEAR)<br></code></pre></td></tr></table></figure><h4 id="FiveCrop"><a href="#FiveCrop" class="headerlink" title="FiveCrop"></a>FiveCrop</h4><p>将给定图片裁剪成 4 张边角图片和 1 张中心图片。如果输入图片是 <code>torch.Tensor</code>，则 expected shape 为 <code>[d, H, W]</code>，其中 d 为指示维度的数。</p><ul><li>size：可以是 tuple 也可以是整数。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">FiveCrop(size)<br></code></pre></td></tr></table></figure><h4 id="TenCrop"><a href="#TenCrop" class="headerlink" title="TenCrop"></a>TenCrop</h4><p>将给定的图片裁剪成 4 张边角图片和 1 张中心图片，然后全部翻转 (默认水平翻转)。如果输入图片是 <code>torch.Tensor</code>，则 expected shape 为 <code>[d, H, W]</code>，其中 d 为指示维度的数。</p><ul><li>size：可以是 tuple 也可以是整数。</li><li>vertical_flip：使用水平翻转或竖直翻转。<code>True</code> 垂直翻转，<code>False</code> 水平翻转。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">TenCrop(size, vertical_flip=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><h3 id="翻转和旋转"><a href="#翻转和旋转" class="headerlink" title="翻转和旋转"></a>翻转和旋转</h3><h4 id="RandomHorizontalFlip"><a href="#RandomHorizontalFlip" class="headerlink" title="RandomHorizontalFlip"></a>RandomHorizontalFlip</h4><p>根据给定概率 p 进行水平翻转。如果输入图片是 <code>torch.Tensor</code>，则 expected shape 为 <code>[d, H, W]</code>，其中 d 为指示维度的数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">RandomHorizontalFlip(p=<span class="hljs-number">0.5</span>)<br></code></pre></td></tr></table></figure><h4 id="RandomVerticalFlip"><a href="#RandomVerticalFlip" class="headerlink" title="RandomVerticalFlip"></a>RandomVerticalFlip</h4><p>根据给定概率 p 进行垂直翻转。如果输入图片是 <code>torch.Tensor</code>，则 expected shape 为 <code>[d, H, W]</code>，其中 d 为指示维度的数。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">RandomVerticalFlip(p=<span class="hljs-number">0.5</span>)<br></code></pre></td></tr></table></figure><h4 id="RandomRotation"><a href="#RandomRotation" class="headerlink" title="RandomRotation"></a>RandomRotation</h4><p>根据角度旋转图片。如果输入图片是 <code>torch.Tensor</code>，则 expected shape 为 <code>[d, H, W]</code>，其中 d 为指示维度的数。</p><ul><li>degrees：旋转角度。如果不是序列 $(min, max)$，则角度范围为 $(-degrees, +degrees)$</li><li>interpolation：插值方法。默认为 <code>NEAREST</code>。由 <code>torchvision.transforms.InterpolationMode</code> 定义。如输入为 Tensor，只有 <code>InterpolationMode.NEAREST</code>，<code>InterpolationMode.BILINEAR</code> 和 <code>InterpolationMode.BICUBIC</code> 可用。</li><li>expand：<code>true</code> 则填充到足够覆盖整个旋转后的图像，<code>false</code> 则使输出图像和输入图像大小一致。</li><li>fill：旋转后的图像外面的区域填充的值，默认为0。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">RandomRotation(degrees, interpolation=InterpolationMode.NEAREST, expand=<span class="hljs-literal">False</span>, center=<span class="hljs-literal">None</span>, fill=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h3 id="图像变换"><a href="#图像变换" class="headerlink" title="图像变换"></a>图像变换</h3><h4 id="Resize"><a href="#Resize" class="headerlink" title="Resize"></a>Resize</h4><p>把图像 Resize 成给定的 size。</p><ul><li>size：(sequence or int) 期望输出 size。如果 size&#x3D;(h, w)，则输出降为匹配的 size，如果 size 是一个 <code>int</code>，将会把较小的边设置为该值。也就是说，如果 height &gt; width，那么图片将会 rescale 成 (size * height &#x2F; width, size)。</li><li>interpolation：插值方法。默认为 <code>BILINEAR</code>。由 <code>torchvision.transforms.InterpolationMode</code> 定义。如输入为 Tensor，只有 <code>InterpolationMode.NEAREST</code>，<code>InterpolationMode.BILINEAR</code> 和 <code>InterpolationMode.BICUBIC</code> 可用。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Resize(size, interpolation=InterpolationMode.BILINEAR)<br></code></pre></td></tr></table></figure><h4 id="Normalize"><a href="#Normalize" class="headerlink" title="Normalize"></a>Normalize</h4><p>用平均值和均方差归一化 Tensor 图像。</p><p><em>该方法不能被用于 PIL 图像。</em></p><p>给出 n 个 channel 的 <code>(mean[1],...,mean[n]) </code> 和 <code>(std[1],..,std[n])</code> ，该方法将依次归一化每个 channel，也就是 <code>output[channel] = (input[channel] - mean[channel]) / std[channel]</code> 。</p><ul><li>mean：每个 channel 的均值。</li><li>std：每个 channel 的均方差。</li><li>inplace：是否采用 <code>in-place</code> 。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Normalize(mean, std, inplace=<span class="hljs-literal">False</span>)<br></code></pre></td></tr></table></figure><h4 id="ToTensor"><a href="#ToTensor" class="headerlink" title="ToTensor"></a>ToTensor</h4><p>将 <code>PIL Image</code> 或者 <code>numpy.ndarray</code> 转换为 <code>tensor</code> 。</p><p>将 [0, 255] 范围内的 $(H\times W\times C)$ 转换为 [0.0, 1.0] 范围内的 $(C\times H\times W)$ <code>torch.FloatTensor</code>。</p><p><code>PIL Image</code> 应该是 (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) 之中的一种模式， <code>numpy.ndarray</code> 的 <code>dtype = np.uint8</code> 。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">ToTensor(pic)<br></code></pre></td></tr></table></figure><h4 id="ToPILImage"><a href="#ToPILImage" class="headerlink" title="ToPILImage"></a>ToPILImage</h4><p>将 <code>tensor</code> 或者 <code>ndarray</code> 转换成 <code>PIL Image</code>。</p><p>将 $(C\times H\times W)$ 的 <code>Tensor</code> 转换为 $(H\times W\times C)$ 的 <code>PIL Image</code>。、</p><p><code>mode</code> 可以参考 <a href="https://pillow.readthedocs.io/en/latest/handbook/concepts.html#concept-modes">Pillow 官网</a> 上的色彩空间。</p><ul><li>mode：<code>PIL Image</code> 的色彩空间，如果 <code>mode=None</code>，则会根据输入数据进行适配<ul><li><code>input channel=4</code> ，<code>mode=RGBA</code></li><li><code>input channel=3</code> ，<code>mode=RGB</code></li><li><code>input channel=2</code> ，<code>mode=LA</code></li><li><code>input channel=1</code> ，<code>mode</code> 由数据类型，也就是 <code>int</code>，<code>float</code>，<code>short</code> 决定。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">convert = ToPILImage(mode=<span class="hljs-literal">None</span>)<br>output = convert(pic)<br></code></pre></td></tr></table></figure><h4 id="Pad"><a href="#Pad" class="headerlink" title="Pad"></a>Pad</h4><p>使用给定的 <code>padding</code> 值填充给定的图像。</p><p>如果 image 是 <code>Tensor</code> ，它的大小应该是 $[d, H, W]$。对于 <code>reflect</code> 和 <code>symmetric</code> mode来说，最多 2 维，对于 <code>edge</code> mode 来说，最多 3 维，对于 <code>constant</code> mode 来说，可以是任意维度。</p><ul><li>padding：设置填充多少个 pixel。当为 <code>int</code> 时，图像上下左右均填充 <code>int</code> 个，若有两个数，则第一个数为左右扩充多少，第二个数表示上下的。当有 4 个数时，则为 左、上、右、下 各填充多少个。</li><li>fill：填充的值 (仅当填充 mode 为 ‘constant’ 时有效。当为 <code>int</code> 时，各通道均填充该值，当为 [r, g, b] tuple 时，表示RGB通道分别填充的值。</li><li>padding_mode：有 4 种填充模式：<ul><li>constant 常量。</li><li>edge 按照图片边缘像素值填充。</li><li>reflect 。以边缘值为中心做镜面对称，如 [1, 2, 3, 4] 边缘扩充一个值，结果为 [2, 1, 2, 3, 4, 3]。</li><li>symmetric。以边缘为中心做镜面对称，如 [1, 2, 3, 4] 边缘扩充一个值，结果为 [1, 1, 2, 3, 4, 4]。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Pad(padding, fill=<span class="hljs-number">0</span>, padding_mode=<span class="hljs-string">&#x27;constant&#x27;</span>)<br></code></pre></td></tr></table></figure><h4 id="ColorJitter"><a href="#ColorJitter" class="headerlink" title="ColorJitter"></a>ColorJitter</h4><p>修改亮度，对比度，饱和度还有色调。</p><p>如果 image 是 <code>Tensor</code>，它的大小应该是 $[\dots, 3, H, W]$，$\dots$ 是维度。</p><ul><li>brightness：浮点数 或 (min, max) 的 tuple，亮度的抖动。brightness_factor 从 [max(0, 1 - brightness), 1 + brightness] 或者 [min, max] 中均匀选择。应该是非负数。</li><li>contrast：浮点数 或 (min, max) 的 tuple，对比度的抖动。contrast_factor 从 [max(0, 1 - contrast), 1 + contrast] 或者 [min, max] 中均匀选择。应该是非负数。</li><li>saturation：浮点数 或 (min, max) 的 tuple，饱和度的抖动。saturation_factor 从 [max(0, 1 - saturation), 1 + saturation] 或者 [min, max] 中均匀选择。应该是非负数。</li><li>hue：浮点数 或 (min, max) 的 tuple，色调的抖动。hue_factor 从 [-hue, hue] 或者 [min, max] 中均匀选择。应该 <code>0&lt;= hue &lt;= 0.5</code> 或者 <code>-0.5&lt;= min &lt;= max &lt;=0.5</code> 。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">ColorJitter(brightness=<span class="hljs-number">0</span>, contrast=<span class="hljs-number">0</span>, saturation=<span class="hljs-number">0</span>, hue=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h4 id="Grayscale"><a href="#Grayscale" class="headerlink" title="Grayscale"></a>Grayscale</h4><p>将图片转换为灰度图。</p><p>如果 image 是 <code>Tensor</code>，它的大小应该是 $[\dots,3,H,W]$，$\dots$ 是维度。</p><ul><li>num_output_channels：(1 或者 3) 输出图像的通道数量。<ul><li><code>num_output_channels == 1</code>：返回单通道图像。</li><li><code>num_output_channels == 3</code>：返回 <code>r==g==b</code> 的 3 通道图像。</li></ul></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">Grayscale(num_output_channels=<span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure><h4 id="RandomGrayscale"><a href="#RandomGrayscale" class="headerlink" title="RandomGrayscale"></a>RandomGrayscale</h4><p>根据概率 p 将图片转为灰度图。</p><p>如果 image 是 <code>Tensor</code>，它的大小应该是 $[\dots,3,H,W]$，$\dots$ 是维度。</p><p>如果输入图像为单通道，则返回单通道，如果为 3 通道，则返回 <code>r==g==b</code> 的 3 通道灰度图。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">RandomGrayscale(p=<span class="hljs-number">0.1</span>)<br></code></pre></td></tr></table></figure><h4 id="LinearTransformation"><a href="#LinearTransformation" class="headerlink" title="LinearTransformation"></a>LinearTransformation</h4><p>用方阵和偏移量的 mean_vector 来做线性变换，可用于白化处理。</p><p>给定 <code>transformation_matrix</code> 和 <code>mean_vector</code>，会先将 <code>Tensor</code> 展平并从中减去 <code>mean_vector</code> ，然后用 <code>transformation_matrix</code> 计算点积，最后将 <code>Tensor</code> 重塑为之前的 shape。</p><ul><li>transformation_matrix：$[D\times D]$ 的 <code>Tensor</code>，$D &#x3D; C\times H\times W$。</li><li>mean_vector：$[D]$ 的 <code>Tensor</code>，$D&#x3D;C\times H\times W$。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">LinearTransformation(transformation_matrix, mean_vector)<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">Applications:</span><br><span class="hljs-string">whitening transformation: Suppose X is a column vector zero-centered data.</span><br><span class="hljs-string">Then compute the data covariance matrix [D x D] with torch.mm(X.t(), X),</span><br><span class="hljs-string">perform SVD on this matrix and pass it as transformation_matrix.</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h4 id="RandomAffine"><a href="#RandomAffine" class="headerlink" title="RandomAffine"></a>RandomAffine</h4><p>图像保持中心不变的随机仿射变换。</p><p>如果 image 是 <code>Tensor</code>，它的大小应该是 $[\dots,H,W]$，$\dots$ 是维度。</p><ul><li>degrees：旋转选择角度的范围。如果角度为一个值，则范围为 (-degrees, +degrees)。tuple 情况下范围为 (min, max)。如果 <code>degrees=0</code>，则停用旋转。</li><li>translate：水平和垂直平移的最大绝对比例的 tuple。如 <code>translate=(a, b)</code>，那么水平平移在 <code>-img_width * a &lt; dx &lt; img_width * a</code> 范围内随机选择，垂直平移在 <code>-img_height * b &lt; dy &lt; img_height * b</code> 范围内随机选择。默认则不会偏移。</li><li>scale：放缩的范围区间。如 <code>(a, b)</code>，则范围为 <code>a&lt;= scale &lt;= b</code>，默认保持原大小。</li><li>shear：错切选择角度的范围。如果 <code>shear</code> 是一个数字，则平行于 x 轴的错切范围为 (-shear, +shear)。如果 <code>shear</code> 是一个包含两个数字的序列，则平行于 x 轴的错切范围为 (shear[0], shear[1])。如果 <code>shear</code> 是一个包含 4 个数字的序列，那么平行于 x 轴的错切范围为 (shear[0], shear[1])，平行于 y 轴的错切范围为 (shear[2], shear[3])。默认不会应用错切。</li><li>interpolation：插值方法。默认为 <code>NEAREST</code>。由 <code>torchvision.transforms.InterpolationMode</code> 定义。如输入为 Tensor，<code>InterpolationMode.NEAREST</code> 和 <code>InterpolationMode.BILINEAR</code> 可用。</li><li>fill：区域外填充的值，默认是 0 。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">RandomAffine(degrees, translate=<span class="hljs-literal">None</span>, scale=<span class="hljs-literal">None</span>, shear=<span class="hljs-literal">None</span>, interpolation=InterpolationMode.NEAREST, fill=<span class="hljs-number">0</span>)<br></code></pre></td></tr></table></figure><h3 id="Transform-组合操作"><a href="#Transform-组合操作" class="headerlink" title="Transform 组合操作"></a>Transform 组合操作</h3><h4 id="Compose"><a href="#Compose" class="headerlink" title="Compose"></a>Compose</h4><p>将多个 transform 组合起来使用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">transforms.Compose([<br>    transforms.CenterCrop(<span class="hljs-number">10</span>),<br>    transforms.ToTensor(),<br>])<br></code></pre></td></tr></table></figure><h4 id="RandomChoice"><a href="#RandomChoice" class="headerlink" title="RandomChoice"></a>RandomChoice</h4><p>应用从列表中随机选择的单个转换。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">transforms.RandomChoice([<br>    transforms.CenterCrop(<span class="hljs-number">10</span>),<br>    transforms.ToTensor(),<br>])<br></code></pre></td></tr></table></figure><h4 id="RandomApply"><a href="#RandomApply" class="headerlink" title="RandomApply"></a>RandomApply</h4><p>给一个 transform 加上概率，以一定的概率执行该操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">RandomApply(transforms, p=<span class="hljs-number">0.5</span>)<br></code></pre></td></tr></table></figure><h4 id="RandomOrder"><a href="#RandomOrder" class="headerlink" title="RandomOrder"></a>RandomOrder</h4><p>将 transforms 中的操作顺序随机打乱。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">RandomOrder([<br>    transforms.CenterCrop(<span class="hljs-number">10</span>),<br>    transforms.ToTensor(),<br>])<br></code></pre></td></tr></table></figure><h4 id="Lambda-Transforms"><a href="#Lambda-Transforms" class="headerlink" title="Lambda Transforms"></a>Lambda Transforms</h4><p>还不了解，待补充。</p><h2 id="构建模型"><a href="#构建模型" class="headerlink" title="构建模型"></a>构建模型</h2><p>神经网络由对数据执行操作的层&#x2F;模块组成。<code>torch.nn</code> 命名空间提供了构建自己的神经网络所需的所有构建块。 PyTorch 中的每个模块都是 <code>nn.Module</code> 的子类。 神经网络是一个模块本身，它由其他模块（层）组成。 这种嵌套结构允许轻松构建和管理复杂的架构。</p><h3 id="设置训练设备"><a href="#设置训练设备" class="headerlink" title="设置训练设备"></a>设置训练设备</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">device = <span class="hljs-string">&#x27;cuda&#x27;</span> <span class="hljs-keyword">if</span> torch.cuda.is_available() <span class="hljs-keyword">else</span> <span class="hljs-string">&#x27;cpu&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="定义网络类"><a href="#定义网络类" class="headerlink" title="定义网络类"></a>定义网络类</h3><p>我们使用子类 <code>nn.Module</code> 定义自己的神经网络，然后在 <code>__init__</code> 中初始化网络层。每个 <code>nn.Module</code> 子类都在 <code>forward</code> 方法中实现对输入数据的操作。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">NeuralNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(NeuralNetwork, self).__init__()<br>        self.linear_relu_stack = nn.Sequential(<br>            nn.Linear(<span class="hljs-number">28</span>*<span class="hljs-number">28</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">10</span>),<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        output = self.linear_relu_stack(x)<br>        <span class="hljs-keyword">return</span> output<br>    <br><span class="hljs-comment"># 将模型载入到对应设备上</span><br>model = NearalNetwork().to(device)<br><span class="hljs-comment"># print 查看模型</span><br><span class="hljs-built_in">print</span>(model)<br></code></pre></td></tr></table></figure><h3 id="模型-Layers"><a href="#模型-Layers" class="headerlink" title="模型 Layers"></a>模型 Layers</h3><h4 id="Containers"><a href="#Containers" class="headerlink" title="Containers"></a>Containers</h4><p><code>torch.nn.Module</code> 是所有网络的基类，我们的模型也应该继承这个类。</p><h5 id="模块添加和迭代"><a href="#模块添加和迭代" class="headerlink" title="模块添加和迭代"></a>模块添加和迭代</h5><ul><li><p>add_module(name, module)</p><p>将一个 <code>child module</code> 添加到当前 <code>module</code> 。被添加的 <code>module</code> 可以通过 <code>name</code> 属性获取。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Model, self).__init__()<br>        self.add_module(<span class="hljs-string">&quot;conv&quot;</span>, nn.Conv2d(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">4</span>))<br>        <span class="hljs-comment">#self.conv = nn.Conv2d(10, 20, 4) 和上面这个增加module的方式等价</span><br>model = Model()<br><span class="hljs-built_in">print</span>(model.conv)<br></code></pre></td></tr></table></figure></li><li><p>modules()</p><p>返回一个包含 当前模型 所有模块的迭代器。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Model, self).__init__()<br>        self.add_module(<span class="hljs-string">&quot;conv&quot;</span>, nn.Conv2d(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, <span class="hljs-number">4</span>))<br>        self.add_module(<span class="hljs-string">&quot;conv1&quot;</span>, nn.Conv2d(<span class="hljs-number">20</span> ,<span class="hljs-number">10</span>, <span class="hljs-number">4</span>))<br>model = Model()<br><br><span class="hljs-keyword">for</span> module <span class="hljs-keyword">in</span> model.modules():<br>    <span class="hljs-built_in">print</span>(module)<br></code></pre></td></tr></table></figure></li><li><p>children()</p><p>返回当前模型 <strong>子模块</strong> 的迭代器。</p></li><li><p>named_children()</p><p>返回 包含 模型当前子模块 的迭代器，包含模块名字和模块本身。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">for</span> name, module <span class="hljs-keyword">in</span> model.named_children():<br>    <span class="hljs-keyword">if</span> name <span class="hljs-keyword">in</span> [<span class="hljs-string">&#x27;conv4&#x27;</span>, <span class="hljs-string">&#x27;conv5&#x27;</span>]:<br>        <span class="hljs-built_in">print</span>(module)<br></code></pre></td></tr></table></figure></li></ul><h5 id="模块设备管理"><a href="#模块设备管理" class="headerlink" title="模块设备管理"></a>模块设备管理</h5><ul><li><p>cpu(device_id&#x3D;None)</p><p>将所有的模型参数 <code>parameters</code> 和 <code>buffers</code> 复制到 CPU。</p></li><li><p>cuda(device_id&#x3D;None)</p><p>将所有的模型参数 <code>parameters</code> 和 <code>buffers</code> 复制给 GPU。</p></li></ul><h5 id="模块数据类型"><a href="#模块数据类型" class="headerlink" title="模块数据类型"></a>模块数据类型</h5><ul><li><p>double()</p><p>将 <code>parameters</code> 和 <code>buffers</code> 的数据类型转换为 <code>double</code>。</p></li><li><p>float()</p><p>将 <code>parameters</code> 和 <code>buffers</code> 的数据类型转换为 <code>float</code>。</p></li><li><p>half()</p><p>将 <code>parameters</code> 和 <code>buffers</code> 的数据类型转换为 <code>half</code>。</p></li></ul><h5 id="字典查看和导入"><a href="#字典查看和导入" class="headerlink" title="字典查看和导入"></a>字典查看和导入</h5><ul><li><p>state_dict()</p><p>返回一个字典，保存着<code>module</code>的所有状态（<code>state</code>）。</p><p><code>parameters</code> 和 <code>persistent buffers</code> 都会包含在字典中，字典的 <code>key</code> 就是 <code>parameter</code> 和 <code>buffer </code> 的 <code>names </code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch.autograd <span class="hljs-keyword">import</span> Variable<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Model</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(Model, self).__init__()<br>        self.conv2 = nn.Linear(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>)<br>        self.vari = Variable(torch.rand([<span class="hljs-number">1</span>]))<br>        self.par = nn.Parameter(torch.rand([<span class="hljs-number">1</span>]))<br>        self.register_buffer(<span class="hljs-string">&quot;buffer&quot;</span>, torch.randn([<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]))<br><br>model = Model()<br><span class="hljs-built_in">print</span>(model.state_dict().keys())<br></code></pre></td></tr></table></figure></li><li><p>load_state_dict(state_dict)</p><p>将 <code>state_dict</code> 中的 <code>parameters</code> 和 <code>buffers</code> 复制到此 <code>module</code>和它的后代中。<code>state_dict</code> 中的 <code>key</code> 必须和 <code>model.state_dict()</code> 返回的 <code>key</code> 一致。</p></li></ul><h5 id="网络训练，梯度，前向传播"><a href="#网络训练，梯度，前向传播" class="headerlink" title="网络训练，梯度，前向传播"></a>网络训练，梯度，前向传播</h5><ul><li><p>forward(*input)</p><p>定义了每次执行的 计算步骤。 在所有的子类中都需要重写这个函数。</p></li><li><p>train(mode&#x3D;True)</p><p>将 <code>module</code> 设置为 <code>training mode</code>。仅仅当模型中有 <code>Dropout</code> 和 <code>BatchNorm</code> 时才会有影响。</p></li><li><p>zero_grad()</p><p>将 <code>module</code> 中的所有模型参数的梯度设置为0.</p></li></ul><h5 id="容器类-Sequential-ModuleList-ParameterList"><a href="#容器类-Sequential-ModuleList-ParameterList" class="headerlink" title="容器类 Sequential, ModuleList, ParameterList"></a>容器类 Sequential, ModuleList, ParameterList</h5><ul><li><p>torch.nn.Sequential(* args)</p><p>一个时序容器。<code>Modules</code> 会以他们传入的顺序被添加到容器中。当然，也可以传入一个<code>OrderedDict</code>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># Example of using Sequential</span><br><br>model = nn.Sequential(<br>          nn.Conv2d(<span class="hljs-number">1</span>,<span class="hljs-number">20</span>,<span class="hljs-number">5</span>),<br>          nn.ReLU(),<br>          nn.Conv2d(<span class="hljs-number">20</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>),<br>          nn.ReLU()<br>        )<br><span class="hljs-comment"># Example of using Sequential with OrderedDict</span><br>model = nn.Sequential(OrderedDict([<br>          (<span class="hljs-string">&#x27;conv1&#x27;</span>, nn.Conv2d(<span class="hljs-number">1</span>,<span class="hljs-number">20</span>,<span class="hljs-number">5</span>)),<br>          (<span class="hljs-string">&#x27;relu1&#x27;</span>, nn.ReLU()),<br>          (<span class="hljs-string">&#x27;conv2&#x27;</span>, nn.Conv2d(<span class="hljs-number">20</span>,<span class="hljs-number">64</span>,<span class="hljs-number">5</span>)),<br>          (<span class="hljs-string">&#x27;relu2&#x27;</span>, nn.ReLU())<br>        ]))<br></code></pre></td></tr></table></figure></li><li><p>torch.nn.ModuleList(modules&#x3D;None)</p><p>将 <code>submodules</code> 保存在一个 <code>list</code> 中。</p><p><code>ModuleList</code> 可以像一般的 <code>Python list</code> 一样被<code>索引</code>。而且 <code>ModuleList</code> 中包含的<code>modules</code> 已经被正确的注册，对所有的 <code>module method</code> 可见。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModule</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyModule, self).__init__()<br>        self.linears = nn.ModuleList([nn.Linear(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># ModuleList can act as an iterable, or be indexed         using ints</span><br>        <span class="hljs-keyword">for</span> i, l <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.linears):<br>            x = self.linears[i // <span class="hljs-number">2</span>](x) + l(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><ul><li><p>append(module)</p><p>等价于 list 的 <code>append() </code> 。</p></li></ul></li><li><p>torch.nn.ParameterList(parameters&#x3D;None)</p><p>将 <code>submodules</code> 保存在一个 <code>list</code> 中。</p><p><code>ParameterList</code> 可以像一般的 <code>Python list</code> 一样被<code>索引</code>。而且 <code>ParameterList</code> 中包含的 <code>parameters</code> 已经被正确的注册，对所有的 <code>module method</code> 可见。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyModule</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>(MyModule, self).__init__()<br>        self.params = nn.ParameterList([nn.Parameter(torch.randn(<span class="hljs-number">10</span>, <span class="hljs-number">10</span>)) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>)])<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-comment"># ModuleList can act as an iterable, or be indexed using ints</span><br>        <span class="hljs-keyword">for</span> i, p <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(self.params):<br>            x = self.params[i // <span class="hljs-number">2</span>].mm(x) + p.mm(x)<br>        <span class="hljs-keyword">return</span> x<br></code></pre></td></tr></table></figure><ul><li><p>append(parameter)</p><p>等价于 list 的 <code>append() </code> 。</p></li></ul></li></ul><h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><h5 id="X维卷积"><a href="#X维卷积" class="headerlink" title="X维卷积"></a>X维卷积</h5><p>卷积操作。</p><p>$N$ 为 <code>batch size</code> ，$C$ 为 <code>channel</code> 数量，$L$ 为信号序列的长度。</p><p>可使用的为 <code>1-3</code> 维的卷积层，函数如下：</p><ul><li><p><code>torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)</code></p><ul><li><p>输入: $(N,C_{in},L_{in})$</p></li><li><p>输出: $(N,C_{out},L_{out})$</p></li><li><p>$L_{out}$ 的 Shape 为：</p><p>$$L_{out}&#x3D;floor((L_{in}+2<em>padding-dilation</em>(kernerl_size-1)-1)&#x2F;stride+1)$$</p></li></ul></li><li><p><code>torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)</code></p><ul><li><p>输入: $(N,C_{in},H_{in},W_{in})$</p></li><li><p>输出: $(N,C_{out},H_{out},W_{out})$</p></li><li><p>$H_{out}$ 和 $W_{out}$ 的 Shape 为：</p><p>$$H_{out}&#x3D;floor((H_{in}+2<em>padding[0]-dilation[0]</em>(kernerl_size[0]-1)-1)&#x2F;stride[0]+1)$$</p><p>$$W_{out}&#x3D;floor((W_{in}+2<em>padding[1]-dilation[1]</em>(kernerl_size[1]-1)-1)&#x2F;stride[1]+1)$$</p></li></ul></li><li><p><code>torch.nn.Conv3d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)</code></p><ul><li><p>输入: $(N,C_{in},D_{in},H_{in},W_{in})$</p></li><li><p>输出: $(N,C_{out},D_{out},H_{out},W_{out})$</p></li><li><p>$D_{out}, H_{out}, W_{out}$ 的 Shape 为：</p><p>$$D_{out}&#x3D;floor((D_{in}+2<em>padding[0]-dilation[0]</em>(kernerl_size[0]-1)-1)&#x2F;stride[0]+1)$$</p><p>$$H_{out}&#x3D;floor((H_{in}+2<em>padding[1]-dilation[1]</em>(kernerl_size[1]-1)-1)&#x2F;stride[1]+1)$$</p><p>$$W_{out}&#x3D;floor((W_{in}+2<em>padding[2]-dilation[2]</em>(kernerl_size[2]-1)-1)&#x2F;stride[2]+1)$$</p></li></ul></li></ul><p><strong>输入输出的计算方式：</strong></p><p>$$ out(N_i, C_{out_j})&#x3D;bias(C_{out_j})+\sum^{C_{in}-1}<em>{k&#x3D;0}weight(C</em>{out_j},k)\bigotimes input(N_i,k) $$</p><p>其中 $\bigotimes$ 为 <code>cross-correlation</code> 操作符。</p><p><strong>参数及其意义为：</strong></p><ul><li>in_channels(<code>int</code>) – 输入信号的通道</li><li>out_channels(<code>int</code>) – 卷积产生的通道</li><li>kerner_size(<code>int</code> or <code>tuple</code>) - 卷积核的尺寸</li><li>stride(<code>int</code> or <code>tuple</code>, <code>optional</code>) - 卷积步长</li><li>padding(<code>int</code> or <code>tuple</code>, <code>optional</code>) - 输入的每一条边补充0的层数</li><li>dilation(<code>int</code> or <code>tuple</code>, <code>optional</code>) – 卷积核元素之间的间距</li><li>groups(<code>int</code>, <code>optional</code>) – 从输入通道到输出通道的阻塞连接数<ul><li><code>groups=1</code>，所有输出由输入卷积得到</li><li><code>groups=2</code>，将输入 <code>channel</code> 平分成两份，卷积后进行 <code>concat</code> 操作</li><li><code>groups=in_channels</code>，所有 <code>input_channel</code> 都由自己的滤波器进行卷积，大小为 <code>out_channels/in_channels</code></li></ul></li><li>bias(<code>bool</code>, <code>optional</code>) - 如果<code>bias=True</code>，添加偏置</li></ul><h5 id="转置卷积"><a href="#转置卷积" class="headerlink" title="转置卷积"></a>转置卷积</h5><p>反卷积操作，相当于使用空洞卷积进行上采样。</p><p>$N$ 为 <code>batch size</code> ，$C$ 为 <code>channel</code> 数量，$L$ 为信号序列的长度。</p><p>可使用的为 <code>1-3</code> 维的卷积层，函数如下：</p><ul><li><p><code>torch.nn.ConvTranspose1d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)</code></p><ul><li><p>输入: $(N,C_{in},L_{in})$</p></li><li><p>输出: $(N,C_{out},L_{out})$</p></li><li><p>$L_{out}$ 的 Shape 为：</p><p>$$L_{out}&#x3D;(L_{in}-1)<em>stride-2</em>padding+dilation\times(kernel_size-1)+output_padding+1$$</p></li></ul></li><li><p><code>torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)</code></p><ul><li><p>输入: $(N,C_{in},H_{in},W_{in})$</p></li><li><p>输出: $(N,C_{out},H_{out},W_{out})$</p></li><li><p>$H_{out}$ 和 $W_{out}$ 的 Shape 为：</p><p>$$H_{out}&#x3D;(H_{in}-1)<em>stride[0]-2</em>padding[0]+dilation[0]\times (kernel_size[0]-1)+output_padding[0]+1$$</p><p>$$W_{out}&#x3D;(W_{in}-1)<em>stride[1]-2</em>padding[1]+dilation[1]\times(kernel_size[1]-1)+output_padding[1]+1$$</p></li></ul></li><li><p><code>torch.nn.ConvTranspose3d(in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, groups=1, bias=True, dilation=1)</code></p><ul><li><p>输入: $(N,C_{in},D_{in},H_{in},W_{in})$</p></li><li><p>输出: $(N,C_{out},D_{out},H_{out},W_{out})$</p></li><li><p>$D_{out}, H_{out}, W_{out}$ 的 Shape 为：</p><p>$$D_{out}&#x3D;(D_{in}-1)<em>stride[0]-2</em>padding[0]+dilation[0]\times(kernel_size[0]-1)+output_padding[0]+1$$</p><p>$$H_{out}&#x3D;(H_{in}-1)<em>stride[1]-2</em>padding[1]+dilation[1]\times(kernel_size[1]-1)+output_padding[1]+1$$</p><p>$$W_{out}&#x3D;(W_{in}-1)<em>stride[2]-2</em>padding[2]+dilation[2]\times(kernel_size[2]-1)+output_padding[2]+1$$</p></li></ul></li></ul><h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><h5 id="Maxpool"><a href="#Maxpool" class="headerlink" title="Maxpool"></a>Maxpool</h5><p>$N$ 为 <code>batch size</code> ，$C$ 为 <code>channel</code> 数量。</p><p>可使用的为 <code>1-3</code> 维的池化层，函数如下：</p><ul><li><p><code>torch.nn.MaxPool1d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)</code></p><ul><li><p>输入: $(N,C_{in},L_{in})$</p></li><li><p>输出: $(N,C_{out},L_{out})$</p></li><li><p>$L_{out}$ 的 Shape 为：</p><p>$$L_{out}&#x3D;floor((L_{in} + 2<em>padding - dilation</em>(kernel_size - 1) - 1)&#x2F;stride + 1)$$</p></li></ul></li><li><p><code>torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)</code></p><ul><li><p>输入: $(N,C_{in},H_{in},W_{in})$</p></li><li><p>输出: $(N,C_{out},H_{out},W_{out})$</p></li><li><p>$H_{out}$ 和 $W_{out}$ 的 Shape 为：</p><p>$$H_{out}&#x3D;floor((H_{in} + 2<em>padding[0] - dilation[0]</em>(kernel_size[0] - 1) - 1)&#x2F;stride[0] + 1)$$</p><p>$$W_{out}&#x3D;floor((W_{in} + 2<em>padding[1] - dilation[1]</em>(kernel_size[1] - 1) - 1)&#x2F;stride[1] + 1)$$</p></li></ul></li><li><p><code>torch.nn.MaxPool3d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)</code></p><ul><li><p>输入: $(N,C_{in},D_{in},H_{in},W_{in})$</p></li><li><p>输出: $(N,C_{out},D_{out},H_{out},W_{out})$</p></li><li><p>$D_{out}, H_{out}, W_{out}$ 的 Shape 为：</p><p>$$D_{out}&#x3D;floor((D_{in} + 2<em>padding[0] - dilation[0]</em>(kernel_size[0] - 1) - 1)&#x2F;stride[0] + 1)$$</p><p>$$H_{out}&#x3D;floor((H_{in} + 2<em>padding[1] - dilation[1]</em>(kernel_size[1] - 1) - 1)&#x2F;stride[1] + 1)$$</p><p>$$W_{out}&#x3D;floor((W_{in} + 2<em>padding[2] - dilation[2]</em>(kernel_size[2] - 1) - 1)&#x2F;stride[2] + 1)$$</p></li></ul></li></ul><h5 id="MaxUnpool"><a href="#MaxUnpool" class="headerlink" title="MaxUnpool"></a>MaxUnpool</h5><p><code>Maxpool</code>的逆过程，不过并不是完全的逆过程，因为在<code>maxpool</code>的过程中，一些值已经丢失。 <code>MaxUnpool</code>输入<code>MaxPool</code>的输出，包括最大值的索引，并计算所有<code>maxpool</code>过程中非最大值被设置为零的部分的反向。</p><ul><li><code>torch.nn.MaxUnpool1d(kernel_size, stride=None, padding=0)</code></li><li><code>torch.nn.MaxUnpool2d(kernel_size, stride=None, padding=0)</code></li><li><code>torch.nn.MaxUnpool3d(kernel_size, stride=None, padding=0)</code></li></ul><h5 id="AvgPool"><a href="#AvgPool" class="headerlink" title="AvgPool"></a>AvgPool</h5><p>平均池化。</p><ul><li><code>torch.nn.AvgPool1d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)</code></li><li><code>torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)</code></li><li><code>torch.nn.AvgPool3d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True)</code></li></ul><p><strong>参数：</strong></p><ul><li>kernel_size(<code>int</code> or <code>tuple</code>) - 池化窗口大小</li><li>stride(<code>int</code> or <code>tuple</code>, <code>optional</code>) - max pooling的窗口移动的步长。默认值是<code>kernel_size</code></li><li>padding(<code>int</code> or <code>tuple</code>, <code>optional</code>) - 输入的每一条边补充0的层数</li><li>dilation(<code>int</code> or <code>tuple</code>, <code>optional</code>) – 一个控制窗口中元素步幅的参数</li><li>ceil_mode - 如果等于<code>True</code>，计算输出信号大小的时候，会使用向上取整，代替默认的向下取整的操作</li><li>count_include_pad - 如果等于<code>True</code>，计算平均池化时，将包括<code>padding</code>填充的0</li></ul><h4 id="非线性激活层"><a href="#非线性激活层" class="headerlink" title="非线性激活层"></a>非线性激活层</h4><ul><li><p><code>torch.nn.ReLU(inplace=False) </code></p><p>表达式：${ReLU}(x)&#x3D; max(0, x)$</p></li><li><p><code>torch.nn.Sigmoid()</code></p><p>表达式：$f(x)&#x3D;1&#x2F;(1+e^{-x})$</p></li><li><p><code>torch.nn.Tanh()</code></p><p>表达式：$f(x)&#x3D;\frac{exp(x)-exp(-x)}{exp(x)+exp(-x)}$</p></li><li><p><code>torch.nn.Softmax()</code></p><p>表达式：$f(x_i)&#x3D;\frac{exp(x_i)}{\sum_j exp(x_j)}$</p></li><li><p><code>torch.nn.LeakyReLU(negative_slope=0.01, inplace=False)</code></p><p>表达式：$f(x) &#x3D; max(0, x) + {negative_slope} * min(0, x)$</p><ul><li>negative_slope：控制负斜率的角度，默认等于0.01</li></ul></li><li><p><code>torch.nn.ELU(alpha=1.0, inplace=False)</code></p><p>表达式：$f(x) &#x3D; max(0,x) + min(0, alpha * (e^x - 1))$</p></li><li><p><code>torch.nn.Threshold(threshold, value, inplace=False)</code></p><p>表达式：$y&#x3D;x, if ,,, x&gt;&#x3D;threshold;,, y&#x3D;value, if,,,x&lt;threshold$</p><ul><li>threshold：阈值</li><li>value：输入值小于阈值则会被value代替</li></ul></li></ul><h4 id="Normalization-层"><a href="#Normalization-层" class="headerlink" title="Normalization 层"></a>Normalization 层</h4><h5 id="BatchNorm"><a href="#BatchNorm" class="headerlink" title="BatchNorm"></a>BatchNorm</h5><p>对 mini-batch 的输入进行 Batch Normalization 操作：</p><p>$$y&#x3D;\frac{x-mean[x]}{\sqrt{Var[x]}+\epsilon}\times gamma+\beta$$</p><p>在每一个小批量（mini-batch）数据中，计算输入各个维度的均值和标准差。gamma与beta是可学习的大小为C的参数向量（C为输入大小）</p><p>在训练时，该层计算每次输入的均值与方差，并进行移动平均。移动平均默认的动量值为0.1。</p><p>在验证时，训练求得的均值&#x2F;方差将用于标准化验证数据。</p><ul><li><code>torch.nn.BatchNorm1d(num_features, eps=1e-05, momentum=0.1, affine=True)</code></li><li><code>torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True)</code></li><li><code>torch.nn.BatchNorm3d(num_features, eps=1e-05, momentum=0.1, affine=True)</code></li></ul><p><strong>参数：</strong></p><ul><li><strong>num_features：</strong> 来自期望输入的特征数。</li><li><strong>eps：</strong> 为保证数值稳定性（分母不能趋近或取0）,给分母加上的值。默认为1e-5。</li><li><strong>momentum：</strong> 动态均值和动态方差所使用的动量。默认为0.1。</li><li><strong>affine：</strong> 一个布尔值，当设为true，给该层添加可学习的仿射变换参数。</li></ul><h4 id="Recurrent-层"><a href="#Recurrent-层" class="headerlink" title="Recurrent 层"></a>Recurrent 层</h4><h5 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h5><p><code>torch.nn.RNN( *args,* * kwargs)</code></p><p>将一个多层的 <code>Elman RNN</code>，激活函数为 <code>tanh</code> 或者 <code>ReLU</code>，用于输入序列。</p><p>对输入序列中每个元素，<code>RNN</code>每层的计算公式为 $$ h_t&#x3D;tanh(W_{ih}x_t+b_{ih}+W_{hh}h_{t-1}+b_{hh}) $$ $h_t$是时刻$t$的隐状态。 $x_t$是上一层时刻$t$的隐状态，或者是第一层在时刻$t$的输入。如果 <code>nonlinearity=&#39;relu&#39;</code> ,那么将使用 <code>relu</code> 代替 <code>tanh</code> 作为激活函数。</p><p><strong>参数：</strong></p><ul><li>input_size – 输入<code>x</code>的特征数量。</li><li>hidden_size – 隐层的特征数量。</li><li>num_layers – RNN的层数。</li><li>nonlinearity – 指定非线性函数使用 <code>tanh</code> 还是 <code>relu</code>。默认是 <code>tanh</code>。</li><li>bias – 如果是 <code>False</code>，那么RNN层就不会使用偏置权重 $b_ih$和$b_hh$,默认是 <code>True</code></li><li>batch_first – 如果 <code>True</code> 的话，那么输入 <code>Tensor</code> 的shape应该是[batch_size, time_step, feature],输出也是这样。</li><li>dropout – 如果值非零，那么除了最后一层外，其它层的输出都会套上一个 <code>dropout</code> 层。</li><li>bidirectional – 如果 <code>True</code>，将会变成一个双向 <code>RNN</code>，默认为 <code>False</code>。</li></ul><h5 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h5><p><code>torch.nn.LSTM( *args,* * kwargs)</code></p><p>将一个多层的 <code>(LSTM)</code> 应用到输入序列。</p><p>对输入序列的每个元素，<code>LSTM</code>的每层都会执行以下计算：<br>$$<br>\begin{aligned} i_t &amp;&#x3D;sigmoid(W_{ii}x_t+b_{ii}+W_{hi}h_{t-1}+b_{hi}) \ f_t &amp;&#x3D; sigmoid(W_{if}x_t+b_{if}+W_{hf}h_{t-1}+b_{hf}) \ o_t &amp;&#x3D; sigmoid(W_{io}x_t+b_{io}+W_{ho}h_{t-1}+b_{ho})\ g_t &amp;&#x3D; tanh(W_{ig}x_t+b_{ig}+W_{hg}h_{t-1}+b_{hg})\ c_t &amp;&#x3D; f_t\odot c_{t-1}+i_t\odot g_t\ h_t &amp;&#x3D; o_t\odot tanh(c_t) \end{aligned}<br>$$</p><p>$h_t$是时刻$t$的隐状态，$c_t$是时刻$t$的细胞状态，$x_t$是上一层的在时刻$t$的隐状态或者是第一层在时刻$t$的输入。$i_t, f_t, g_t, o_t$ 分别代表 输入门，遗忘门，细胞和输出门。</p><p><strong>参数：</strong></p><ul><li>input_size – 输入的特征维度</li><li>hidden_size – 隐状态的特征维度</li><li>num_layers – 层数（和时序展开要区分开）</li><li>bias – 如果为<code>False</code>，那么<code>LSTM</code>将不会使用$b_{ih},b_{hh}$，默认为<code>True</code>。</li><li>batch_first – 如果为<code>True</code>，那么输入和输出<code>Tensor</code>的形状为<code>(batch, seq, feature)</code></li><li>dropout – 如果非零的话，将会在<code>RNN</code>的输出上加个<code>dropout</code>，最后一层除外。</li><li>bidirectional – 如果为<code>True</code>，将会变成一个双向<code>RNN</code>，默认为<code>False</code>。</li></ul><h4 id="Transformer-层"><a href="#Transformer-层" class="headerlink" title="Transformer 层"></a>Transformer 层</h4><h5 id="nn-Transformer"><a href="#nn-Transformer" class="headerlink" title="nn.Transformer"></a>nn.Transformer</h5><p>一个基于 “Attension is All You Need” 实现的 Transformer 模型。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">torch.nn.Transformer(d_model=<span class="hljs-number">512</span>, nhead=<span class="hljs-number">8</span>, num_encoder_layers=<span class="hljs-number">6</span>, num_decoder_layers=<span class="hljs-number">6</span>, dim_feedforward=<span class="hljs-number">2048</span>, dropout=<span class="hljs-number">0.1</span>, activation=&lt;function relu&gt;, custom_encoder=<span class="hljs-literal">None</span>, custom_decoder=<span class="hljs-literal">None</span>, layer_norm_eps=<span class="hljs-number">1e-05</span>, batch_first=<span class="hljs-literal">False</span>, norm_first=<span class="hljs-literal">False</span>, device=<span class="hljs-literal">None</span>, dtype=<span class="hljs-literal">None</span>)<br></code></pre></td></tr></table></figure><p><strong>参数：</strong></p><ul><li><strong>d_model</strong> – the number of expected features in the encoder&#x2F;decoder inputs (default&#x3D;512).</li><li><strong>nhead</strong> – the number of heads in the multiheadattention models (default&#x3D;8).</li><li><strong>num_encoder_layers</strong> – the number of sub-encoder-layers in the encoder (default&#x3D;6).</li><li><strong>num_decoder_layers</strong> – the number of sub-decoder-layers in the decoder (default&#x3D;6).</li><li><strong>dim_feedforward</strong> – the dimension of the feedforward network model (default&#x3D;2048).</li><li><strong>dropout</strong> – the dropout value (default&#x3D;0.1).</li><li><strong>activation</strong> – the activation function of encoder&#x2F;decoder intermediate layer, can be a string (“relu” or “gelu”) or a unary callable. Default: relu</li><li><strong>custom_encoder</strong> – custom encoder (default&#x3D;None).</li><li><strong>custom_decoder</strong> – custom decoder (default&#x3D;None).</li><li><strong>layer_norm_eps</strong> – the eps value in layer normalization components (default&#x3D;1e-5).</li><li><strong>batch_first</strong> – If <code>True</code>, then the input and output tensors are provided as (batch, seq, feature). Default: <code>False</code> (seq, batch, feature).</li><li><strong>norm_first</strong> – if <code>True</code>, encoder and decoder layers will perform LayerNorms before other attention and feedforward operations, otherwise after. Default: <code>False</code> (after).</li></ul><h5 id="nn-TransformerEncoder"><a href="#nn-TransformerEncoder" class="headerlink" title="nn.TransformerEncoder"></a>nn.TransformerEncoder</h5><p>由 N 个 encoder 层堆叠形成的 TransformerEncoder。</p><p><code>torch.nn.TransformerEncoder(encoder_layer, num_layers, norm=None)</code></p><p><strong>参数：</strong></p><ul><li><strong>encoder_layer</strong> – an instance of the TransformerEncoderLayer() class (required).</li><li><strong>num_layers</strong> – the number of sub-encoder-layers in the encoder (required).</li><li><strong>norm</strong> – the layer normalization component (optional).</li></ul><h5 id="nn-TransformerDecoder"><a href="#nn-TransformerDecoder" class="headerlink" title="nn.TransformerDecoder"></a>nn.TransformerDecoder</h5><p>由 N 个 decoder 层堆叠形成的 TransformerDecoder。</p><p><code>torch.nn.TransformerDecoder(decoder_layer, num_layers, norm=None)</code></p><p><strong>参数：</strong></p><ul><li><strong>decoder_layer</strong> – an instance of the TransformerDecoderLayer() class (required).</li><li><strong>num_layers</strong> – the number of sub-decoder-layers in the decoder (required).</li><li><strong>norm</strong> – the layer normalization component (optional).</li></ul><h4 id="Linear-层"><a href="#Linear-层" class="headerlink" title="Linear 层"></a>Linear 层</h4><h5 id="Linear"><a href="#Linear" class="headerlink" title="Linear"></a>Linear</h5><p><code>torch.nn.Linear(in_features, out_features, bias=True)</code></p><p>对输入数据做线性变换：$y&#x3D;Ax+b$。</p><p><strong>参数：</strong></p><ul><li><strong>in_features</strong> - 每个输入样本的大小</li><li><strong>out_features</strong> - 每个输出样本的大小</li><li><strong>bias</strong> - 若设置为False，这层不会学习偏置。默认值：True</li></ul><p><strong>形状：</strong></p><ul><li><strong>输入:</strong> $(N,in_features)$</li><li><strong>输出：</strong> $(N,out_features)$</li></ul><h5 id="Bilinear"><a href="#Bilinear" class="headerlink" title="Bilinear"></a>Bilinear</h5><p><code>torch.nn.Bilinear(in1_features, in2_features, out_features, bias=True)</code></p><p>对输入数据做双线性变换：$y&#x3D;x_1^TAx_2+b$。</p><p><strong>参数：</strong></p><ul><li><strong>in1_features</strong> – size of each first input sample</li><li><strong>in2_features</strong> – size of each second input sample</li><li><strong>out_features</strong> – size of each output sample</li><li><strong>bias</strong> – If set to False, the layer will not learn an additive bias. Default: <code>True</code></li></ul><h4 id="Dropout-层"><a href="#Dropout-层" class="headerlink" title="Dropout 层"></a>Dropout 层</h4><h5 id="X-维-Dropout"><a href="#X-维-Dropout" class="headerlink" title="X 维 Dropout"></a>X 维 Dropout</h5><ul><li><code>torch.nn.Dropout(p=0.5, inplace=False)</code></li><li><code>torch.nn.Dropout2d(p=0.5, inplace=False)</code></li><li><code>torch.nn.Dropout3d(p=0.5, inplace=False)</code></li></ul><p>输入输出形状参照 卷积层—X 维卷积。</p><h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><h3 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h3><p>每次优化循环的迭代为一个 <code>epoch</code>。</p><p>每个 <code>epoch</code> 由以下两个重要部分组成：</p><ul><li><strong>The Train Loop</strong> - 在训练数据集上迭代以收敛到最优参数。</li><li><strong>The Validation&#x2F;Test Loop</strong> - 在测试集上测试来检查模型性能是否有提升。</li></ul><h3 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h3><p>对于回归任务来说，常用的 loss function 包括均方误差 <code>nn.MSELoss</code>，对于分类任务来说，Negative Log Likehood <code>nn.NLLLoss</code>。还有将 <code>nn.LogSoftmax</code> 和 <code>nn.NLLLoss</code> 结合起来的 <code>nn.CrossEntropyLoss</code> 交叉熵 loss function。</p><h3 id="Autograd-求导"><a href="#Autograd-求导" class="headerlink" title="Autograd 求导"></a>Autograd 求导</h3><p><code>torch.autograd</code>提供了类和函数用来对任意标量函数进行求导。要想使用自动求导，只需要对已有的代码进行微小的改变。只需要将所有的<code>tensor</code>包含进<code>Variable</code>对象中即可。</p><p>可以通过创建 <code>tensor</code> 时设置 <code>requires_grad</code>，也可以通过 <code>x.requires_grad_(True)</code> 来设置自动求导。</p><p>可以通过 <code>z.grad_fn</code> 来查看 Gradient function。</p><p>在模型中，只需要 <code>loss.backward()</code> 就可以计算后向传播时的导数。</p><p>如果想要关闭梯度跟踪，则需要在 <code>with torch.no_grad():</code> 下进行函数操作，或者对 <code>tensor</code> 使用 <code>detach()</code>。</p><h3 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h3><p><code>torch.optim</code>是一个实现了各种优化算法的库。大部分常用的方法得到支持，并且接口具备足够的通用性，使得未来能够集成更加复杂的方法。</p><p>为了构建一个<code>Optimizer</code>，你需要给它一个包含了需要优化的参数（必须都是<code>Variable</code>对象）的iterable。然后，你可以设置optimizer的参数选项，比如学习率，权重衰减。</p><p>常用的 Optimizer 有 SGD 和 Adam。</p><p>所有 Optimizer 中都含有 <code>step()</code> 和 <code>zero_grad()</code> 函数， <code>step()</code> 函数完成单次优化迭代，<code>zero_grad()</code> 将之前计算的梯度清空。通用训练流程如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">0.1</span>, momentum=<span class="hljs-number">0.9</span>)<br>optimizer.zero_grad()<br>loss(model(<span class="hljs-built_in">input</span>), target).backward()<br>optimizer.step()<br></code></pre></td></tr></table></figure><p>如果要对 learning_rate 采用特殊下降方法，则通用训练流程为：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">scheduler = (optimizer, ... )<br><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):<br>    train(...)<br>    validate(...)<br>    scheduler.step()<br></code></pre></td></tr></table></figure><h4 id="迭代优化方法"><a href="#迭代优化方法" class="headerlink" title="迭代优化方法"></a>迭代优化方法</h4><h5 id="SGD"><a href="#SGD" class="headerlink" title="SGD"></a>SGD</h5><p><code>torch.optim.SGD(params, lr=&lt;required parameter&gt;, momentum=0, dampening=0, weight_decay=0, nesterov=False)</code></p><ul><li>params (iterable) – 待优化参数的iterable或者是定义了参数组的dict</li><li>lr (<code>float</code>) – 学习率</li><li>momentum (<code>float</code>, 可选) – 动量因子（默认：0）</li><li>weight_decay (<code>float</code>, 可选) – 权重衰减（L2惩罚）（默认：0）</li><li>dampening (<code>float</code>, 可选) – 动量的抑制因子（默认：0）</li><li>nesterov (<code>bool</code>, 可选) – 使用Nesterov动量（默认：False）</li></ul><h5 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h5><p><code>torch.optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)</code></p><ul><li>params (iterable) – 待优化参数的iterable或者是定义了参数组的dict</li><li>lr (<code>float</code>, 可选) – 学习率（默认：1e-3）</li><li>betas (Tuple[<code>float</code>, <code>float</code>], 可选) – 用于计算梯度以及梯度平方的运行平均值的系数（默认：0.9，0.999）</li><li>eps (<code>float</code>, 可选) – 为了增加数值计算的稳定性而加到分母里的项（默认：1e-8）</li><li>weight_decay (<code>float</code>, 可选) – 权重衰减（L2惩罚）（默认: 0）</li></ul><h4 id="lr-scheduler"><a href="#lr-scheduler" class="headerlink" title="lr_scheduler"></a>lr_scheduler</h4><h5 id="余弦退火"><a href="#余弦退火" class="headerlink" title="余弦退火"></a>余弦退火</h5><p><code>torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max, eta_min=0, last_epoch=-1, verbose=False)</code></p><p><strong>参数：</strong></p><ul><li><strong>optimizer</strong> (<a href="https://pytorch.org/docs/stable/optim.html#torch.optim.Optimizer"><em>Optimizer</em></a>) – Wrapped optimizer.</li><li><strong>T_max</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – Maximum number of iterations.</li><li><strong>eta_min</strong> (<a href="https://docs.python.org/3/library/functions.html#float"><em>float</em></a>) – Minimum learning rate. Default: 0.</li><li><strong>last_epoch</strong> (<a href="https://docs.python.org/3/library/functions.html#int"><em>int</em></a>) – The index of last epoch. Default: -1.</li><li><strong>verbose</strong> (<a href="https://docs.python.org/3/library/functions.html#bool"><em>bool</em></a>) – If <code>True</code>, prints a message to stdout for each update. Default: <code>False</code>.</li></ul><h3 id="模型的存储和导入"><a href="#模型的存储和导入" class="headerlink" title="模型的存储和导入"></a>模型的存储和导入</h3><h4 id="存储模型权重"><a href="#存储模型权重" class="headerlink" title="存储模型权重"></a>存储模型权重</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torchvision.models <span class="hljs-keyword">as</span> models<br><span class="hljs-comment"># 通过 state_dict() 方法存储权重</span><br>model = models.vgg16(pretrained=<span class="hljs-literal">True</span>)<br>torch.save(model.state_dict(), <span class="hljs-string">&#x27;model_weights.pth&#x27;</span>)<br><br><span class="hljs-comment"># 通过 load_state_dict() 方法导入权重</span><br>model = models.vgg16()<br>model.load_state_dict(torch.load(<span class="hljs-string">&#x27;model_weights.pth&#x27;</span>))<br></code></pre></td></tr></table></figure><h4 id="存储整个模型"><a href="#存储整个模型" class="headerlink" title="存储整个模型"></a>存储整个模型</h4><p>将整个模型结构和权重一起存储，数据较大。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 存储</span><br>torch.save(model, <span class="hljs-string">&#x27;model.pth&#x27;</span>)<br>model = torch.load(<span class="hljs-string">&#x27;model.pth&#x27;</span>)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Coding</category>
      
      <category>PyTorch</category>
      
    </categories>
    
    
    <tags>
      
      <tag>PyTorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>论文阅读：A Simple Framework for Contrastive Learning of Visual Representations</title>
    <link href="/2022/01/11/SimCLR/"/>
    <url>/2022/01/11/SimCLR/</url>
    
    <content type="html"><![CDATA[<h2 id="Framework"><a href="#Framework" class="headerlink" title="Framework"></a>Framework</h2><img src="Figure2.png" alt="Framework"/><ul><li>Data augmentation module</li></ul><p>功能：生成一对正样本 $\widetilde{x}_i$，$\widetilde{x}_j$。</p><p>SimCLR 中数据增广模块顺序采用三个简单增广：随机裁剪后将大小 resize 为原来大小、随机颜色变换、随机高斯模糊。</p><p>论文中提到，随机裁剪和颜色变换的组合对性能有重要影响。</p><blockquote><p>The combination of random crop and color distortion is crucial to achieve a good performance.</p></blockquote><ul><li>Base encoder $f(\cdot)$</li></ul><p>功能：从增广数据中提取 representation。</p><p>SimCLR 中允许多种网络结构的选择，没有任何限制。</p><p>论文中方便起见采用了 ResNet。</p><blockquote><p>Our framework allows various choices of the network architecture without any constraints. We opt for simplicity and adopt the commonly used ResNet (He et al., 2016) to obtain $h_i&#x3D;f(\widetilde x_i)&#x3D;ResNet(\widetilde{x}_i)$ where $h_i \in \mathbb{R}^d$ is the output after the average pooling layer.</p></blockquote><ul><li>Projection head $g(\cdot)$</li></ul><p>功能：将 representations 映射到 对比损失 (contrastive loss) 的应用空间。</p><p>SimCLR 使用含一层隐藏层的 MLP (Multilayer Perceptron) 来获取 $z_i&#x3D;g(h_i)&#x3D;W^{(2)}\sigma (W^{(1)}h_i)$，这里 $\sigma$ 是非线性函数 ReLU。</p><p>论文中提到，在 $z_i$ 上定义 contrastive loss 比在 $h_i$ 上定义更有益。</p><blockquote><p>We find it beneficial to define the contrastive loss on $z_i$’s rather than $h_i$’s.</p></blockquote><ul><li>Contrastive loss function</li></ul><p>功能：对比预测任务 (contrastive prediction task)</p><p>在给定一组包含正样本对 $\widetilde{x}_i$ 和 $\widetilde{x}_j$ 的点集 ${\widetilde{x}_k}$ 中，对比预测的任务是给定 $\widetilde{x}_i$，找出匹配的 $\widetilde{x}_j$。</p><p>SimCLR 中使用的 loss 被称作 NT-Xent (the normalized temperature-scaled cross entropy loss)，其表达式如下：<br>$$<br>\ell_{i,j}&#x3D;-\log\frac{exp(sim(z_i,z_j)&#x2F;\tau)}{\sum_{k&#x3D;1}^{2N}\mathbb{1}_{[k\neq i]}exp(sim(z_i,z_k)&#x2F;\tau)}.<br>$$</p><h2 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h2><img src="Algorithm1.png" alt="Algorithm"/><h2 id="评价方案-Evaluation-Protocol"><a href="#评价方案-Evaluation-Protocol" class="headerlink" title="评价方案 (Evaluation Protocol)"></a>评价方案 (Evaluation Protocol)</h2><h3 id="数据集和度量"><a href="#数据集和度量" class="headerlink" title="数据集和度量"></a>数据集和度量</h3><p>SimCLR 中大多数无监督预训练工作使用 ImageNet ILSVRC-2012 数据集，还有一些其他的预训练实验，使用了 CIFAR-10数据集。</p><p>为了评价学习到的 representations，SimCLR 采用被广泛使用的评价方案：</p><p>在冻结的基础网络上训练线性分类器，并使用准确度作为 representation quality.</p><blockquote><p>A linear classifier is trained on top of the frozen base network, and test accuracy is used as a proxy for representation quality.</p></blockquote><h3 id="默认设置"><a href="#默认设置" class="headerlink" title="默认设置"></a>默认设置</h3><p>使用 ResNet-50 作为基础 encoder 网络，使用2层 MLP 映射头将 representation 映射到本征空间，使用 NT-Xent loss，LARS 优化器 (learning rate &#x3D; 4.8 [0.3$\times$BatchSize&#x2F;256]，weight decay &#x3D; $10^{-6}$)。</p><p>采用 4096 的 batch size 训练 100 个 epoch，在首先10个 epoch 使用 linear warmup，学习率下降机制使用无重启的余弦下降。</p><blockquote><p>Furthermore, we use linear warmup for the first 10 epochs, and decay the learning rate with the cosine decay schedule without restarts.</p></blockquote><h2 id="对于对比表示学习的数据增广"><a href="#对于对比表示学习的数据增广" class="headerlink" title="对于对比表示学习的数据增广"></a>对于对比表示学习的数据增广</h2><h3 id="组合的数据增广操作对表示学习很重要"><a href="#组合的数据增广操作对表示学习很重要" class="headerlink" title="组合的数据增广操作对表示学习很重要"></a>组合的数据增广操作对表示学习很重要</h3><p>为了研究独立数据增广操作的影响和组合数据增广操作的重要性，SimCLR 研究者探究了独立数据增广操作下和成对数据增广操作下，SimCLR 框架的表现。</p><p>因为 ImageNet 数据集的图像具有不同的大小，在进行操作的时候总是会进行裁剪和 resize ，为了进行消融实验，SimCLR 研究者采用一种非对称的数据变换：总是先进行随机裁剪和 resize 操作，然后只在一个 branch 上再进行目标变换，从而达到对比目的。</p><p>独立或成对变换的线性估计结果如下图所示：</p><img src="Figure5.png" alt="Linear evaluation under individual or composition of data augmentations"/><p>由上图可以得出结论：<strong>没有一个单独的变换对表示学习来说是充分的</strong>。</p><blockquote><p>No single transformation suffices to learn good representations.</p></blockquote><p>同时可以看出，随机裁剪+随机颜色变化这一增广组合的效果更好。SimCLR 研究者认为对于同一张图片的随机裁剪的颜色分布是大致相同的，如下图所示。单单利用颜色分布就已经足够去辨别图像了，神经网络可能会利用这点来完成预测任务。所以，裁剪+颜色变换对于学习普遍特征来说是很重要的。</p><blockquote><p>We conjecture that one serious issue when using only random cropping as data augmentation is that most patches from an image share a similar color distribution. Neural nets may exploit this shortcut to solve the predictive task. Therefore, it is critical to compose cropping with color distortion in order to learn generalizable features.</p></blockquote><img src="Figure6.png" alt="Histograms of pixel intensities"/><h3 id="对比学习比监督学习更需要-更强的数据增广"><a href="#对比学习比监督学习更需要-更强的数据增广" class="headerlink" title="对比学习比监督学习更需要 更强的数据增广"></a>对比学习比监督学习更需要 更强的数据增广</h3><img src="Table1.png" alt="Influence of color distortion"/><p>如上表所示，颜色增广持续提升 SimCLR model 的效果，然而在 Supervised model 上，更强的数据增广反而会使模型的性能降低。</p><p>在这种情况下，AutoAugment (一种使用监督学习的增广策略) 不比简单裁剪+颜色变换的效果要好。</p><p>因此，无监督对比学习方法比监督学习需要更强的增广。</p><p><em>简单想法：监督学习方法存在过拟合，因此在更强的数据增广，也就是扰动的情况下，效果会降低。</em></p><h2 id="Encoder-和-Head-的结构"><a href="#Encoder-和-Head-的结构" class="headerlink" title="Encoder 和 Head 的结构"></a>Encoder 和 Head 的结构</h2><h3 id="无监督对比学习从大模型中收益更多"><a href="#无监督对比学习从大模型中收益更多" class="headerlink" title="无监督对比学习从大模型中收益更多"></a>无监督对比学习从大模型中收益更多</h3><p>如下图所示，随着模型 size 的增加，有监督模型和无监督模型线性分类器的性能差距越来越小。</p><blockquote><p>Unsupervised learning benefits more from bigger models than its supervised counterpart.</p></blockquote><img src="Figure7.png" alt="Linear evaluation of models with varied depth and width"/><h3 id="非线性映射头提升它前一层的表示效果"><a href="#非线性映射头提升它前一层的表示效果" class="headerlink" title="非线性映射头提升它前一层的表示效果"></a>非线性映射头提升它前一层的表示效果</h3><blockquote><p>A nonlinear projection head improves the representation quality of the layer before it.</p></blockquote><p>为了研究映射头的重要性，SimCLR 研究者采用了三种不同的映射头结构</p><ul><li>直接映射</li><li>线性映射 (<a href="#refer-anchor-1">Wu et al., 2018</a> 中的方法，该方法已经被用于之前几个方法，比较可靠)</li><li>默认包含一层隐藏层 (和 ReLU 激活层) 的非线性映射 (和 <a href="#refer-anchor-2">Bachman et al., 2019</a> 的方法类似)</li></ul><p>从下图中可以观察到，非线性映射比线性映射要好 ($+3%$)，比没有映射要好得多 ($&gt;10%$)。</p><p>当使用映射头的时候，即使不是在输出空间中，也有类似的情况。更进一步地说，使用非线性映射时，映射头的前一层 $h$ 依旧比后一层 $z&#x3D;g(h)$ 要好得多 ($&gt;10%$)。这说明映射头前面的隐藏层比之后的其他层的表示更好。</p><blockquote><p>The hidden layer before the projection head is a better representation than the layer after.</p></blockquote><img src="Figure8.png" alt="Influence of different projection heads"/><p>SimCLR 研究者认为在表示层前使用非线性映射的重要影响是因为由对比损失决定的信息损失。准确地说，$z&#x3D;g(h)$ 移除了对于下游任务重要的某些信息，例如颜色和物件偏移。通过使用非线性变换 $g(\cdot)$，更多的信息可以被保存在 $h$ 层中。为了验证这个猜测，他们做了如下图的实验：</p><img src="Table3.png" alt="Accuracy of layer before MLPs and after"/><p>实验表明，对于下游任务而言，$h$ 层确实比表示层保留的信息更多，实验效果更好。</p><h2 id="损失函数和Batch-Size"><a href="#损失函数和Batch-Size" class="headerlink" title="损失函数和Batch Size"></a>损失函数和Batch Size</h2><h3 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h3><p>SimCLR 研究者将 NT-Xent 和其他 loss 进行对比，如下表所示，NT-Xent 性能要好得多。</p><p>表内的 “sh” 指的是semi-hard negative mining。其他的一些 loss function 不根据负样本的 relative hardness 来给出权重，所以必须使用 semi-hard negative mining<a href="#refer-anchor-3"><sup>[3]<sup></a>。</p><img src="Table5.png"/><p>之后 SimCLR 研究者测试了 $\ell_2$ normalization 的重要性 (也就是余弦相似度 vs 点乘) 和 NT-Xent loss 中的 temperature $\tau$ 的选择。结果如上表所示。</p><p>在没有 $\ell_2$ normalization 的条件下，对比任务的准确率更高，但是最终表示的效果更差。</p><h3 id="更大的-batch-sizes-和更多的-epochs-有益于对比学习"><a href="#更大的-batch-sizes-和更多的-epochs-有益于对比学习" class="headerlink" title="更大的 batch sizes 和更多的 epochs 有益于对比学习"></a>更大的 batch sizes 和更多的 epochs 有益于对比学习</h3><p>如下表所示，模型的效果随着 batch size 和 training epoch 的增加不断变好。</p><img src="Figure9.png"/><p>在对比学习的过程中，更大的 batch size 和更多的 epoch 都意味着会有更多的负样本，因此会改善结果。</p><p>更大的 batch size 在每个 epoch 内会生成更多的负样本，而增加 epoch 相当于在每个 epoch 内会随机生成更多种类的负样本。</p><h2 id="和-SOTA-的对比"><a href="#和-SOTA-的对比" class="headerlink" title="和 SOTA 的对比"></a>和 SOTA 的对比</h2><p>SimCLR 研究者使用三种不同的隐藏的宽度 ($1\times,2\times,4\times$) 进行对比。</p><h3 id="线性估计-Linear-evaluation"><a href="#线性估计-Linear-evaluation" class="headerlink" title="线性估计 (Linear evaluation)"></a>线性估计 (Linear evaluation)</h3><p>比较结果如下图所示。</p><img src="Table6.png"/><h3 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h3><p>SimCLR 使用标签数据集 ILSVRC-12 中训练集采样的 $1%$ 或 $10%$ 进行训练 (对应的每一类有 ~12.8，~128 张图片)。结果如下表所示：</p><img src="Table7.png"/><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在这部分工作中，SimCLR 呈现了一个简单的框架和它进行对比视觉表示学习的实例。研究者仔细的研究了它的每个模块，展现了每个不同设计选择的影响。把这些发现结合起来，他们相当可观地提升了之前自监督，半监督和迁移学习方法的性能。</p><p>他们的方法和标准监督学习在 ImageNet 上数据增广的选择不同，在网络的最后使用了非线性映射头和对比 loss。这种简单框架的优秀说明了虽然最近人们比较感兴趣，但自监督学习的价值还是被低估了。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id="refer-anchor-1"><div>- [1] Wu, Z., Xiong, Y., Yu, S. X., and Lin, D. Unsupervised feature learning via non-parametric instance discrimination. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3733–3742, 2018.<div id="refer-anchor-2"><div>- [2] Bachman, P., Hjelm, R. D., and Buchwalter, W. Learning representations by maximizing mutual information across views. In Advances in Neural Information Processing Systems, pp. 15509–15519, 2019.<div id="refer-anchor-3"><div>- [3] Schroff, F., Kalenichenko, D., and Philbin, J. Facenet: A unified embedding for face recognition and clustering. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 815–823, 2015.]]></content>
    
    
    <categories>
      
      <category>Paper Reading</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Contrastive Learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>基于Hexo的本地博客搭建</title>
    <link href="/2022/01/09/Blog-Setup/"/>
    <url>/2022/01/09/Blog-Setup/</url>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>在21年下半年进实验室做了半年的科研训练，觉得应该适时地对自己的学习经历做阶段性总结，既可以用来复习回顾，又可以形成一种正反馈的成就机制，于是决定搭建一个自己的博客。网络上已经有一些非常详细的教程，本文也参照了这些教程，不过考虑到日后重建的需要，还是自己再做一遍总结比较妥当。日后的个性化定制、写作、服务器部署等等之后会写在其他文章里作为补充。</p><p>本博客搭建使用 Hexo 框架，它是基于 Node.js 的高效静态站点生成框架。通过 Hexo，可以使用 Markdown 语法来撰写文章，再生成静态网站并部署到本地或者服务器端。因此我们可以专注于写作的内容，不需要担心网页源代码的具体细节。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>需要安装的内容包括：</p><ul><li>Node.js (版本需不低于10.13，建议使用Node.js 12.0以上版本)</li><li>Git</li><li>Hexo (前两项是安装Hexo的必要条件)</li></ul><h3 id="Node-js安装"><a href="#Node-js安装" class="headerlink" title="Node.js安装"></a>Node.js安装</h3><p>首先在官网上下载 <a href="https://nodejs.org/en/">Node.js</a>，版本根据自己喜好选择，下载后安装，安装选项随意。</p><p><strong>安装验证方法：</strong></p><p>cmd 窗口内输入 <code>node -v</code> 和 <code>npm -v</code>，如果出现版本号，那么安装成功。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 本机示例</span><br>C:\Users\Pand&gt;node -v<br>v14.16.1<br><br>C:\Users\Pand&gt;npm -v<br>6.14.12<br></code></pre></td></tr></table></figure><h4 id="国内镜像源加速"><a href="#国内镜像源加速" class="headerlink" title="国内镜像源加速"></a>国内镜像源加速</h4><p>如果没有梯子，npm 下载速度可能会很慢，可以设置国内镜像源进行加速。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm config <span class="hljs-built_in">set</span> registry https://registry.npm.taobao.org<br></code></pre></td></tr></table></figure><p>查看 config 使用 <code>npm config list</code> 命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 本机示例</span><br>C:\Users\Pand&gt;npm config list<br>; cli configs<br>metrics-registry = <span class="hljs-string">&quot;https://registry.npm.taobao.org/&quot;</span><br>scope = <span class="hljs-string">&quot;&quot;</span><br>user-agent = <span class="hljs-string">&quot;npm/6.14.12 node/v14.16.1 win32 x64&quot;</span><br><br>; userconfig C:\Users\Pand\.npmrc<br>registry = <span class="hljs-string">&quot;https://registry.npm.taobao.org/&quot;</span> <span class="hljs-comment"># 此行说明已经配置成功</span><br><br>; <span class="hljs-built_in">builtin</span> config undefined<br>prefix = <span class="hljs-string">&quot;C:\\Users\\Pand\\AppData\\Roaming\\npm&quot;</span><br><br>; node bin location = C:\Program Files\nodejs\node.exe<br>; cwd = C:\Users\Pand<br>; HOME = C:\Users\Pand<br>; <span class="hljs-string">&quot;npm config ls -l&quot;</span> to show all defaults.<br></code></pre></td></tr></table></figure><h3 id="Git安装"><a href="#Git安装" class="headerlink" title="Git安装"></a>Git安装</h3><p>Hexo 需要通过 Git 进行版本控制，因此还要下载 Git，此处给出两个下载地址，下载后安装，安装选项随意。</p><ul><li><a href="https://npm.taobao.org/mirrors/git-for-windows/">淘宝 Git for Windows 镜像</a></li><li><a href="https://git-scm.com/download/win">官方下载地址</a></li></ul><p><strong>安装验证方法：</strong></p><p>cmd 窗口内输入 <code>git --version</code>，如果出现版本号，那么安装成功。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">C:\Users\Pand&gt;git --version<br>git version 2.32.0.windows.2<br></code></pre></td></tr></table></figure><h3 id="Hexo安装"><a href="#Hexo安装" class="headerlink" title="Hexo安装"></a>Hexo安装</h3><p>在完成前两项安装之后，可使用 npm 安装 Hexo。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install -g hexo-cli<br></code></pre></td></tr></table></figure><p><strong>安装验证方法：</strong></p><p>cmd 窗口内输入 <code>hexo -v</code>，出现版本信息，那么安装成功。</p><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><p>安装 Hexo 完成后，新建一个文件夹作为博客文件夹，之后运行以下命令来新建网站：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo init folder <span class="hljs-comment"># 此处folder为新建文件夹名称</span><br><span class="hljs-built_in">cd</span> folder<br>npm install<br></code></pre></td></tr></table></figure><p>新建完成后，博客文件夹的目录如下：</p><figure class="highlight sqf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs sqf">.<br>├── <span class="hljs-variable">_config</span>.yml<br>├── package.json<br>├── scaffolds<br>├── source<br>|   ├── <span class="hljs-variable">_drafts</span><br>|   └── <span class="hljs-variable">_posts</span><br>└── themes<br></code></pre></td></tr></table></figure><p>下面介绍该目录下的文件，根据自己需求修改，进一步完成博客配置。</p><h3 id="config-yml"><a href="#config-yml" class="headerlink" title="_config.yml"></a>_config.yml</h3><p>主配置文件，可以在 <code>_config.yml</code> 中修改大部分配置，文件中重要参数及其作用如下。</p><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td><code>title</code></td><td>网站标题</td></tr><tr><td><code>subtitle</code></td><td>网站副标题</td></tr><tr><td><code>description</code></td><td>网站描述，用于搜索引擎检索</td></tr><tr><td><code>keywords</code></td><td>网站关键词，用于搜索引擎检索</td></tr><tr><td><code>author</code></td><td>作者名</td></tr><tr><td><code>language</code></td><td>网站使用的语言。中文 <code>zh-CN</code>，英文<code>en</code></td></tr><tr><td><code>timezone</code></td><td>网站时区。参照 <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">时区列表</a> 进行设置，中国大陆地区可以使用 <code>Asia/Shanghai</code></td></tr><tr><td><code>url</code></td><td>网址，必须以 <code>http://</code> 或 <code>https://</code> 开头</td></tr><tr><td><code>root</code></td><td>网站根目录</td></tr><tr><td><code>source_dir</code></td><td>资源文件夹，用来存放博客源文件</td></tr><tr><td><code>public_dir</code></td><td>公共文件夹，用于存放生成的站点文件</td></tr><tr><td><code>tag_dir</code></td><td>标签文件夹</td></tr><tr><td><code>archive_dir</code></td><td>归档文件夹</td></tr><tr><td><code>category_dir</code></td><td>分类文件夹</td></tr><tr><td><code>theme</code></td><td>当前主题名称</td></tr></tbody></table><h3 id="scaffolds"><a href="#scaffolds" class="headerlink" title="scaffolds"></a>scaffolds</h3><p>模板文件夹。新建文章时，Hexo 会根据 scaffold 来建立文件。</p><p>scaffolds下 draft 是新建草稿模板，post 是新建文章模板，page 是新建页面模板。</p><p>下面是我使用的 scaffold-post 示例</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs markdown">title: &#123;&#123; title &#125;&#125;<br>date: &#123;&#123; date &#125;&#125;<br>categories: <br>tags: <br>excerpt: <br>index<span class="hljs-emphasis">_img: </span><br></code></pre></td></tr></table></figure><h3 id="source"><a href="#source" class="headerlink" title="source"></a>source</h3><p>用户资源文件夹。除  <code>_post </code> 文件夹外，开头命名为 <code>_</code> 的文件&#x2F;文件夹将被忽略。</p><p>Markdown 和 HTML 文件会被解析并放到 <code>public</code> 文件夹，其他文件会被拷贝过去。</p><h3 id="theme"><a href="#theme" class="headerlink" title="theme"></a>theme</h3><p>主题文件夹。Hexo 会根据主题来生成静态页面。</p><p>可以在 <a href="https://hexo.io/themes/">Hexo 主题官网</a> 找到自己想要的主题并安装。一般来讲，安装主题直接下载主题包并复制到 <code>theme</code> 文件夹即可。</p><p>如果主题有 Github 仓库，可以直接在主题文件夹内执行 <code>git clone &#39;Github网址&#39;</code> 下载主题仓库，并在<code>_config.yml</code> 文件中修改主题名称。</p><p>本博客采用的是 <code>Fluid</code> 主题，个人觉得比较好看、简洁，其相关链接如下</p><ul><li><a href="https://github.com/fluid-dev/hexo-theme-fluid">Github 仓库</a></li><li><a href="https://hexo.fluid-dev.com/">Fluid Demo</a></li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>[1] <a href="https://godweiyang.com/2018/04/13/hexo-blog/">超详细Hexo+Github博客搭建小白教程</a></li><li>[2] <a href="https://zhuanlan.zhihu.com/p/28329874">Hexo与Github搭建个人博客</a></li><li>[3] <a href="https://hsinjhao.github.io/2019/05/16/BuildBlogsBasedOnHexoAndGithub/">利用hexo和github搭建个人博客的辛酸之路</a></li><li>[4] <a href="https://hexo.io/zh-cn/docs/">Hexo 官方文档</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>Blog Building</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>t-SNE 可视化降维方法简介</title>
    <link href="/2022/01/05/t-SNE%E7%AE%80%E4%BB%8B/"/>
    <url>/2022/01/05/t-SNE%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p><strong>t-distributed stochastic neighbor embedding (t-SNE)</strong><a href="#refer-anchor-1"><sup>[1]<sup></a> 是一种基于概率将高维数据降为低维的降维方法，通常被用于将高维数据进行2维或3维的可视化。</p><p>传统的<strong>线性方法</strong>主要将<strong>不相似的点</strong>在低维表示中分开。</p><blockquote><p>PCA (Principle Components Analysis, 主成分分析)</p><p>MDS (Multiple Dimensional Scaling, 多维缩放)</p></blockquote><p>对处于<strong>低维流形</strong>上的高维数据而言，更重要地是让<strong>相邻点</strong>在低维表示中保持相邻。<strong>非线性技术</strong>主要保持数据的<strong>局部结构</strong> (Locality)。</p><blockquote><p>Sammon mapping</p><p>LLE (Locally Linear Embedding, 局部线性嵌入)</p><p>LE (Laplacian Eigenmaps, 拉普拉斯特征映射)</p><p>Isomap (Isometric Mapping, 等度量映射)</p></blockquote><p>和以上方法相同，<strong>t-SNE</strong>通过建立<strong>配对相似度</strong> (pairwise similarities)来进行低维重构。</p><p>不同的是，<strong>t-SNE</strong>通过概率来建立配对相似度，而不是简单地通过距离建立。</p><p>首先我们先介绍t-SNE的前身，SNE (Stochastic Neighbor Embedding, 随机近邻嵌入)</p><h2 id="SNE"><a href="#SNE" class="headerlink" title="SNE"></a>SNE</h2><p>SNE首先通过概率来建立配对相似度。</p><h4 id="配对相似度-基于条件概率"><a href="#配对相似度-基于条件概率" class="headerlink" title="配对相似度-基于条件概率"></a>配对相似度-基于条件概率</h4><p>给定一组高维数据点$x_1,x_2,\cdots,x_n$，$p_{j|i}$是$x_i$会将$x_j$选为邻居的条件概率。这里的比值是邻居和所有点的高斯分布概率密度之比。<br>$$<br>p_{j|i}&#x3D;\frac{exp(-||x_i-x_j||^2&#x2F;2\sigma_i^2)}{\sum\limits_{k\neq i}exp(-||x_i-x_k||^2&#x2F;2\sigma_i^2)}<br>$$<br>注意：1）分母即归一化。2）默认$p_{i|i}&#x3D;0$。3）每不同数据点$x_i$有不同的$\sigma_i$。其计算方式将在下面叙述。</p><p>同样的，对于低维表示，定义同样的条件概率。不同的是，为了消除缩放对数据点的影响，同时也为了方便计算，这里指定$\sigma_i &#x3D; \frac{1}{\sqrt{2}}$。<br>$$<br>q_{j|i}&#x3D;\frac{exp(-||y_i-y_j||^2)}{\sum\limits_{k\neq i}exp(-||y_i-y_k||^2)}<br>$$<br>注意：1）若$\sigma_i$取其他值，也只影响缩放。</p><p>则可以认为，如果建模正确，低维映射$y_i$和$y_j$的相似度应该和高维数据$x_i$和$x_j$的相似度相等。</p><h4 id="损失函数-基于KL散度"><a href="#损失函数-基于KL散度" class="headerlink" title="损失函数-基于KL散度"></a>损失函数-基于KL散度</h4><p>基于这个想法，SNE意图找到一个可以减小$p_{j|i}$和$q_{j|i}$之间失配 (mismatch) 的低维表示。</p><p>为了减少失配，首先需要方法来衡量它，SNE引入了<a href="#kl%E6%95%A3%E5%BA%A6">KL散度</a> (Kullback-Leibler divergences)<a href="#refer-anchor-2"><sup>[2]<sup></a> 来衡量失配，损失函数 (cost function) 如下：<br>$$<br>C&#x3D;\sum\limits_i KL(P_i||Q_i)&#x3D;\sum\limits_i\sum\limits_j p_{j|i}\log \frac{p_{j|i}}{q_{j|i}}<br>$$<br>定义了$C$后，SNE采用梯度下降的方法来学习到合适的$y_i$，对$y_i$的梯度为：<br>$$<br>\frac{\partial C}{\partial y_i}&#x3D;2\sum\limits_j(p_{j|i}-q_{j|i}+p_{i|j}-q_{i|j})(y_i-y_j)<br>$$<br>采用动量项来迭代更新$y_i$<br>$$<br>y_i^{(t)}&#x3D;y_i^{(t-1)}+\eta \frac{\partial C}{\partial y_i}+\alpha(t)(y_i^{(t-1)}-y_i^{(t-2)})<br>$$<br>至此，SNE的过程已经介绍完毕，通过计算条件概率来得到$P$，初始化$Y$后，计算$Q$。之后通过动量梯度下降来更新$Y$，得到计算结果。</p><h4 id="选取-sigma-i-基于熵"><a href="#选取-sigma-i-基于熵" class="headerlink" title="选取$\sigma_i$-基于熵"></a>选取$\sigma_i$-基于熵</h4><p>在数据集中，不同类别数据点的分布密度往往不同，因此不能定制一个所有点都适用的$\sigma$。</p><blockquote><p>Every $\sigma_i$ is either set by hand or found by a simple binary search (<a href="#refer-anchor-3">Hinton and Roweis, 2003</a>) or by a very robust root-finding method (<a href="#refer-anchor-4">Vladymyrov and Carreira-Perpinan, 2013</a>)</p></blockquote><p>这里介绍一种基于熵来限制分布自由度的方法。</p><p>熵增加，$\sigma_i$也增加，所以通过限制熵的大小来寻找合适的$\sigma_i$，让不同类别的数据点有一个大致相同的分布。定义困惑度 (perplexity) 如下<br>$$<br>Perp(P_i) &#x3D;2^{H(P_i)}&#x3D;2^{-\sum\limits_jp_{j|i}\log_2p_{j|i}}<br>$$<br>这里的$H(P_i)$是香农熵，通常指定的困惑值在5和50之间。</p><p>由于$Perp(\cdot)$函数是单调函数，可以采用二分的方法来寻找$\sigma_i$。</p><h4 id="SNE局限-Limitations"><a href="#SNE局限-Limitations" class="headerlink" title="SNE局限 (Limitations)"></a>SNE局限 (Limitations)</h4><ul><li>Cost function 难以优化。偏导 $2\sum\limits_j(p_{j|i}-q_{j|i}+p_{i|j}-q_{i|j})(y_i-y_j)$ 难以计算。</li><li>Crowding problem。在二维映射空间中，能容纳<strong>（高维空间中的）中等距离间隔点</strong>的空间，不会比能容纳<strong>（高维空间中的）相近点</strong>的空间大太多。所以高维空间中离得远的、近的点，在低维空间中都被塞在了一起，引起了拥挤问题。</li></ul><h2 id="t-SNE"><a href="#t-SNE" class="headerlink" title="t-SNE"></a>t-SNE</h2><p>t-SNE在SNE的基础上进行了改进，优化了SNE的Limitations。</p><ul><li>Cost function 难以优化 $\Longrightarrow$ 使用 Symmetric SNE。</li><li>Crowding problem $\Longrightarrow$ 在低维嵌入上使用Student’s t-distribution 替代 Guassian distribution，同时也简化了cost function。</li></ul><p>下面，我们将分别针对这些优化进行介绍。</p><h4 id="Symmetric-SNE"><a href="#Symmetric-SNE" class="headerlink" title="Symmetric SNE"></a>Symmetric SNE</h4><p>在高维空间中定义联合概率$p_{ij}$为对称条件概率：<br>$$<br>p_{ij}&#x3D;\frac{p_{j|i}+p_{i|j}}{2n}<br>$$<br>则cost function为：<br>$$<br>C&#x3D;KL(P||Q)&#x3D;\sum\limits_i\sum\limits_jp_{ij}\log\frac{p_{ij}}{q_{ij}}<br>$$<br>则简化后的偏导为：<br>$$<br>\frac{\partial C}{\partial y_i}&#x3D;4\sum\limits_j(p_{ij}-q_{ij})(y_i-y_j)<br>$$<br>偏导形式相对SNE来说更简单，计算速度更快。</p><p>(注意：这只是Symmetric SNE的梯度公式，t-SNE的梯度公式类似，推导见后。)</p><h4 id="Crowding-problem"><a href="#Crowding-problem" class="headerlink" title="Crowding problem"></a>Crowding problem</h4><p>“crowding problem”:</p><blockquote><p>The area of the two-dimensional map that is available to accommodate <strong>moderately distant datapoints</strong> will not be nearly large enough compared with the area available to accommodate <strong>nearby datapoints</strong>.</p></blockquote><p>在<a href="#sne%E5%B1%80%E9%99%90" title="limitations">SNE局限</a>中已经提到过，由于在低维空间中，能容纳的点一定比高维空间中的少，所以高维空间中远的、近的点，在低维空间中往往被塞在一起。</p><p>这个问题其实是由于高斯概率分布造成的，高斯分布对于中等距离和较近距离的区分较少，也即，不能对近距离的点做出明显区分。因此，对于低维表示，t-SNE采用t分布来替换高斯分布。</p><img src="gaussian_t_comparasion.png" style="zoom:72%;" /><p>上图横轴表示距离，纵轴表示相似度，可以看到，对较大相似度的点，t分布在低维空间中的距离需要更小一点，对于低相似度的点，t分布在低维空间中需要的距离更远。</p><p>所以，可以使同一簇内的点聚合地更紧密，不同簇之间的点更加疏远，解决crowding problem。</p><h4 id="t-SNE配对相似度及损失函数"><a href="#t-SNE配对相似度及损失函数" class="headerlink" title="t-SNE配对相似度及损失函数"></a>t-SNE配对相似度及损失函数</h4><p>至此为止，我们可以定义联结概率 (joint probabilities) $q_{ij}$：<br>$$<br>q_{ij}&#x3D;\frac{(1+||y_i-y_j||^2)^{-1}}{\sum\limits_{k\neq l}(1+||y_k-y_l||^2)^{-1}}<br>$$<br>注意：和SNE的$q_{j|i}$公式相比，分母的求和号中，之前是$k\neq i$，表示仅排除 $i$ 自身项；现在是 $k\neq l$ ，表示排除所有自身项。也就是点对间所有两两之差。</p><p>损失函数 (cost function) 为：<br>$$<br>\frac{\partial C}{\partial y_i}&#x3D;4\sum\limits_j(p_{ij}-q_{ij})(y_i-y_j)(1+||y_i-y_j||^2)^{-1}<br>$$</p><p>推导详见 Maaten &amp; Hinton, 2008<a href="#refer-anchor-7"><sup>[4]<sup></a> Appendix A.</p><p>至此，我们已经得到了t-SNE的损失函数，可以同样通过SNE中提到的动量迭代法来求解$Y$。</p><p>接下来，对t-SNE的优势和局限性做一个总结。</p><h2 id="优势及局限性"><a href="#优势及局限性" class="headerlink" title="优势及局限性"></a>优势及局限性</h2><p>Advantages：</p><ul><li>相较于LLE和LE等算法来说，t-SNE中点的相似度 (similarity) 由概率密度表示，不用KNN指定邻居，减少了参数量。</li><li>每个点的局部邻居由概率密度表示，具有适应性 (相当于可以对每个点自定义邻居数量)。</li><li>高维数据中高斯密度的应用让t-SNE保有局部特征的同时，维护全局结构。(不太懂)</li></ul><blockquote><p>Gaussian kernel employed by t-SNE (in high-dimensional) defines a soft border between the local and global structure of the data.</p></blockquote><ul><li>相较于SNE，t-SNE采用t分布后消除了一部分指数计算，计算效率更高，计算更快。</li></ul><p>Limitations：</p><ul><li>t-SNE不一定适用于超过三维的降维。对于超过三维的更高维度，t分布可能需要采用更高的自由度才更加合适。</li></ul><blockquote><p>It is unclear t-SNE would perform on general <strong>Dimensionality Reduction</strong> for more than 3 dimensions. For such higher (than 3) dimensions, Student-t distribution with more degrees of freedom should be more appropriate.</p></blockquote><ul><li>t-SNE也是通过数据的局部结构来执行降维任务的，因此可能对某些高维数据失效 (数据本身就是高维的，无法找到一种恰当的低维表示)</li></ul><blockquote><p>t-SNE reduces the dimensionality of data mainly based on local properties of the data which means it would fail in data which has intrinsically high dimensional structure (<strong>curse of dimensionality</strong>).</p></blockquote><ul><li>t-SNE的损失函数不是凸函数，因此在构造解的时候不会有固定解，而且没有一种有效且固定的解法，只能通过迭代求解。</li></ul><h2 id="关联概念"><a href="#关联概念" class="headerlink" title="关联概念"></a>关联概念</h2><h3 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h3><p>上文中提到的KL散度是一种衡量概率差别的方法，是两个概率分布$P$和$Q$差别的<strong>非对称</strong>度量。</p><blockquote><p>KL散度 (Kullback-Leibler divergence，简称KLD)，在讯息系统中称为相对熵 (relative entropy)<a href="#refer-anchor-2"><sup>[2]<sup></a>。</p></blockquote><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>对于离散随机变量，它的概率分布$P$和$Q$的KL散度可按下式定义为<br>$$<br>D_{KL}(P||Q)&#x3D;\sum\limits_iP(i)\ln\frac{P(i)}{Q(i)}<br>$$<br>即按概率$P$求得的$P$和$Q$的对数商的平均值。KL散度仅当概率$P$和$Q$各自总和均为1，且对于任何$i$皆满足$Q(i)&gt;0$以及$P(i)&gt;0$时才有定义。</p><h4 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h4><p>KLD的值为非负数：<br>$$<br>D_{KL}(P||Q)\ge 0<br>$$<br>当且仅当$P&#x3D;Q$时$D_{KL}(P||Q)$为零。</p><p>虽然从直觉上KL散度是个度量或距离函数，但是它实际上并不是一个真正的度量或距离。因为KL散度具有不对称性：<br>$$<br>D_{KL}(P||Q)\neq D_{KL}(Q||P)<br>$$</p><h3 id="Student’s-t-distribution"><a href="#Student’s-t-distribution" class="headerlink" title="Student’s t-distribution"></a>Student’s t-distribution</h3><p><strong>学生t分布</strong> (Student’s t-distribution)，简称<strong>t分布</strong>，在概率论及统计学中用于根据小样本来估计总体呈正态分布且标准差未知的期望值<a href="#refer-anchor-6"><sup>[3]<sup></a>。</p><p>其概率分布密度函数 (Probability Density Function, PDF) 为<br>$$<br>f(t)&#x3D;\frac{\Gamma(\frac{v+1}{2})}{\sqrt{v\pi}\Gamma(\frac{v}{2})}(1+\frac{t^2}{v})^{-\frac{v+1}{2}}<br>$$<br>其中 $v$ 是自由度 。</p><p>特殊情况，当 $v&#x3D;1$ 时<br>$$<br>f(t)&#x3D;\frac{1}{\pi(1+t^2)}<br>$$<br>这种概率分布也叫作柯西分布 (Cauchy distribution)。在t-SNE中用到的也是柯西分布。</p><p>特殊情况，当 $v&#x3D;\infty$ 时<br>$$<br>f(t)&#x3D;\frac{1}{\sqrt{2\pi}}e^{-\frac{t^2}{2}}<br>$$<br>称为高斯&#x2F;正态分布。</p><p>t分布的概率密度图如下图所示。</p><img src="student_t_pdf.png" alt="Student's t-distribution" style="zoom:30%;" /><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><div id="refer-anchor-1"><div>- [1] [Wikipedia: t-distributed stochastic neighbor embedding](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)<div id="refer-anchor-2"><div>- [2] [Wikipedia: Kullback–Leibler divergence](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)<div id="refer-anchor-6"><div>- [3] [Wikipedia: Student's t-distribution](https://en.wikipedia.org/wiki/Student%27s_t-distribution)<div id="refer-anchor-7"><div>- [4] Van der Maaten L, Hinton G. Visualizing data using t-SNE[J]. Journal of machine learning research, 2008, 9(11).<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><div id="refer-anchor-3"><div>- [1] Hinton G, Roweis S T. Stochastic neighbor embedding[C]//NIPS. 2002, 15: 833-840.<div id="refer-anchor-4"><div>- [2] Vladymyrov M, Carreira-Perpinan M. Entropic affinities: Properties and efficient numerical computation[C]//International conference on machine learning. PMLR, 2013: 477-485.<div id="refer-anchor-5"><div>- [3] [论文笔记：Visualizing data using t-SNE](https://psubnwell.github.io/2017/12/01/paper-note-t-sne/)]]></content>
    
    
    <categories>
      
      <category>Representation Learning</category>
      
    </categories>
    
    
    <tags>
      
      <tag>t-SNE</tag>
      
      <tag>Dimension Reduction</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>subplot</title>
    <link href="/2021/12/29/subplot/"/>
    <url>/2021/12/29/subplot/</url>
    
    <content type="html"><![CDATA[<h3 id="pyplot-绘制多图方法"><a href="#pyplot-绘制多图方法" class="headerlink" title="pyplot 绘制多图方法"></a>pyplot 绘制多图方法</h3><hr><h4 id="subplot"><a href="#subplot" class="headerlink" title="subplot"></a>subplot</h4><h5 id="subplot-语法："><a href="#subplot-语法：" class="headerlink" title="subplot()语法："></a>subplot()语法：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">subplot(nrows, ncols, index, **kwargs)<br></code></pre></td></tr></table></figure><ul><li>nrows：行数</li><li>ncols：列数</li><li>index：从左到右，从上到下，每个子区域的编号$1\cdots N$</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python">row, col = <span class="hljs-number">3</span>, <span class="hljs-number">2</span><br><br>img = img.reshape(features, samples)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, row * col+<span class="hljs-number">1</span>):<br>    plt.subplot(row, col, i)<br>    timg = img[:, i-<span class="hljs-number">1</span>]<br>    timg = timg.reshape(width, height)<br>    plt.imshow(timg)<br>    plt.xticks([])<br>    plt.yticks([])<br>plt.show()<br></code></pre></td></tr></table></figure><h4 id="subplots"><a href="#subplots" class="headerlink" title="subplots"></a>subplots</h4><h5 id="subplots-语法："><a href="#subplots-语法：" class="headerlink" title="subplots()语法："></a>subplots()语法：</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">matplotlib.pyplot.subplots(nrows=<span class="hljs-number">1</span>, ncols=<span class="hljs-number">1</span>, *, sharex=<span class="hljs-literal">False</span>, sharey=<span class="hljs-literal">False</span>, squeeze=<span class="hljs-literal">True</span>, subplot_kw=<span class="hljs-literal">None</span>, gridspec_kw=<span class="hljs-literal">None</span>, **fig_kw)<br></code></pre></td></tr></table></figure><ul><li><strong>nrows</strong>：默认为 1，设置图表的行数。</li><li><strong>ncols</strong>：默认为 1，设置图表的列数。</li><li><strong>sharex、sharey</strong>：设置 x、y 轴是否共享属性，默认为 false，可设置为 ‘none’、’all’、’row’ 或 ‘col’。 False 或 none 每个子图的 x 轴或 y 轴都是独立的，True 或 ‘all’：所有子图共享 x 轴或 y 轴，’row’ 设置每个子图行共享一个 x 轴或 y 轴，’col’：设置每个子图列共享一个 x 轴或 y 轴。</li><li><strong>squeeze</strong>：布尔值，默认为 True，表示额外的维度从返回的 Axes(轴)对象中挤出，对于 N<em>1 或 1</em>N 个子图，返回一个 1 维数组，对于 N*M，N&gt;1 和 M&gt;1 返回一个 2 维数组。如果设置为 False，则不进行挤压操作，返回一个元素为 Axes 实例的2维数组，即使它最终是1x1。</li><li><strong>subplot_kw</strong>：可选，字典类型。把字典的关键字传递给 add_subplot() 来创建每个子图。</li><li><strong>gridspec_kw</strong>：可选，字典类型。把字典的关键字传递给 GridSpec 构造函数创建子图放在网格里(grid)</li><li>*<strong>*fig_kw</strong>：把详细的关键字参数传给 figure() 函数。</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># 创建画像和子图</span><br>fig, axs = plt.subplots(nrows, ncols)<br><br><span class="hljs-comment">###### 未对代码进行测试！</span><br>axs[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>].imshow(timg1)<br>axs[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>].axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>axs[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>].imshow(timg2)<br>axs[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>].axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br><span class="hljs-comment">######</span><br>fig.show()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
